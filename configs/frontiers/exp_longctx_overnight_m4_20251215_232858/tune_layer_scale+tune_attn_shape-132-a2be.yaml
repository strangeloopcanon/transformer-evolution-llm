model:
  name: arch-tune_layer_scale+tune_attn_shape-132-a2be
  emb:
    dim: 512
    vocab: 50257
    rope: null
    dropout: 0.0
    init_std: 0.02
  blocks:
  - name: null
    attn:
      kind: GQA
      causal: true
      heads: 8
      head_dim: 64
      rope: yarn
      rope_theta: null
      rope_factor: null
      alibi: false
      linear_feature_map: elu
      kv_latent_dim: null
      sw: null
      kv_groups: 1
      dropout: 0.0
      qk_norm_max: null
      gating_pos: none
      gating_op: dense
      sparsity: none
      block_size: null
      block_stride: null
      global_stride: null
      dilation: null
      selector: none
      selector_topk: null
      selector_heads: null
      selector_dim: null
      selector_rope: none
      selector_detach: false
    ffn:
      type: dense
      hidden: 2048
      activation: swiglu
      dropout: 0.0
    ssm: null
    extras: []
  - name: null
    attn:
      kind: GQA
      causal: true
      heads: 8
      head_dim: 64
      rope: yarn
      rope_theta: null
      rope_factor: null
      alibi: false
      linear_feature_map: elu
      kv_latent_dim: null
      sw: null
      kv_groups: 4
      dropout: 0.0
      qk_norm_max: null
      gating_pos: none
      gating_op: dense
      sparsity: none
      block_size: null
      block_stride: null
      global_stride: null
      dilation: null
      selector: none
      selector_topk: null
      selector_heads: null
      selector_dim: null
      selector_rope: none
      selector_detach: false
    ffn:
      type: dense
      hidden: 2048
      activation: swiglu
      dropout: 0.0
    ssm: null
    extras:
    - type: layer_scale
      targets:
      - attn
      - ffn
      init: 1.0e-05
      learnable: true
  head:
    tie_embeddings: true
    vocab: 50257
  norm: rmsnorm
  recurrences: []
train:
  lr: 0.0008
  warmup: 500
  clip: 1.0
  bf16: true
  grad_ckpt: true
  max_tokens: 600000
  weight_decay: 0.02
  seed: 4242
  router_lb_coeff: 0.01
  router_entropy_coeff: 0.005
  entropy_threshold: 0.5
  entropy_patience: 3
  instability_threshold: 50.0
  no_improve_patience: 40
  improvement_tolerance: 0.001
  ppl_stop_threshold: null
  passkey_eval_steps: 6
  passkey_eval_batches: 4
  passkey_eval_seq_len: 2048
  passkey_eval_min_distance: 1536
  passkey_eval_batch_size: 1
  passkey_eval_lr: 0.001
  passkey_eval_vocab_limit: 256
data:
  tokenizer: gpt2
  hf_revision: main
  seq_len: 512
  batch_size: 1
  workers: 0
  shards:
  - name: ag_news
    split: train
    weight: 0.25
  - name: wikitext
    split: wikitext-2-raw-v1
    weight: 0.35
  - name: mbpp
    split: train
    weight: 0.4
  eval_shards:
  - name: ag_news
    split: test
    weight: 1.0
  - name: wikitext
    split: wikitext-2-raw-v1:test
    weight: 1.0
  - name: mbpp
    split: test
    weight: 1.0
  eval_tokens: 16384
  healing_shards: []
  healing_tokens: null
evolution:
  rung0_thresholds:
    max_params: 150000000
    max_kv_bytes_per_token: 4500
    min_throughput_proxy: 5.0
    gate_entropy_min: 0.0
    gate_entropy_max: 4.0
  rung1_tokens: 200000
  rung2_tokens: 600000
  population: 24
  topk_keep: 0.45
  crossover_prob: 0.4
  parent_selection: map_elites
  archive_max_elites: 48
  adaptive_mutation: true
  adaptive_mutation_eta: 0.1
  adaptive_mutation_min_weight: 0.05
  adaptive_mutation_max_weight: 5.0
  weight_inheritance: parent
  objectives:
    ppl_code: min
    passkey_loss: min
    throughput: max
    ram: min
  composite_metrics:
  - name: longctx_score
    op: weighted_sum
    terms:
      ppl_code: 1.0
      passkey_loss: 2000.0
      ram: 500.0
      throughput: -2.0
    epsilon: 1.0e-06
