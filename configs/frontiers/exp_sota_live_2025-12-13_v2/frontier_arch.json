[
  {
    "id": "shift_moe-2-6cc6",
    "parent": "seed-1-f3a5",
    "metrics": {
      "layers": 12.0,
      "moe_blocks": 5.0,
      "graph_entropy": 2.6880533617977047,
      "selector_blocks": 0.0,
      "selector_topk_avg": 0.0,
      "memory_blocks": 7.0,
      "recurrences": 0.0,
      "novelty": 0.4166666666666667,
      "params": 325965315.0,
      "kv_bytes_per_token": 12288,
      "throughput_proxy": 26.490953233506943,
      "ppl_code": 1.0,
      "ppl_math": 1.05,
      "throughput": 324.37268620583535,
      "ram": 0.6071577128022909,
      "long_recall": 1.0083333333333333,
      "router_entropy": 0.6845440626144409,
      "router_lb": 0.0234346155077219,
      "router_load_max": 0.4755859375,
      "router_load_min": 0.0,
      "router_load_cv": 2.576119899749756,
      "capacity_overflow": 0.0,
      "max_grad_norm": 0.0,
      "instability": 0.0,
      "stop_reason_code": 3.0,
      "nan_seen": 0.0,
      "loss_spike": 8.722767233848572e-06,
      "prior_distance": 0.025563275517486335,
      "ppl_per_long_recall": 0.9917355371900827,
      "ppl_per_param": 3.067811064499301e-09,
      "ppl_per_throughput": 0.0030828736281618844
    },
    "spec": {
      "model": {
        "name": "phi-tiny-evo-creative",
        "emb": {
          "dim": 512,
          "vocab": 50257,
          "rope": null,
          "dropout": 0.0
        },
        "blocks": [
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "moe",
              "hidden": 2048,
              "n_experts": 16,
              "k": 2,
              "capacity_factor": 1.2,
              "balance": 0.05,
              "shared": 1,
              "router_temperature": null,
              "router_type": "softmax",
              "router_bias_detached": false,
              "shared_expert": false,
              "router_aux_weight": null,
              "router_lb_weight": null,
              "drop_policy": "none",
              "experts": []
            },
            "ssm": null,
            "extras": [
              {
                "type": "custom",
                "name": "exp-gater",
                "params": {
                  "dim": 256
                }
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": "yarn",
              "rope_theta": null,
              "sw": 128,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "local_global",
              "block_size": null,
              "block_stride": null,
              "global_stride": 64,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": null,
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 256,
                "stride": 32,
                "aggregator": "gate",
                "gating_weight": 0.25
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "moe",
              "hidden": 2048,
              "n_experts": 16,
              "k": 2,
              "capacity_factor": 1.2,
              "balance": 0.05,
              "shared": 1,
              "router_temperature": null,
              "router_type": "softmax",
              "router_bias_detached": false,
              "shared_expert": false,
              "router_aux_weight": null,
              "router_lb_weight": null,
              "drop_policy": "none",
              "experts": []
            },
            "ssm": null,
            "extras": [
              {
                "type": "custom",
                "name": "exp-gater",
                "params": {
                  "dim": 256
                }
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": {
              "kind": "mamba2",
              "d_state": 16,
              "d_conv": 4,
              "dt_rank": 8,
              "chunk": 128,
              "gate": 0.15
            },
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 512,
                "stride": 128,
                "aggregator": "attention",
                "gating_weight": 0.1191520977835257
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "moe",
              "hidden": 2048,
              "n_experts": 16,
              "k": 2,
              "capacity_factor": 1.2,
              "balance": 0.05,
              "shared": 1,
              "router_temperature": null,
              "router_type": "softmax",
              "router_bias_detached": false,
              "shared_expert": false,
              "router_aux_weight": null,
              "router_lb_weight": null,
              "drop_policy": "none",
              "experts": []
            },
            "ssm": null,
            "extras": [
              {
                "type": "custom",
                "name": "exp-gater",
                "params": {
                  "dim": 256
                }
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": {
              "kind": "mamba2",
              "d_state": 16,
              "d_conv": 4,
              "dt_rank": 8,
              "chunk": 128,
              "gate": 0.15
            },
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 512,
                "stride": 128,
                "aggregator": "attention",
                "gating_weight": 0.1191520977835257
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": "yarn",
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "moe",
              "hidden": 2048,
              "n_experts": 16,
              "k": 2,
              "capacity_factor": 1.2,
              "balance": 0.05,
              "shared": 1,
              "router_temperature": null,
              "router_type": "softmax",
              "router_bias_detached": false,
              "shared_expert": false,
              "router_aux_weight": null,
              "router_lb_weight": null,
              "drop_policy": "none",
              "experts": []
            },
            "ssm": null,
            "extras": [
              {
                "type": "gated",
                "targets": [
                  "attn",
                  "ffn",
                  "ssm"
                ],
                "init_weight": 0.2,
                "learnable": true
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": null,
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 1024,
                "stride": 64,
                "aggregator": "gate",
                "gating_weight": 0.35
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": {
              "kind": "mamba2",
              "d_state": 16,
              "d_conv": 4,
              "dt_rank": 8,
              "chunk": 128,
              "gate": 0.15
            },
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 512,
                "stride": 128,
                "aggregator": "attention",
                "gating_weight": 0.1191520977835257
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": "yarn",
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "moe",
              "hidden": 2048,
              "n_experts": 16,
              "k": 2,
              "capacity_factor": 1.2,
              "balance": 0.05,
              "shared": 1,
              "router_temperature": null,
              "router_type": "softmax",
              "router_bias_detached": false,
              "shared_expert": false,
              "router_aux_weight": null,
              "router_lb_weight": null,
              "drop_policy": "none",
              "experts": []
            },
            "ssm": null,
            "extras": [
              {
                "type": "gated",
                "targets": [
                  "attn",
                  "ffn",
                  "ssm"
                ],
                "init_weight": 0.2,
                "learnable": true
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": null,
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 1024,
                "stride": 64,
                "aggregator": "gate",
                "gating_weight": 0.35
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": null,
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 1024,
                "stride": 64,
                "aggregator": "gate",
                "gating_weight": 0.35
              }
            ]
          }
        ],
        "head": {
          "tie_embeddings": true,
          "vocab": 50257
        },
        "norm": "layernorm",
        "recurrences": []
      },
      "train": {
        "lr": 0.0008,
        "warmup": 500,
        "clip": 1.0,
        "bf16": true,
        "grad_checkpoint": true,
        "max_tokens": 520000,
        "weight_decay": 0.02,
        "seed": 4242,
        "router_lb_coeff": 0.01,
        "router_entropy_coeff": 0.005,
        "entropy_threshold": 0.5,
        "entropy_patience": 3,
        "instability_threshold": 500.0,
        "no_improve_patience": 20,
        "improvement_tolerance": 0.001,
        "ppl_stop_threshold": null,
        "init_checkpoint": null,
        "optimizer": {
          "name": "adamw",
          "lr": null,
          "betas": null,
          "eps": null,
          "weight_decay": null
        }
      },
      "data": {
        "tokenizer": "gpt2",
        "hf_revision": "main",
        "seq_len": 512,
        "batch_size": 1,
        "workers": 0,
        "shards": [
          {
            "name": "ag_news",
            "split": "train",
            "weight": 0.25,
            "cache_path": null,
            "revision": null
          },
          {
            "name": "wikitext",
            "split": "wikitext-2-raw-v1",
            "weight": 0.35,
            "cache_path": null,
            "revision": null
          },
          {
            "name": "mbpp",
            "split": "train",
            "weight": 0.4,
            "cache_path": null,
            "revision": null
          }
        ],
        "healing_shards": [],
        "healing_tokens": null
      },
      "evolution": {
        "rung0_thresholds": {
          "gate_entropy_min": 0.0,
          "gate_entropy_max": 4.0
        },
        "rung1_tokens": 300000,
        "rung2_tokens": 900000,
        "population": 24,
        "topk_keep": 0.45,
        "crossover_prob": 0.5,
        "parent_selection": "lexicase",
        "pareto_objectives": [
          "ppl_code",
          "ppl_math",
          "long_recall",
          "ppl_per_long_recall",
          "throughput",
          "ram",
          "novelty",
          "graph_entropy"
        ],
        "objectives": {
          "ppl_code": "min",
          "ppl_math": "min",
          "long_recall": "max",
          "ppl_per_long_recall": "min",
          "throughput": "max",
          "ram": "min",
          "novelty": "max",
          "graph_entropy": "max",
          "instability": "min"
        },
        "composite_metrics": [
          {
            "name": "ppl_per_long_recall",
            "op": "ratio",
            "numerator": "ppl_code",
            "denominator": "long_recall",
            "terms": {},
            "epsilon": 0.1
          }
        ],
        "promotion_prob": 0.4,
        "promotion_min_layers": 8,
        "promotion_min_moe_blocks": 2,
        "promotion_steps_multiplier": 1.5,
        "promotion_tokens_multiplier": 1.5,
        "promotion_min_router_entropy": 0.0,
        "promotion_min_recurrence_gain": 0.0,
        "promotion_max_instability": null
      },
      "priors": {
        "tokens_per_param": 4.0,
        "window_scale": 6.0,
        "rope_theta_default": 10000.0,
        "prior_weight": 0.0,
        "compute_penalty_weight": 0.0
      }
    }
  },
  {
    "id": "xover-3-e120",
    "parent": null,
    "metrics": {
      "layers": 5.0,
      "moe_blocks": 2.0,
      "graph_entropy": 2.377076747431871,
      "selector_blocks": 0.0,
      "selector_topk_avg": 0.0,
      "memory_blocks": 3.0,
      "recurrences": 0.0,
      "novelty": 1.0588235294117647,
      "params": 146832497.0,
      "kv_bytes_per_token": 5120,
      "throughput_proxy": 152.587890625,
      "ppl_code": 1.0,
      "ppl_math": 1.02,
      "throughput": 534.2130381599293,
      "ram": 0.27349683828651905,
      "long_recall": 0.8,
      "router_entropy": 0.688422441482544,
      "router_lb": 0.025782525539398193,
      "router_load_max": 0.48828125,
      "router_load_min": 0.0,
      "router_load_cv": 2.6564524173736572,
      "capacity_overflow": 0.0,
      "max_grad_norm": 0.0,
      "instability": 0.0,
      "stop_reason_code": 3.0,
      "nan_seen": 0.0,
      "loss_spike": 2.551870420575142e-05,
      "prior_distance": 0.06071277496034261,
      "ppl_per_long_recall": 1.25,
      "ppl_per_param": 6.8104814699160225e-09,
      "ppl_per_throughput": 0.0018719123805821945
    },
    "spec": {
      "model": {
        "name": "phi-tiny-evo-creative",
        "emb": {
          "dim": 512,
          "vocab": 50257,
          "rope": null,
          "dropout": 0.0
        },
        "blocks": [
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": "yarn",
              "rope_theta": null,
              "sw": 128,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "local_global",
              "block_size": null,
              "block_stride": null,
              "global_stride": 64,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": null,
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 256,
                "stride": 32,
                "aggregator": "gate",
                "gating_weight": 0.25
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "moe",
              "hidden": 2048,
              "n_experts": 16,
              "k": 2,
              "capacity_factor": 1.2,
              "balance": 0.05,
              "shared": 1,
              "router_temperature": null,
              "router_type": "softmax",
              "router_bias_detached": false,
              "shared_expert": false,
              "router_aux_weight": null,
              "router_lb_weight": null,
              "drop_policy": "none",
              "experts": []
            },
            "ssm": null,
            "extras": [
              {
                "type": "custom",
                "name": "exp-gater",
                "params": {
                  "dim": 256
                }
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "moe",
              "hidden": 2048,
              "n_experts": 16,
              "k": 2,
              "capacity_factor": 1.2,
              "balance": 0.05,
              "shared": 1,
              "router_temperature": null,
              "router_type": "softmax",
              "router_bias_detached": false,
              "shared_expert": false,
              "router_aux_weight": null,
              "router_lb_weight": null,
              "drop_policy": "none",
              "experts": []
            },
            "ssm": null,
            "extras": [
              {
                "type": "custom",
                "name": "exp-gater",
                "params": {
                  "dim": 256
                }
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": null,
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 1024,
                "stride": 64,
                "aggregator": "gate",
                "gating_weight": 0.35
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": null,
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 1024,
                "stride": 64,
                "aggregator": "gate",
                "gating_weight": 0.35
              }
            ]
          }
        ],
        "head": {
          "tie_embeddings": true,
          "vocab": 50257
        },
        "norm": "layernorm",
        "recurrences": []
      },
      "train": {
        "lr": 0.0008,
        "warmup": 500,
        "clip": 1.0,
        "bf16": true,
        "grad_checkpoint": true,
        "max_tokens": 520000,
        "weight_decay": 0.02,
        "seed": 4242,
        "router_lb_coeff": 0.01,
        "router_entropy_coeff": 0.005,
        "entropy_threshold": 0.5,
        "entropy_patience": 3,
        "instability_threshold": 500.0,
        "no_improve_patience": 20,
        "improvement_tolerance": 0.001,
        "ppl_stop_threshold": null,
        "init_checkpoint": null,
        "optimizer": {
          "name": "adamw",
          "lr": null,
          "betas": null,
          "eps": null,
          "weight_decay": null
        }
      },
      "data": {
        "tokenizer": "gpt2",
        "hf_revision": "main",
        "seq_len": 512,
        "batch_size": 1,
        "workers": 0,
        "shards": [
          {
            "name": "ag_news",
            "split": "train",
            "weight": 0.25,
            "cache_path": null,
            "revision": null
          },
          {
            "name": "wikitext",
            "split": "wikitext-2-raw-v1",
            "weight": 0.35,
            "cache_path": null,
            "revision": null
          },
          {
            "name": "mbpp",
            "split": "train",
            "weight": 0.4,
            "cache_path": null,
            "revision": null
          }
        ],
        "healing_shards": [],
        "healing_tokens": null
      },
      "evolution": {
        "rung0_thresholds": {
          "gate_entropy_min": 0.0,
          "gate_entropy_max": 4.0
        },
        "rung1_tokens": 300000,
        "rung2_tokens": 900000,
        "population": 24,
        "topk_keep": 0.45,
        "crossover_prob": 0.5,
        "parent_selection": "lexicase",
        "pareto_objectives": [
          "ppl_code",
          "ppl_math",
          "long_recall",
          "ppl_per_long_recall",
          "throughput",
          "ram",
          "novelty",
          "graph_entropy"
        ],
        "objectives": {
          "ppl_code": "min",
          "ppl_math": "min",
          "long_recall": "max",
          "ppl_per_long_recall": "min",
          "throughput": "max",
          "ram": "min",
          "novelty": "max",
          "graph_entropy": "max",
          "instability": "min"
        },
        "composite_metrics": [
          {
            "name": "ppl_per_long_recall",
            "op": "ratio",
            "numerator": "ppl_code",
            "denominator": "long_recall",
            "terms": {},
            "epsilon": 0.1
          }
        ],
        "promotion_prob": 0.4,
        "promotion_min_layers": 8,
        "promotion_min_moe_blocks": 2,
        "promotion_steps_multiplier": 1.5,
        "promotion_tokens_multiplier": 1.5,
        "promotion_min_router_entropy": 0.0,
        "promotion_min_recurrence_gain": 0.0,
        "promotion_max_instability": null
      },
      "priors": {
        "tokens_per_param": 4.0,
        "window_scale": 6.0,
        "rope_theta_default": 10000.0,
        "prior_weight": 0.0,
        "compute_penalty_weight": 0.0
      }
    }
  },
  {
    "id": "shuffle_block_span-6-db95",
    "parent": "seed-1-f3a5",
    "metrics": {
      "layers": 12.0,
      "moe_blocks": 5.0,
      "graph_entropy": 2.6880533617977047,
      "selector_blocks": 0.0,
      "selector_topk_avg": 0.0,
      "memory_blocks": 7.0,
      "recurrences": 0.0,
      "novelty": 0.0,
      "params": 325965315.0,
      "kv_bytes_per_token": 12288,
      "throughput_proxy": 26.490953233506943,
      "ppl_code": 1.0,
      "ppl_math": 1.05,
      "throughput": 345.109200950632,
      "ram": 0.6071577128022909,
      "long_recall": 1.0083333333333333,
      "router_entropy": 0.688246238231659,
      "router_lb": 0.02484424151480198,
      "router_load_max": 0.4931640625,
      "router_load_min": 0.0,
      "router_load_cv": 2.6838881969451904,
      "capacity_overflow": 0.0,
      "max_grad_norm": 0.0,
      "instability": 0.0,
      "stop_reason_code": 3.0,
      "nan_seen": 0.0,
      "loss_spike": 4.7789886593818665e-05,
      "prior_distance": 0.025563275517486335,
      "ppl_per_long_recall": 0.9917355371900827,
      "ppl_per_param": 3.067811064499301e-09,
      "ppl_per_throughput": 0.002897633552641937
    },
    "spec": {
      "model": {
        "name": "phi-tiny-evo-creative",
        "emb": {
          "dim": 512,
          "vocab": 50257,
          "rope": null,
          "dropout": 0.0
        },
        "blocks": [
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": "yarn",
              "rope_theta": null,
              "sw": 128,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "local_global",
              "block_size": null,
              "block_stride": null,
              "global_stride": 64,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": null,
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 256,
                "stride": 32,
                "aggregator": "gate",
                "gating_weight": 0.25
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "moe",
              "hidden": 2048,
              "n_experts": 16,
              "k": 2,
              "capacity_factor": 1.2,
              "balance": 0.05,
              "shared": 1,
              "router_temperature": null,
              "router_type": "softmax",
              "router_bias_detached": false,
              "shared_expert": false,
              "router_aux_weight": null,
              "router_lb_weight": null,
              "drop_policy": "none",
              "experts": []
            },
            "ssm": null,
            "extras": [
              {
                "type": "custom",
                "name": "exp-gater",
                "params": {
                  "dim": 256
                }
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "moe",
              "hidden": 2048,
              "n_experts": 16,
              "k": 2,
              "capacity_factor": 1.2,
              "balance": 0.05,
              "shared": 1,
              "router_temperature": null,
              "router_type": "softmax",
              "router_bias_detached": false,
              "shared_expert": false,
              "router_aux_weight": null,
              "router_lb_weight": null,
              "drop_policy": "none",
              "experts": []
            },
            "ssm": null,
            "extras": [
              {
                "type": "custom",
                "name": "exp-gater",
                "params": {
                  "dim": 256
                }
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": {
              "kind": "mamba2",
              "d_state": 16,
              "d_conv": 4,
              "dt_rank": 8,
              "chunk": 128,
              "gate": 0.15
            },
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 512,
                "stride": 128,
                "aggregator": "attention",
                "gating_weight": 0.1191520977835257
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "moe",
              "hidden": 2048,
              "n_experts": 16,
              "k": 2,
              "capacity_factor": 1.2,
              "balance": 0.05,
              "shared": 1,
              "router_temperature": null,
              "router_type": "softmax",
              "router_bias_detached": false,
              "shared_expert": false,
              "router_aux_weight": null,
              "router_lb_weight": null,
              "drop_policy": "none",
              "experts": []
            },
            "ssm": null,
            "extras": [
              {
                "type": "custom",
                "name": "exp-gater",
                "params": {
                  "dim": 256
                }
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": {
              "kind": "mamba2",
              "d_state": 16,
              "d_conv": 4,
              "dt_rank": 8,
              "chunk": 128,
              "gate": 0.15
            },
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 512,
                "stride": 128,
                "aggregator": "attention",
                "gating_weight": 0.1191520977835257
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": "yarn",
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "moe",
              "hidden": 2048,
              "n_experts": 16,
              "k": 2,
              "capacity_factor": 1.2,
              "balance": 0.05,
              "shared": 1,
              "router_temperature": null,
              "router_type": "softmax",
              "router_bias_detached": false,
              "shared_expert": false,
              "router_aux_weight": null,
              "router_lb_weight": null,
              "drop_policy": "none",
              "experts": []
            },
            "ssm": null,
            "extras": [
              {
                "type": "gated",
                "targets": [
                  "attn",
                  "ffn",
                  "ssm"
                ],
                "init_weight": 0.2,
                "learnable": true
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": null,
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 1024,
                "stride": 64,
                "aggregator": "gate",
                "gating_weight": 0.35
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": {
              "kind": "mamba2",
              "d_state": 16,
              "d_conv": 4,
              "dt_rank": 8,
              "chunk": 128,
              "gate": 0.15
            },
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 512,
                "stride": 128,
                "aggregator": "attention",
                "gating_weight": 0.1191520977835257
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": "yarn",
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "moe",
              "hidden": 2048,
              "n_experts": 16,
              "k": 2,
              "capacity_factor": 1.2,
              "balance": 0.05,
              "shared": 1,
              "router_temperature": null,
              "router_type": "softmax",
              "router_bias_detached": false,
              "shared_expert": false,
              "router_aux_weight": null,
              "router_lb_weight": null,
              "drop_policy": "none",
              "experts": []
            },
            "ssm": null,
            "extras": [
              {
                "type": "gated",
                "targets": [
                  "attn",
                  "ffn",
                  "ssm"
                ],
                "init_weight": 0.2,
                "learnable": true
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": null,
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 1024,
                "stride": 64,
                "aggregator": "gate",
                "gating_weight": 0.35
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": null,
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 1024,
                "stride": 64,
                "aggregator": "gate",
                "gating_weight": 0.35
              }
            ]
          }
        ],
        "head": {
          "tie_embeddings": true,
          "vocab": 50257
        },
        "norm": "layernorm",
        "recurrences": []
      },
      "train": {
        "lr": 0.0008,
        "warmup": 500,
        "clip": 1.0,
        "bf16": true,
        "grad_checkpoint": true,
        "max_tokens": 520000,
        "weight_decay": 0.02,
        "seed": 4242,
        "router_lb_coeff": 0.01,
        "router_entropy_coeff": 0.005,
        "entropy_threshold": 0.5,
        "entropy_patience": 3,
        "instability_threshold": 500.0,
        "no_improve_patience": 20,
        "improvement_tolerance": 0.001,
        "ppl_stop_threshold": null,
        "init_checkpoint": null,
        "optimizer": {
          "name": "adamw",
          "lr": null,
          "betas": null,
          "eps": null,
          "weight_decay": null
        }
      },
      "data": {
        "tokenizer": "gpt2",
        "hf_revision": "main",
        "seq_len": 512,
        "batch_size": 1,
        "workers": 0,
        "shards": [
          {
            "name": "ag_news",
            "split": "train",
            "weight": 0.25,
            "cache_path": null,
            "revision": null
          },
          {
            "name": "wikitext",
            "split": "wikitext-2-raw-v1",
            "weight": 0.35,
            "cache_path": null,
            "revision": null
          },
          {
            "name": "mbpp",
            "split": "train",
            "weight": 0.4,
            "cache_path": null,
            "revision": null
          }
        ],
        "healing_shards": [],
        "healing_tokens": null
      },
      "evolution": {
        "rung0_thresholds": {
          "gate_entropy_min": 0.0,
          "gate_entropy_max": 4.0
        },
        "rung1_tokens": 300000,
        "rung2_tokens": 900000,
        "population": 24,
        "topk_keep": 0.45,
        "crossover_prob": 0.5,
        "parent_selection": "lexicase",
        "pareto_objectives": [
          "ppl_code",
          "ppl_math",
          "long_recall",
          "ppl_per_long_recall",
          "throughput",
          "ram",
          "novelty",
          "graph_entropy"
        ],
        "objectives": {
          "ppl_code": "min",
          "ppl_math": "min",
          "long_recall": "max",
          "ppl_per_long_recall": "min",
          "throughput": "max",
          "ram": "min",
          "novelty": "max",
          "graph_entropy": "max",
          "instability": "min"
        },
        "composite_metrics": [
          {
            "name": "ppl_per_long_recall",
            "op": "ratio",
            "numerator": "ppl_code",
            "denominator": "long_recall",
            "terms": {},
            "epsilon": 0.1
          }
        ],
        "promotion_prob": 0.4,
        "promotion_min_layers": 8,
        "promotion_min_moe_blocks": 2,
        "promotion_steps_multiplier": 1.5,
        "promotion_tokens_multiplier": 1.5,
        "promotion_min_router_entropy": 0.0,
        "promotion_min_recurrence_gain": 0.0,
        "promotion_max_instability": null
      },
      "priors": {
        "tokens_per_param": 4.0,
        "window_scale": 6.0,
        "rope_theta_default": 10000.0,
        "prior_weight": 0.0,
        "compute_penalty_weight": 0.0
      }
    }
  },
  {
    "id": "xover-7-091d",
    "parent": null,
    "metrics": {
      "layers": 1.0,
      "moe_blocks": 0.0,
      "graph_entropy": 1.655609079175885,
      "selector_blocks": 0.0,
      "selector_topk_avg": 0.0,
      "memory_blocks": 1.0,
      "recurrences": 0.0,
      "novelty": 1.6923076923076923,
      "params": 29722193.0,
      "kv_bytes_per_token": 1024,
      "throughput_proxy": 3814.697265625,
      "ppl_code": 1.0,
      "ppl_math": 1.0,
      "throughput": 1074.857286267665,
      "ram": 0.055361898615956306,
      "long_recall": 1.1,
      "router_entropy": 0.0,
      "router_lb": 0.0,
      "router_load_max": 0.0,
      "router_load_min": 0.0,
      "router_load_cv": 0.0,
      "capacity_overflow": 0.0,
      "max_grad_norm": 0.0,
      "instability": 0.0,
      "stop_reason_code": 3.0,
      "nan_seen": 0.0,
      "loss_spike": 0.0,
      "prior_distance": 0.24285100877225355,
      "ppl_per_long_recall": 0.9090909090909091,
      "ppl_per_param": 3.364489289198815e-08,
      "ppl_per_throughput": 0.0009303560693833138
    },
    "spec": {
      "model": {
        "name": "phi-tiny-evo-creative",
        "emb": {
          "dim": 512,
          "vocab": 50257,
          "rope": null,
          "dropout": 0.0
        },
        "blocks": [
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": "yarn",
              "rope_theta": null,
              "sw": 128,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "local_global",
              "block_size": null,
              "block_stride": null,
              "global_stride": 64,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": null,
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 256,
                "stride": 32,
                "aggregator": "gate",
                "gating_weight": 0.25
              }
            ]
          }
        ],
        "head": {
          "tie_embeddings": true,
          "vocab": 50257
        },
        "norm": "layernorm",
        "recurrences": []
      },
      "train": {
        "lr": 0.0008,
        "warmup": 500,
        "clip": 1.0,
        "bf16": true,
        "grad_checkpoint": true,
        "max_tokens": 520000,
        "weight_decay": 0.02,
        "seed": 4242,
        "router_lb_coeff": 0.01,
        "router_entropy_coeff": 0.005,
        "entropy_threshold": 0.5,
        "entropy_patience": 3,
        "instability_threshold": 500.0,
        "no_improve_patience": 20,
        "improvement_tolerance": 0.001,
        "ppl_stop_threshold": null,
        "init_checkpoint": null,
        "optimizer": {
          "name": "adamw",
          "lr": null,
          "betas": null,
          "eps": null,
          "weight_decay": null
        }
      },
      "data": {
        "tokenizer": "gpt2",
        "hf_revision": "main",
        "seq_len": 512,
        "batch_size": 1,
        "workers": 0,
        "shards": [
          {
            "name": "ag_news",
            "split": "train",
            "weight": 0.25,
            "cache_path": null,
            "revision": null
          },
          {
            "name": "wikitext",
            "split": "wikitext-2-raw-v1",
            "weight": 0.35,
            "cache_path": null,
            "revision": null
          },
          {
            "name": "mbpp",
            "split": "train",
            "weight": 0.4,
            "cache_path": null,
            "revision": null
          }
        ],
        "healing_shards": [],
        "healing_tokens": null
      },
      "evolution": {
        "rung0_thresholds": {
          "gate_entropy_min": 0.0,
          "gate_entropy_max": 4.0
        },
        "rung1_tokens": 300000,
        "rung2_tokens": 900000,
        "population": 24,
        "topk_keep": 0.45,
        "crossover_prob": 0.5,
        "parent_selection": "lexicase",
        "pareto_objectives": [
          "ppl_code",
          "ppl_math",
          "long_recall",
          "ppl_per_long_recall",
          "throughput",
          "ram",
          "novelty",
          "graph_entropy"
        ],
        "objectives": {
          "ppl_code": "min",
          "ppl_math": "min",
          "long_recall": "max",
          "ppl_per_long_recall": "min",
          "throughput": "max",
          "ram": "min",
          "novelty": "max",
          "graph_entropy": "max",
          "instability": "min"
        },
        "composite_metrics": [
          {
            "name": "ppl_per_long_recall",
            "op": "ratio",
            "numerator": "ppl_code",
            "denominator": "long_recall",
            "terms": {},
            "epsilon": 0.1
          }
        ],
        "promotion_prob": 0.4,
        "promotion_min_layers": 8,
        "promotion_min_moe_blocks": 2,
        "promotion_steps_multiplier": 1.5,
        "promotion_tokens_multiplier": 1.5,
        "promotion_min_router_entropy": 0.0,
        "promotion_min_recurrence_gain": 0.0,
        "promotion_max_instability": null
      },
      "priors": {
        "tokens_per_param": 4.0,
        "window_scale": 6.0,
        "rope_theta_default": 10000.0,
        "prior_weight": 0.0,
        "compute_penalty_weight": 0.0
      }
    }
  },
  {
    "id": "insert_custom_module-8-bfeb",
    "parent": "shift_moe-2-6cc6",
    "metrics": {
      "layers": 12.0,
      "moe_blocks": 5.0,
      "graph_entropy": 2.701720036658605,
      "selector_blocks": 0.0,
      "selector_topk_avg": 0.0,
      "memory_blocks": 7.0,
      "recurrences": 0.0,
      "novelty": 0.041666666666666664,
      "params": 327015427.0,
      "kv_bytes_per_token": 12288,
      "throughput_proxy": 26.490953233506943,
      "ppl_code": 1.0,
      "ppl_math": 1.05,
      "throughput": 327.86283713121077,
      "ram": 0.6091136988252401,
      "long_recall": 1.0083333333333333,
      "router_entropy": 0.6848662257194519,
      "router_lb": 0.02404768541455269,
      "router_load_max": 0.4970703125,
      "router_load_min": 0.0,
      "router_load_cv": 2.699084758758545,
      "capacity_overflow": 0.0,
      "max_grad_norm": 0.0,
      "instability": 0.0,
      "stop_reason_code": 3.0,
      "nan_seen": 0.0,
      "loss_spike": 5.317665636539459e-05,
      "prior_distance": 0.025563275517486335,
      "ppl_per_long_recall": 0.9917355371900827,
      "ppl_per_param": 3.0579597090384363e-09,
      "ppl_per_throughput": 0.0030500559586135703
    },
    "spec": {
      "model": {
        "name": "phi-tiny-evo-creative",
        "emb": {
          "dim": 512,
          "vocab": 50257,
          "rope": null,
          "dropout": 0.0
        },
        "blocks": [
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "moe",
              "hidden": 2048,
              "n_experts": 16,
              "k": 2,
              "capacity_factor": 1.2,
              "balance": 0.05,
              "shared": 1,
              "router_temperature": null,
              "router_type": "softmax",
              "router_bias_detached": false,
              "shared_expert": false,
              "router_aux_weight": null,
              "router_lb_weight": null,
              "drop_policy": "none",
              "experts": []
            },
            "ssm": null,
            "extras": [
              {
                "type": "custom",
                "name": "exp-gater",
                "params": {
                  "dim": 256
                }
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": "yarn",
              "rope_theta": null,
              "sw": 128,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "local_global",
              "block_size": null,
              "block_stride": null,
              "global_stride": 64,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": null,
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 256,
                "stride": 32,
                "aggregator": "gate",
                "gating_weight": 0.25
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "moe",
              "hidden": 2048,
              "n_experts": 16,
              "k": 2,
              "capacity_factor": 1.2,
              "balance": 0.05,
              "shared": 1,
              "router_temperature": null,
              "router_type": "softmax",
              "router_bias_detached": false,
              "shared_expert": false,
              "router_aux_weight": null,
              "router_lb_weight": null,
              "drop_policy": "none",
              "experts": []
            },
            "ssm": null,
            "extras": [
              {
                "type": "custom",
                "name": "exp-gater",
                "params": {
                  "dim": 256
                }
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": {
              "kind": "mamba2",
              "d_state": 16,
              "d_conv": 4,
              "dt_rank": 8,
              "chunk": 128,
              "gate": 0.15
            },
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 512,
                "stride": 128,
                "aggregator": "attention",
                "gating_weight": 0.1191520977835257
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "moe",
              "hidden": 2048,
              "n_experts": 16,
              "k": 2,
              "capacity_factor": 1.2,
              "balance": 0.05,
              "shared": 1,
              "router_temperature": null,
              "router_type": "softmax",
              "router_bias_detached": false,
              "shared_expert": false,
              "router_aux_weight": null,
              "router_lb_weight": null,
              "drop_policy": "none",
              "experts": []
            },
            "ssm": null,
            "extras": [
              {
                "type": "custom",
                "name": "exp-gater",
                "params": {
                  "dim": 256
                }
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": {
              "kind": "mamba2",
              "d_state": 16,
              "d_conv": 4,
              "dt_rank": 8,
              "chunk": 128,
              "gate": 0.15
            },
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 512,
                "stride": 128,
                "aggregator": "attention",
                "gating_weight": 0.1191520977835257
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": "yarn",
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "moe",
              "hidden": 2048,
              "n_experts": 16,
              "k": 2,
              "capacity_factor": 1.2,
              "balance": 0.05,
              "shared": 1,
              "router_temperature": null,
              "router_type": "softmax",
              "router_bias_detached": false,
              "shared_expert": false,
              "router_aux_weight": null,
              "router_lb_weight": null,
              "drop_policy": "none",
              "experts": []
            },
            "ssm": null,
            "extras": [
              {
                "type": "gated",
                "targets": [
                  "attn",
                  "ffn",
                  "ssm"
                ],
                "init_weight": 0.2,
                "learnable": true
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": null,
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 1024,
                "stride": 64,
                "aggregator": "gate",
                "gating_weight": 0.35
              },
              {
                "type": "custom",
                "name": "exp-4338",
                "params": {
                  "dim": 1024,
                  "activation": "relu",
                  "notes": "auto-generated"
                }
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": {
              "kind": "mamba2",
              "d_state": 16,
              "d_conv": 4,
              "dt_rank": 8,
              "chunk": 128,
              "gate": 0.15
            },
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 512,
                "stride": 128,
                "aggregator": "attention",
                "gating_weight": 0.1191520977835257
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": "yarn",
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "moe",
              "hidden": 2048,
              "n_experts": 16,
              "k": 2,
              "capacity_factor": 1.2,
              "balance": 0.05,
              "shared": 1,
              "router_temperature": null,
              "router_type": "softmax",
              "router_bias_detached": false,
              "shared_expert": false,
              "router_aux_weight": null,
              "router_lb_weight": null,
              "drop_policy": "none",
              "experts": []
            },
            "ssm": null,
            "extras": [
              {
                "type": "gated",
                "targets": [
                  "attn",
                  "ffn",
                  "ssm"
                ],
                "init_weight": 0.2,
                "learnable": true
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": null,
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 1024,
                "stride": 64,
                "aggregator": "gate",
                "gating_weight": 0.35
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": null,
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 1024,
                "stride": 64,
                "aggregator": "gate",
                "gating_weight": 0.35
              }
            ]
          }
        ],
        "head": {
          "tie_embeddings": true,
          "vocab": 50257
        },
        "norm": "layernorm",
        "recurrences": []
      },
      "train": {
        "lr": 0.0008,
        "warmup": 500,
        "clip": 1.0,
        "bf16": true,
        "grad_checkpoint": true,
        "max_tokens": 520000,
        "weight_decay": 0.02,
        "seed": 4242,
        "router_lb_coeff": 0.01,
        "router_entropy_coeff": 0.005,
        "entropy_threshold": 0.5,
        "entropy_patience": 3,
        "instability_threshold": 500.0,
        "no_improve_patience": 20,
        "improvement_tolerance": 0.001,
        "ppl_stop_threshold": null,
        "init_checkpoint": null,
        "optimizer": {
          "name": "adamw",
          "lr": null,
          "betas": null,
          "eps": null,
          "weight_decay": null
        }
      },
      "data": {
        "tokenizer": "gpt2",
        "hf_revision": "main",
        "seq_len": 512,
        "batch_size": 1,
        "workers": 0,
        "shards": [
          {
            "name": "ag_news",
            "split": "train",
            "weight": 0.25,
            "cache_path": null,
            "revision": null
          },
          {
            "name": "wikitext",
            "split": "wikitext-2-raw-v1",
            "weight": 0.35,
            "cache_path": null,
            "revision": null
          },
          {
            "name": "mbpp",
            "split": "train",
            "weight": 0.4,
            "cache_path": null,
            "revision": null
          }
        ],
        "healing_shards": [],
        "healing_tokens": null
      },
      "evolution": {
        "rung0_thresholds": {
          "gate_entropy_min": 0.0,
          "gate_entropy_max": 4.0
        },
        "rung1_tokens": 300000,
        "rung2_tokens": 900000,
        "population": 24,
        "topk_keep": 0.45,
        "crossover_prob": 0.5,
        "parent_selection": "lexicase",
        "pareto_objectives": [
          "ppl_code",
          "ppl_math",
          "long_recall",
          "ppl_per_long_recall",
          "throughput",
          "ram",
          "novelty",
          "graph_entropy"
        ],
        "objectives": {
          "ppl_code": "min",
          "ppl_math": "min",
          "long_recall": "max",
          "ppl_per_long_recall": "min",
          "throughput": "max",
          "ram": "min",
          "novelty": "max",
          "graph_entropy": "max",
          "instability": "min"
        },
        "composite_metrics": [
          {
            "name": "ppl_per_long_recall",
            "op": "ratio",
            "numerator": "ppl_code",
            "denominator": "long_recall",
            "terms": {},
            "epsilon": 0.1
          }
        ],
        "promotion_prob": 0.4,
        "promotion_min_layers": 8,
        "promotion_min_moe_blocks": 2,
        "promotion_steps_multiplier": 1.5,
        "promotion_tokens_multiplier": 1.5,
        "promotion_min_router_entropy": 0.0,
        "promotion_min_recurrence_gain": 0.0,
        "promotion_max_instability": null
      },
      "priors": {
        "tokens_per_param": 4.0,
        "window_scale": 6.0,
        "rope_theta_default": 10000.0,
        "prior_weight": 0.0,
        "compute_penalty_weight": 0.0
      }
    }
  },
  {
    "id": "xover-9-7f06",
    "parent": null,
    "metrics": {
      "layers": 13.0,
      "moe_blocks": 5.0,
      "graph_entropy": 2.690886274676896,
      "selector_blocks": 0.0,
      "selector_topk_avg": 0.0,
      "memory_blocks": 8.0,
      "recurrences": 0.0,
      "novelty": 0.52,
      "params": 330954755.0,
      "kv_bytes_per_token": 13312,
      "throughput_proxy": 22.572173169378697,
      "ppl_code": 1.0,
      "ppl_math": 1.05,
      "throughput": 331.23805870187624,
      "ram": 0.6164512690156698,
      "long_recall": 1.0307692307692307,
      "router_entropy": 0.6842429280281067,
      "router_lb": 0.022513151168823242,
      "router_load_max": 0.4677734375,
      "router_load_min": 0.0,
      "router_load_cv": 2.5045790672302246,
      "capacity_overflow": 0.0,
      "max_grad_norm": 0.0,
      "instability": 0.0,
      "stop_reason_code": 3.0,
      "nan_seen": 0.0,
      "loss_spike": 0.0,
      "prior_distance": 0.02312867796508752,
      "ppl_per_long_recall": 0.9701492537313434,
      "ppl_per_param": 3.0215610590033675e-09,
      "ppl_per_throughput": 0.0030189767562308675
    },
    "spec": {
      "model": {
        "name": "phi-tiny-evo-creative",
        "emb": {
          "dim": 512,
          "vocab": 50257,
          "rope": null,
          "dropout": 0.0
        },
        "blocks": [
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "moe",
              "hidden": 2048,
              "n_experts": 16,
              "k": 2,
              "capacity_factor": 1.2,
              "balance": 0.05,
              "shared": 1,
              "router_temperature": null,
              "router_type": "softmax",
              "router_bias_detached": false,
              "shared_expert": false,
              "router_aux_weight": null,
              "router_lb_weight": null,
              "drop_policy": "none",
              "experts": []
            },
            "ssm": null,
            "extras": [
              {
                "type": "custom",
                "name": "exp-gater",
                "params": {
                  "dim": 256
                }
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": "yarn",
              "rope_theta": null,
              "sw": 128,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "local_global",
              "block_size": null,
              "block_stride": null,
              "global_stride": 64,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": null,
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 256,
                "stride": 32,
                "aggregator": "gate",
                "gating_weight": 0.25
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "moe",
              "hidden": 2048,
              "n_experts": 16,
              "k": 2,
              "capacity_factor": 1.2,
              "balance": 0.05,
              "shared": 1,
              "router_temperature": null,
              "router_type": "softmax",
              "router_bias_detached": false,
              "shared_expert": false,
              "router_aux_weight": null,
              "router_lb_weight": null,
              "drop_policy": "none",
              "experts": []
            },
            "ssm": null,
            "extras": [
              {
                "type": "custom",
                "name": "exp-gater",
                "params": {
                  "dim": 256
                }
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": {
              "kind": "mamba2",
              "d_state": 16,
              "d_conv": 4,
              "dt_rank": 8,
              "chunk": 128,
              "gate": 0.15
            },
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 512,
                "stride": 128,
                "aggregator": "attention",
                "gating_weight": 0.1191520977835257
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "moe",
              "hidden": 2048,
              "n_experts": 16,
              "k": 2,
              "capacity_factor": 1.2,
              "balance": 0.05,
              "shared": 1,
              "router_temperature": null,
              "router_type": "softmax",
              "router_bias_detached": false,
              "shared_expert": false,
              "router_aux_weight": null,
              "router_lb_weight": null,
              "drop_policy": "none",
              "experts": []
            },
            "ssm": null,
            "extras": [
              {
                "type": "custom",
                "name": "exp-gater",
                "params": {
                  "dim": 256
                }
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": {
              "kind": "mamba2",
              "d_state": 16,
              "d_conv": 4,
              "dt_rank": 8,
              "chunk": 128,
              "gate": 0.15
            },
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 512,
                "stride": 128,
                "aggregator": "attention",
                "gating_weight": 0.1191520977835257
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": "yarn",
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "moe",
              "hidden": 2048,
              "n_experts": 16,
              "k": 2,
              "capacity_factor": 1.2,
              "balance": 0.05,
              "shared": 1,
              "router_temperature": null,
              "router_type": "softmax",
              "router_bias_detached": false,
              "shared_expert": false,
              "router_aux_weight": null,
              "router_lb_weight": null,
              "drop_policy": "none",
              "experts": []
            },
            "ssm": null,
            "extras": [
              {
                "type": "gated",
                "targets": [
                  "attn",
                  "ffn",
                  "ssm"
                ],
                "init_weight": 0.2,
                "learnable": true
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": null,
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 1024,
                "stride": 64,
                "aggregator": "gate",
                "gating_weight": 0.35
              },
              {
                "type": "custom",
                "name": "exp-4338",
                "params": {
                  "dim": 1024,
                  "activation": "relu",
                  "notes": "auto-generated"
                }
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": {
              "kind": "mamba2",
              "d_state": 16,
              "d_conv": 4,
              "dt_rank": 8,
              "chunk": 128,
              "gate": 0.15
            },
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 512,
                "stride": 128,
                "aggregator": "attention",
                "gating_weight": 0.1191520977835257
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": "yarn",
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "moe",
              "hidden": 2048,
              "n_experts": 16,
              "k": 2,
              "capacity_factor": 1.2,
              "balance": 0.05,
              "shared": 1,
              "router_temperature": null,
              "router_type": "softmax",
              "router_bias_detached": false,
              "shared_expert": false,
              "router_aux_weight": null,
              "router_lb_weight": null,
              "drop_policy": "none",
              "experts": []
            },
            "ssm": null,
            "extras": [
              {
                "type": "gated",
                "targets": [
                  "attn",
                  "ffn",
                  "ssm"
                ],
                "init_weight": 0.2,
                "learnable": true
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": null,
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 1024,
                "stride": 64,
                "aggregator": "gate",
                "gating_weight": 0.35
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": null,
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 1024,
                "stride": 64,
                "aggregator": "gate",
                "gating_weight": 0.35
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": null,
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 1024,
                "stride": 64,
                "aggregator": "gate",
                "gating_weight": 0.35
              }
            ]
          }
        ],
        "head": {
          "tie_embeddings": true,
          "vocab": 50257
        },
        "norm": "layernorm",
        "recurrences": []
      },
      "train": {
        "lr": 0.0008,
        "warmup": 500,
        "clip": 1.0,
        "bf16": true,
        "grad_checkpoint": true,
        "max_tokens": 520000,
        "weight_decay": 0.02,
        "seed": 4242,
        "router_lb_coeff": 0.01,
        "router_entropy_coeff": 0.005,
        "entropy_threshold": 0.5,
        "entropy_patience": 3,
        "instability_threshold": 500.0,
        "no_improve_patience": 20,
        "improvement_tolerance": 0.001,
        "ppl_stop_threshold": null,
        "init_checkpoint": null,
        "optimizer": {
          "name": "adamw",
          "lr": null,
          "betas": null,
          "eps": null,
          "weight_decay": null
        }
      },
      "data": {
        "tokenizer": "gpt2",
        "hf_revision": "main",
        "seq_len": 512,
        "batch_size": 1,
        "workers": 0,
        "shards": [
          {
            "name": "ag_news",
            "split": "train",
            "weight": 0.25,
            "cache_path": null,
            "revision": null
          },
          {
            "name": "wikitext",
            "split": "wikitext-2-raw-v1",
            "weight": 0.35,
            "cache_path": null,
            "revision": null
          },
          {
            "name": "mbpp",
            "split": "train",
            "weight": 0.4,
            "cache_path": null,
            "revision": null
          }
        ],
        "healing_shards": [],
        "healing_tokens": null
      },
      "evolution": {
        "rung0_thresholds": {
          "gate_entropy_min": 0.0,
          "gate_entropy_max": 4.0
        },
        "rung1_tokens": 300000,
        "rung2_tokens": 900000,
        "population": 24,
        "topk_keep": 0.45,
        "crossover_prob": 0.5,
        "parent_selection": "lexicase",
        "pareto_objectives": [
          "ppl_code",
          "ppl_math",
          "long_recall",
          "ppl_per_long_recall",
          "throughput",
          "ram",
          "novelty",
          "graph_entropy"
        ],
        "objectives": {
          "ppl_code": "min",
          "ppl_math": "min",
          "long_recall": "max",
          "ppl_per_long_recall": "min",
          "throughput": "max",
          "ram": "min",
          "novelty": "max",
          "graph_entropy": "max",
          "instability": "min"
        },
        "composite_metrics": [
          {
            "name": "ppl_per_long_recall",
            "op": "ratio",
            "numerator": "ppl_code",
            "denominator": "long_recall",
            "terms": {},
            "epsilon": 0.1
          }
        ],
        "promotion_prob": 0.4,
        "promotion_min_layers": 8,
        "promotion_min_moe_blocks": 2,
        "promotion_steps_multiplier": 1.5,
        "promotion_tokens_multiplier": 1.5,
        "promotion_min_router_entropy": 0.0,
        "promotion_min_recurrence_gain": 0.0,
        "promotion_max_instability": null
      },
      "priors": {
        "tokens_per_param": 4.0,
        "window_scale": 6.0,
        "rope_theta_default": 10000.0,
        "prior_weight": 0.0,
        "compute_penalty_weight": 0.0
      }
    }
  },
  {
    "id": "xover-10-ebf8",
    "parent": null,
    "metrics": {
      "layers": 22.0,
      "moe_blocks": 9.0,
      "graph_entropy": 2.7614908461268786,
      "selector_blocks": 0.0,
      "selector_topk_avg": 0.0,
      "memory_blocks": 13.0,
      "recurrences": 0.0,
      "novelty": 0.7352941176470589,
      "params": 568642725.0,
      "kv_bytes_per_token": 22528,
      "throughput_proxy": 7.8816059207128095,
      "ppl_code": 1.0,
      "ppl_math": 1.09,
      "throughput": 207.54857132800362,
      "ram": 1.059179613366723,
      "long_recall": 1.0272727272727273,
      "router_entropy": 0.6902990076276991,
      "router_lb": 0.026351969689130783,
      "router_load_max": 0.5,
      "router_load_min": 0.0,
      "router_load_cv": 2.7294747829437256,
      "capacity_overflow": 0.0,
      "max_grad_norm": 0.0,
      "instability": 0.0,
      "stop_reason_code": 3.0,
      "nan_seen": 0.0,
      "loss_spike": 6.987713277339935e-05,
      "prior_distance": 0.027754414086760507,
      "ppl_per_long_recall": 0.9734513274336283,
      "ppl_per_param": 1.7585734522498288e-09,
      "ppl_per_throughput": 0.004818149282365474
    },
    "spec": {
      "model": {
        "name": "phi-tiny-evo-creative",
        "emb": {
          "dim": 512,
          "vocab": 50257,
          "rope": null,
          "dropout": 0.0
        },
        "blocks": [
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": "yarn",
              "rope_theta": null,
              "sw": 128,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "local_global",
              "block_size": null,
              "block_stride": null,
              "global_stride": 64,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": null,
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 256,
                "stride": 32,
                "aggregator": "gate",
                "gating_weight": 0.25
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "moe",
              "hidden": 2048,
              "n_experts": 16,
              "k": 2,
              "capacity_factor": 1.2,
              "balance": 0.05,
              "shared": 1,
              "router_temperature": null,
              "router_type": "softmax",
              "router_bias_detached": false,
              "shared_expert": false,
              "router_aux_weight": null,
              "router_lb_weight": null,
              "drop_policy": "none",
              "experts": []
            },
            "ssm": null,
            "extras": [
              {
                "type": "custom",
                "name": "exp-gater",
                "params": {
                  "dim": 256
                }
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "moe",
              "hidden": 2048,
              "n_experts": 16,
              "k": 2,
              "capacity_factor": 1.2,
              "balance": 0.05,
              "shared": 1,
              "router_temperature": null,
              "router_type": "softmax",
              "router_bias_detached": false,
              "shared_expert": false,
              "router_aux_weight": null,
              "router_lb_weight": null,
              "drop_policy": "none",
              "experts": []
            },
            "ssm": null,
            "extras": [
              {
                "type": "custom",
                "name": "exp-gater",
                "params": {
                  "dim": 256
                }
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": {
              "kind": "mamba2",
              "d_state": 16,
              "d_conv": 4,
              "dt_rank": 8,
              "chunk": 128,
              "gate": 0.15
            },
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 512,
                "stride": 128,
                "aggregator": "attention",
                "gating_weight": 0.1191520977835257
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "moe",
              "hidden": 2048,
              "n_experts": 16,
              "k": 2,
              "capacity_factor": 1.2,
              "balance": 0.05,
              "shared": 1,
              "router_temperature": null,
              "router_type": "softmax",
              "router_bias_detached": false,
              "shared_expert": false,
              "router_aux_weight": null,
              "router_lb_weight": null,
              "drop_policy": "none",
              "experts": []
            },
            "ssm": null,
            "extras": [
              {
                "type": "custom",
                "name": "exp-gater",
                "params": {
                  "dim": 256
                }
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": {
              "kind": "mamba2",
              "d_state": 16,
              "d_conv": 4,
              "dt_rank": 8,
              "chunk": 128,
              "gate": 0.15
            },
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 512,
                "stride": 128,
                "aggregator": "attention",
                "gating_weight": 0.1191520977835257
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": "yarn",
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "moe",
              "hidden": 2048,
              "n_experts": 16,
              "k": 2,
              "capacity_factor": 1.2,
              "balance": 0.05,
              "shared": 1,
              "router_temperature": null,
              "router_type": "softmax",
              "router_bias_detached": false,
              "shared_expert": false,
              "router_aux_weight": null,
              "router_lb_weight": null,
              "drop_policy": "none",
              "experts": []
            },
            "ssm": null,
            "extras": [
              {
                "type": "gated",
                "targets": [
                  "attn",
                  "ffn",
                  "ssm"
                ],
                "init_weight": 0.2,
                "learnable": true
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": null,
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 1024,
                "stride": 64,
                "aggregator": "gate",
                "gating_weight": 0.35
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": {
              "kind": "mamba2",
              "d_state": 16,
              "d_conv": 4,
              "dt_rank": 8,
              "chunk": 128,
              "gate": 0.15
            },
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 512,
                "stride": 128,
                "aggregator": "attention",
                "gating_weight": 0.1191520977835257
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": "yarn",
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "moe",
              "hidden": 2048,
              "n_experts": 16,
              "k": 2,
              "capacity_factor": 1.2,
              "balance": 0.05,
              "shared": 1,
              "router_temperature": null,
              "router_type": "softmax",
              "router_bias_detached": false,
              "shared_expert": false,
              "router_aux_weight": null,
              "router_lb_weight": null,
              "drop_policy": "none",
              "experts": []
            },
            "ssm": null,
            "extras": [
              {
                "type": "gated",
                "targets": [
                  "attn",
                  "ffn",
                  "ssm"
                ],
                "init_weight": 0.2,
                "learnable": true
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": "yarn",
              "rope_theta": null,
              "sw": 128,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "local_global",
              "block_size": null,
              "block_stride": null,
              "global_stride": 64,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": null,
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 256,
                "stride": 32,
                "aggregator": "gate",
                "gating_weight": 0.25
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "moe",
              "hidden": 2048,
              "n_experts": 16,
              "k": 2,
              "capacity_factor": 1.2,
              "balance": 0.05,
              "shared": 1,
              "router_temperature": null,
              "router_type": "softmax",
              "router_bias_detached": false,
              "shared_expert": false,
              "router_aux_weight": null,
              "router_lb_weight": null,
              "drop_policy": "none",
              "experts": []
            },
            "ssm": null,
            "extras": [
              {
                "type": "custom",
                "name": "exp-gater",
                "params": {
                  "dim": 256
                }
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": {
              "kind": "mamba2",
              "d_state": 16,
              "d_conv": 4,
              "dt_rank": 8,
              "chunk": 128,
              "gate": 0.15
            },
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 512,
                "stride": 128,
                "aggregator": "attention",
                "gating_weight": 0.1191520977835257
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "moe",
              "hidden": 2048,
              "n_experts": 16,
              "k": 2,
              "capacity_factor": 1.2,
              "balance": 0.05,
              "shared": 1,
              "router_temperature": null,
              "router_type": "softmax",
              "router_bias_detached": false,
              "shared_expert": false,
              "router_aux_weight": null,
              "router_lb_weight": null,
              "drop_policy": "none",
              "experts": []
            },
            "ssm": null,
            "extras": [
              {
                "type": "custom",
                "name": "exp-gater",
                "params": {
                  "dim": 256
                }
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": {
              "kind": "mamba2",
              "d_state": 16,
              "d_conv": 4,
              "dt_rank": 8,
              "chunk": 128,
              "gate": 0.15
            },
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 512,
                "stride": 128,
                "aggregator": "attention",
                "gating_weight": 0.1191520977835257
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": "yarn",
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "moe",
              "hidden": 2048,
              "n_experts": 16,
              "k": 2,
              "capacity_factor": 1.2,
              "balance": 0.05,
              "shared": 1,
              "router_temperature": null,
              "router_type": "softmax",
              "router_bias_detached": false,
              "shared_expert": false,
              "router_aux_weight": null,
              "router_lb_weight": null,
              "drop_policy": "none",
              "experts": []
            },
            "ssm": null,
            "extras": [
              {
                "type": "gated",
                "targets": [
                  "attn",
                  "ffn",
                  "ssm"
                ],
                "init_weight": 0.2,
                "learnable": true
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": null,
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 1024,
                "stride": 64,
                "aggregator": "gate",
                "gating_weight": 0.35
              },
              {
                "type": "custom",
                "name": "exp-4338",
                "params": {
                  "dim": 1024,
                  "activation": "relu",
                  "notes": "auto-generated"
                }
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": {
              "kind": "mamba2",
              "d_state": 16,
              "d_conv": 4,
              "dt_rank": 8,
              "chunk": 128,
              "gate": 0.15
            },
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 512,
                "stride": 128,
                "aggregator": "attention",
                "gating_weight": 0.1191520977835257
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": "yarn",
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "moe",
              "hidden": 2048,
              "n_experts": 16,
              "k": 2,
              "capacity_factor": 1.2,
              "balance": 0.05,
              "shared": 1,
              "router_temperature": null,
              "router_type": "softmax",
              "router_bias_detached": false,
              "shared_expert": false,
              "router_aux_weight": null,
              "router_lb_weight": null,
              "drop_policy": "none",
              "experts": []
            },
            "ssm": null,
            "extras": [
              {
                "type": "gated",
                "targets": [
                  "attn",
                  "ffn",
                  "ssm"
                ],
                "init_weight": 0.2,
                "learnable": true
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": null,
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 1024,
                "stride": 64,
                "aggregator": "gate",
                "gating_weight": 0.35
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": null,
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 1024,
                "stride": 64,
                "aggregator": "gate",
                "gating_weight": 0.35
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": null,
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 1024,
                "stride": 64,
                "aggregator": "gate",
                "gating_weight": 0.35
              }
            ]
          }
        ],
        "head": {
          "tie_embeddings": true,
          "vocab": 50257
        },
        "norm": "layernorm",
        "recurrences": []
      },
      "train": {
        "lr": 0.0008,
        "warmup": 500,
        "clip": 1.0,
        "bf16": true,
        "grad_checkpoint": true,
        "max_tokens": 520000,
        "weight_decay": 0.02,
        "seed": 4242,
        "router_lb_coeff": 0.01,
        "router_entropy_coeff": 0.005,
        "entropy_threshold": 0.5,
        "entropy_patience": 3,
        "instability_threshold": 500.0,
        "no_improve_patience": 20,
        "improvement_tolerance": 0.001,
        "ppl_stop_threshold": null,
        "init_checkpoint": null,
        "optimizer": {
          "name": "adamw",
          "lr": null,
          "betas": null,
          "eps": null,
          "weight_decay": null
        }
      },
      "data": {
        "tokenizer": "gpt2",
        "hf_revision": "main",
        "seq_len": 512,
        "batch_size": 1,
        "workers": 0,
        "shards": [
          {
            "name": "ag_news",
            "split": "train",
            "weight": 0.25,
            "cache_path": null,
            "revision": null
          },
          {
            "name": "wikitext",
            "split": "wikitext-2-raw-v1",
            "weight": 0.35,
            "cache_path": null,
            "revision": null
          },
          {
            "name": "mbpp",
            "split": "train",
            "weight": 0.4,
            "cache_path": null,
            "revision": null
          }
        ],
        "healing_shards": [],
        "healing_tokens": null
      },
      "evolution": {
        "rung0_thresholds": {
          "gate_entropy_min": 0.0,
          "gate_entropy_max": 4.0
        },
        "rung1_tokens": 300000,
        "rung2_tokens": 900000,
        "population": 24,
        "topk_keep": 0.45,
        "crossover_prob": 0.5,
        "parent_selection": "lexicase",
        "pareto_objectives": [
          "ppl_code",
          "ppl_math",
          "long_recall",
          "ppl_per_long_recall",
          "throughput",
          "ram",
          "novelty",
          "graph_entropy"
        ],
        "objectives": {
          "ppl_code": "min",
          "ppl_math": "min",
          "long_recall": "max",
          "ppl_per_long_recall": "min",
          "throughput": "max",
          "ram": "min",
          "novelty": "max",
          "graph_entropy": "max",
          "instability": "min"
        },
        "composite_metrics": [
          {
            "name": "ppl_per_long_recall",
            "op": "ratio",
            "numerator": "ppl_code",
            "denominator": "long_recall",
            "terms": {},
            "epsilon": 0.1
          }
        ],
        "promotion_prob": 0.4,
        "promotion_min_layers": 8,
        "promotion_min_moe_blocks": 2,
        "promotion_steps_multiplier": 1.5,
        "promotion_tokens_multiplier": 1.5,
        "promotion_min_router_entropy": 0.0,
        "promotion_min_recurrence_gain": 0.0,
        "promotion_max_instability": null
      },
      "priors": {
        "tokens_per_param": 4.0,
        "window_scale": 6.0,
        "rope_theta_default": 10000.0,
        "prior_weight": 0.0,
        "compute_penalty_weight": 0.0
      }
    }
  },
  {
    "id": "xover-11-be28",
    "parent": null,
    "metrics": {
      "layers": 7.0,
      "moe_blocks": 3.0,
      "graph_entropy": 2.525103553819171,
      "selector_blocks": 0.0,
      "selector_topk_avg": 0.0,
      "memory_blocks": 4.0,
      "recurrences": 0.0,
      "novelty": 0.7894736842105263,
      "params": 205405601.0,
      "kv_bytes_per_token": 7168,
      "throughput_proxy": 77.85096460459184,
      "ppl_code": 1.0,
      "ppl_math": 1.03,
      "throughput": 422.4855089350322,
      "ram": 0.3825977463275194,
      "long_recall": 0.842857142857143,
      "router_entropy": 0.6853306690851847,
      "router_lb": 0.023797353108723957,
      "router_load_max": 0.4765625,
      "router_load_min": 0.0,
      "router_load_cv": 2.562779426574707,
      "capacity_overflow": 0.0,
      "max_grad_norm": 0.0,
      "instability": 0.0,
      "stop_reason_code": 3.0,
      "nan_seen": 0.0,
      "loss_spike": 9.073782712221146e-05,
      "prior_distance": 0.04415474693097899,
      "ppl_per_long_recall": 1.1864406779661016,
      "ppl_per_param": 4.868416416746104e-09,
      "ppl_per_throughput": 0.0023669450877042393
    },
    "spec": {
      "model": {
        "name": "phi-tiny-evo-creative",
        "emb": {
          "dim": 512,
          "vocab": 50257,
          "rope": null,
          "dropout": 0.0
        },
        "blocks": [
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": "yarn",
              "rope_theta": null,
              "sw": 128,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "local_global",
              "block_size": null,
              "block_stride": null,
              "global_stride": 64,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": null,
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 256,
                "stride": 32,
                "aggregator": "gate",
                "gating_weight": 0.25
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "moe",
              "hidden": 2048,
              "n_experts": 16,
              "k": 2,
              "capacity_factor": 1.2,
              "balance": 0.05,
              "shared": 1,
              "router_temperature": null,
              "router_type": "softmax",
              "router_bias_detached": false,
              "shared_expert": false,
              "router_aux_weight": null,
              "router_lb_weight": null,
              "drop_policy": "none",
              "experts": []
            },
            "ssm": null,
            "extras": [
              {
                "type": "custom",
                "name": "exp-gater",
                "params": {
                  "dim": 256
                }
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "moe",
              "hidden": 2048,
              "n_experts": 16,
              "k": 2,
              "capacity_factor": 1.2,
              "balance": 0.05,
              "shared": 1,
              "router_temperature": null,
              "router_type": "softmax",
              "router_bias_detached": false,
              "shared_expert": false,
              "router_aux_weight": null,
              "router_lb_weight": null,
              "drop_policy": "none",
              "experts": []
            },
            "ssm": null,
            "extras": [
              {
                "type": "custom",
                "name": "exp-gater",
                "params": {
                  "dim": 256
                }
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": {
              "kind": "mamba2",
              "d_state": 16,
              "d_conv": 4,
              "dt_rank": 8,
              "chunk": 128,
              "gate": 0.15
            },
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 512,
                "stride": 128,
                "aggregator": "attention",
                "gating_weight": 0.1191520977835257
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "moe",
              "hidden": 2048,
              "n_experts": 16,
              "k": 2,
              "capacity_factor": 1.2,
              "balance": 0.05,
              "shared": 1,
              "router_temperature": null,
              "router_type": "softmax",
              "router_bias_detached": false,
              "shared_expert": false,
              "router_aux_weight": null,
              "router_lb_weight": null,
              "drop_policy": "none",
              "experts": []
            },
            "ssm": null,
            "extras": [
              {
                "type": "custom",
                "name": "exp-gater",
                "params": {
                  "dim": 256
                }
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": null,
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 1024,
                "stride": 64,
                "aggregator": "gate",
                "gating_weight": 0.35
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": null,
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 1024,
                "stride": 64,
                "aggregator": "gate",
                "gating_weight": 0.35
              }
            ]
          }
        ],
        "head": {
          "tie_embeddings": true,
          "vocab": 50257
        },
        "norm": "layernorm",
        "recurrences": []
      },
      "train": {
        "lr": 0.0008,
        "warmup": 500,
        "clip": 1.0,
        "bf16": true,
        "grad_checkpoint": true,
        "max_tokens": 520000,
        "weight_decay": 0.02,
        "seed": 4242,
        "router_lb_coeff": 0.01,
        "router_entropy_coeff": 0.005,
        "entropy_threshold": 0.5,
        "entropy_patience": 3,
        "instability_threshold": 500.0,
        "no_improve_patience": 20,
        "improvement_tolerance": 0.001,
        "ppl_stop_threshold": null,
        "init_checkpoint": null,
        "optimizer": {
          "name": "adamw",
          "lr": null,
          "betas": null,
          "eps": null,
          "weight_decay": null
        }
      },
      "data": {
        "tokenizer": "gpt2",
        "hf_revision": "main",
        "seq_len": 512,
        "batch_size": 1,
        "workers": 0,
        "shards": [
          {
            "name": "ag_news",
            "split": "train",
            "weight": 0.25,
            "cache_path": null,
            "revision": null
          },
          {
            "name": "wikitext",
            "split": "wikitext-2-raw-v1",
            "weight": 0.35,
            "cache_path": null,
            "revision": null
          },
          {
            "name": "mbpp",
            "split": "train",
            "weight": 0.4,
            "cache_path": null,
            "revision": null
          }
        ],
        "healing_shards": [],
        "healing_tokens": null
      },
      "evolution": {
        "rung0_thresholds": {
          "gate_entropy_min": 0.0,
          "gate_entropy_max": 4.0
        },
        "rung1_tokens": 300000,
        "rung2_tokens": 900000,
        "population": 24,
        "topk_keep": 0.45,
        "crossover_prob": 0.5,
        "parent_selection": "lexicase",
        "pareto_objectives": [
          "ppl_code",
          "ppl_math",
          "long_recall",
          "ppl_per_long_recall",
          "throughput",
          "ram",
          "novelty",
          "graph_entropy"
        ],
        "objectives": {
          "ppl_code": "min",
          "ppl_math": "min",
          "long_recall": "max",
          "ppl_per_long_recall": "min",
          "throughput": "max",
          "ram": "min",
          "novelty": "max",
          "graph_entropy": "max",
          "instability": "min"
        },
        "composite_metrics": [
          {
            "name": "ppl_per_long_recall",
            "op": "ratio",
            "numerator": "ppl_code",
            "denominator": "long_recall",
            "terms": {},
            "epsilon": 0.1
          }
        ],
        "promotion_prob": 0.4,
        "promotion_min_layers": 8,
        "promotion_min_moe_blocks": 2,
        "promotion_steps_multiplier": 1.5,
        "promotion_tokens_multiplier": 1.5,
        "promotion_min_router_entropy": 0.0,
        "promotion_min_recurrence_gain": 0.0,
        "promotion_max_instability": null
      },
      "priors": {
        "tokens_per_param": 4.0,
        "window_scale": 6.0,
        "rope_theta_default": 10000.0,
        "prior_weight": 0.0,
        "compute_penalty_weight": 0.0
      }
    }
  },
  {
    "id": "xover-13-8bb9",
    "parent": null,
    "metrics": {
      "layers": 10.0,
      "moe_blocks": 5.0,
      "graph_entropy": 2.689105183641252,
      "selector_blocks": 0.0,
      "selector_topk_avg": 0.0,
      "memory_blocks": 5.0,
      "recurrences": 0.0,
      "novelty": 1.0,
      "params": 318068707.0,
      "kv_bytes_per_token": 10240,
      "throughput_proxy": 38.14697265625,
      "ppl_code": 1.0,
      "ppl_math": 1.05,
      "throughput": 336.3680405076229,
      "ram": 0.5924491342157125,
      "long_recall": 0.9,
      "router_entropy": 0.6835681557655334,
      "router_lb": 0.02578248977661133,
      "router_load_max": 0.4931640625,
      "router_load_min": 0.0,
      "router_load_cv": 2.6809089183807373,
      "capacity_overflow": 0.0,
      "max_grad_norm": 0.0,
      "instability": 0.0,
      "stop_reason_code": 3.0,
      "nan_seen": 0.0,
      "loss_spike": 8.320435881614685e-06,
      "prior_distance": 0.03238014853435782,
      "ppl_per_long_recall": 1.1111111111111112,
      "ppl_per_param": 3.143974801645608e-09,
      "ppl_per_throughput": 0.002972934047155225
    },
    "spec": {
      "model": {
        "name": "phi-tiny-evo-creative",
        "emb": {
          "dim": 512,
          "vocab": 50257,
          "rope": null,
          "dropout": 0.0
        },
        "blocks": [
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "moe",
              "hidden": 2048,
              "n_experts": 16,
              "k": 2,
              "capacity_factor": 1.2,
              "balance": 0.05,
              "shared": 1,
              "router_temperature": null,
              "router_type": "softmax",
              "router_bias_detached": false,
              "shared_expert": false,
              "router_aux_weight": null,
              "router_lb_weight": null,
              "drop_policy": "none",
              "experts": []
            },
            "ssm": null,
            "extras": [
              {
                "type": "custom",
                "name": "exp-gater",
                "params": {
                  "dim": 256
                }
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": "yarn",
              "rope_theta": null,
              "sw": 128,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "local_global",
              "block_size": null,
              "block_stride": null,
              "global_stride": 64,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": null,
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 256,
                "stride": 32,
                "aggregator": "gate",
                "gating_weight": 0.25
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "moe",
              "hidden": 2048,
              "n_experts": 16,
              "k": 2,
              "capacity_factor": 1.2,
              "balance": 0.05,
              "shared": 1,
              "router_temperature": null,
              "router_type": "softmax",
              "router_bias_detached": false,
              "shared_expert": false,
              "router_aux_weight": null,
              "router_lb_weight": null,
              "drop_policy": "none",
              "experts": []
            },
            "ssm": null,
            "extras": [
              {
                "type": "custom",
                "name": "exp-gater",
                "params": {
                  "dim": 256
                }
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": {
              "kind": "mamba2",
              "d_state": 16,
              "d_conv": 4,
              "dt_rank": 8,
              "chunk": 128,
              "gate": 0.15
            },
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 512,
                "stride": 128,
                "aggregator": "attention",
                "gating_weight": 0.1191520977835257
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "moe",
              "hidden": 2048,
              "n_experts": 16,
              "k": 2,
              "capacity_factor": 1.2,
              "balance": 0.05,
              "shared": 1,
              "router_temperature": null,
              "router_type": "softmax",
              "router_bias_detached": false,
              "shared_expert": false,
              "router_aux_weight": null,
              "router_lb_weight": null,
              "drop_policy": "none",
              "experts": []
            },
            "ssm": null,
            "extras": [
              {
                "type": "custom",
                "name": "exp-gater",
                "params": {
                  "dim": 256
                }
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": {
              "kind": "mamba2",
              "d_state": 16,
              "d_conv": 4,
              "dt_rank": 8,
              "chunk": 128,
              "gate": 0.15
            },
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 512,
                "stride": 128,
                "aggregator": "attention",
                "gating_weight": 0.1191520977835257
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": "yarn",
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "moe",
              "hidden": 2048,
              "n_experts": 16,
              "k": 2,
              "capacity_factor": 1.2,
              "balance": 0.05,
              "shared": 1,
              "router_temperature": null,
              "router_type": "softmax",
              "router_bias_detached": false,
              "shared_expert": false,
              "router_aux_weight": null,
              "router_lb_weight": null,
              "drop_policy": "none",
              "experts": []
            },
            "ssm": null,
            "extras": [
              {
                "type": "gated",
                "targets": [
                  "attn",
                  "ffn",
                  "ssm"
                ],
                "init_weight": 0.2,
                "learnable": true
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": "yarn",
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "moe",
              "hidden": 2048,
              "n_experts": 16,
              "k": 2,
              "capacity_factor": 1.2,
              "balance": 0.05,
              "shared": 1,
              "router_temperature": null,
              "router_type": "softmax",
              "router_bias_detached": false,
              "shared_expert": false,
              "router_aux_weight": null,
              "router_lb_weight": null,
              "drop_policy": "none",
              "experts": []
            },
            "ssm": null,
            "extras": [
              {
                "type": "gated",
                "targets": [
                  "attn",
                  "ffn",
                  "ssm"
                ],
                "init_weight": 0.2,
                "learnable": true
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": null,
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 1024,
                "stride": 64,
                "aggregator": "gate",
                "gating_weight": 0.35
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": null,
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 1024,
                "stride": 64,
                "aggregator": "gate",
                "gating_weight": 0.35
              }
            ]
          }
        ],
        "head": {
          "tie_embeddings": true,
          "vocab": 50257
        },
        "norm": "layernorm",
        "recurrences": []
      },
      "train": {
        "lr": 0.0008,
        "warmup": 500,
        "clip": 1.0,
        "bf16": true,
        "grad_checkpoint": true,
        "max_tokens": 520000,
        "weight_decay": 0.02,
        "seed": 4242,
        "router_lb_coeff": 0.01,
        "router_entropy_coeff": 0.005,
        "entropy_threshold": 0.5,
        "entropy_patience": 3,
        "instability_threshold": 500.0,
        "no_improve_patience": 20,
        "improvement_tolerance": 0.001,
        "ppl_stop_threshold": null,
        "init_checkpoint": null,
        "optimizer": {
          "name": "adamw",
          "lr": null,
          "betas": null,
          "eps": null,
          "weight_decay": null
        }
      },
      "data": {
        "tokenizer": "gpt2",
        "hf_revision": "main",
        "seq_len": 512,
        "batch_size": 1,
        "workers": 0,
        "shards": [
          {
            "name": "ag_news",
            "split": "train",
            "weight": 0.25,
            "cache_path": null,
            "revision": null
          },
          {
            "name": "wikitext",
            "split": "wikitext-2-raw-v1",
            "weight": 0.35,
            "cache_path": null,
            "revision": null
          },
          {
            "name": "mbpp",
            "split": "train",
            "weight": 0.4,
            "cache_path": null,
            "revision": null
          }
        ],
        "healing_shards": [],
        "healing_tokens": null
      },
      "evolution": {
        "rung0_thresholds": {
          "gate_entropy_min": 0.0,
          "gate_entropy_max": 4.0
        },
        "rung1_tokens": 300000,
        "rung2_tokens": 900000,
        "population": 24,
        "topk_keep": 0.45,
        "crossover_prob": 0.5,
        "parent_selection": "lexicase",
        "pareto_objectives": [
          "ppl_code",
          "ppl_math",
          "long_recall",
          "ppl_per_long_recall",
          "throughput",
          "ram",
          "novelty",
          "graph_entropy"
        ],
        "objectives": {
          "ppl_code": "min",
          "ppl_math": "min",
          "long_recall": "max",
          "ppl_per_long_recall": "min",
          "throughput": "max",
          "ram": "min",
          "novelty": "max",
          "graph_entropy": "max",
          "instability": "min"
        },
        "composite_metrics": [
          {
            "name": "ppl_per_long_recall",
            "op": "ratio",
            "numerator": "ppl_code",
            "denominator": "long_recall",
            "terms": {},
            "epsilon": 0.1
          }
        ],
        "promotion_prob": 0.4,
        "promotion_min_layers": 8,
        "promotion_min_moe_blocks": 2,
        "promotion_steps_multiplier": 1.5,
        "promotion_tokens_multiplier": 1.5,
        "promotion_min_router_entropy": 0.0,
        "promotion_min_recurrence_gain": 0.0,
        "promotion_max_instability": null
      },
      "priors": {
        "tokens_per_param": 4.0,
        "window_scale": 6.0,
        "rope_theta_default": 10000.0,
        "prior_weight": 0.0,
        "compute_penalty_weight": 0.0
      }
    }
  },
  {
    "id": "make_gqa-14-498f",
    "parent": "xover-9-7f06",
    "metrics": {
      "layers": 13.0,
      "moe_blocks": 5.0,
      "graph_entropy": 2.690886274676896,
      "selector_blocks": 0.0,
      "selector_topk_avg": 0.0,
      "memory_blocks": 8.0,
      "recurrences": 0.0,
      "novelty": 0.0,
      "params": 330954755.0,
      "kv_bytes_per_token": 13312,
      "throughput_proxy": 22.572173169378697,
      "ppl_code": 1.0,
      "ppl_math": 1.05,
      "throughput": 331.90416389208065,
      "ram": 0.6164512690156698,
      "long_recall": 1.0307692307692307,
      "router_entropy": 0.6844437479972839,
      "router_lb": 0.02361266650259495,
      "router_load_max": 0.4755859375,
      "router_load_min": 0.0,
      "router_load_cv": 2.576119899749756,
      "capacity_overflow": 0.0,
      "max_grad_norm": 0.0,
      "instability": 0.0,
      "stop_reason_code": 3.0,
      "nan_seen": 0.0,
      "loss_spike": 0.0,
      "prior_distance": 0.02312867796508752,
      "ppl_per_long_recall": 0.9701492537313434,
      "ppl_per_param": 3.0215610590033675e-09,
      "ppl_per_throughput": 0.0030129179106205854
    },
    "spec": {
      "model": {
        "name": "phi-tiny-evo-creative",
        "emb": {
          "dim": 512,
          "vocab": 50257,
          "rope": null,
          "dropout": 0.0
        },
        "blocks": [
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "moe",
              "hidden": 2048,
              "n_experts": 16,
              "k": 2,
              "capacity_factor": 1.2,
              "balance": 0.05,
              "shared": 1,
              "router_temperature": null,
              "router_type": "softmax",
              "router_bias_detached": false,
              "shared_expert": false,
              "router_aux_weight": null,
              "router_lb_weight": null,
              "drop_policy": "none",
              "experts": []
            },
            "ssm": null,
            "extras": [
              {
                "type": "custom",
                "name": "exp-gater",
                "params": {
                  "dim": 256
                }
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": "yarn",
              "rope_theta": null,
              "sw": 128,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "local_global",
              "block_size": null,
              "block_stride": null,
              "global_stride": 64,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": null,
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 256,
                "stride": 32,
                "aggregator": "gate",
                "gating_weight": 0.25
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "moe",
              "hidden": 2048,
              "n_experts": 16,
              "k": 2,
              "capacity_factor": 1.2,
              "balance": 0.05,
              "shared": 1,
              "router_temperature": null,
              "router_type": "softmax",
              "router_bias_detached": false,
              "shared_expert": false,
              "router_aux_weight": null,
              "router_lb_weight": null,
              "drop_policy": "none",
              "experts": []
            },
            "ssm": null,
            "extras": [
              {
                "type": "custom",
                "name": "exp-gater",
                "params": {
                  "dim": 256
                }
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": {
              "kind": "mamba2",
              "d_state": 16,
              "d_conv": 4,
              "dt_rank": 8,
              "chunk": 128,
              "gate": 0.15
            },
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 512,
                "stride": 128,
                "aggregator": "attention",
                "gating_weight": 0.1191520977835257
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "moe",
              "hidden": 2048,
              "n_experts": 16,
              "k": 2,
              "capacity_factor": 1.2,
              "balance": 0.05,
              "shared": 1,
              "router_temperature": null,
              "router_type": "softmax",
              "router_bias_detached": false,
              "shared_expert": false,
              "router_aux_weight": null,
              "router_lb_weight": null,
              "drop_policy": "none",
              "experts": []
            },
            "ssm": null,
            "extras": [
              {
                "type": "custom",
                "name": "exp-gater",
                "params": {
                  "dim": 256
                }
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": {
              "kind": "mamba2",
              "d_state": 16,
              "d_conv": 4,
              "dt_rank": 8,
              "chunk": 128,
              "gate": 0.15
            },
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 512,
                "stride": 128,
                "aggregator": "attention",
                "gating_weight": 0.1191520977835257
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": "yarn",
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "moe",
              "hidden": 2048,
              "n_experts": 16,
              "k": 2,
              "capacity_factor": 1.2,
              "balance": 0.05,
              "shared": 1,
              "router_temperature": null,
              "router_type": "softmax",
              "router_bias_detached": false,
              "shared_expert": false,
              "router_aux_weight": null,
              "router_lb_weight": null,
              "drop_policy": "none",
              "experts": []
            },
            "ssm": null,
            "extras": [
              {
                "type": "gated",
                "targets": [
                  "attn",
                  "ffn",
                  "ssm"
                ],
                "init_weight": 0.2,
                "learnable": true
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": null,
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 1024,
                "stride": 64,
                "aggregator": "gate",
                "gating_weight": 0.35
              },
              {
                "type": "custom",
                "name": "exp-4338",
                "params": {
                  "dim": 1024,
                  "activation": "relu",
                  "notes": "auto-generated"
                }
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": {
              "kind": "mamba2",
              "d_state": 16,
              "d_conv": 4,
              "dt_rank": 8,
              "chunk": 128,
              "gate": 0.15
            },
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 512,
                "stride": 128,
                "aggregator": "attention",
                "gating_weight": 0.1191520977835257
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": "yarn",
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "moe",
              "hidden": 2048,
              "n_experts": 16,
              "k": 2,
              "capacity_factor": 1.2,
              "balance": 0.05,
              "shared": 1,
              "router_temperature": null,
              "router_type": "softmax",
              "router_bias_detached": false,
              "shared_expert": false,
              "router_aux_weight": null,
              "router_lb_weight": null,
              "drop_policy": "none",
              "experts": []
            },
            "ssm": null,
            "extras": [
              {
                "type": "gated",
                "targets": [
                  "attn",
                  "ffn",
                  "ssm"
                ],
                "init_weight": 0.2,
                "learnable": true
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": null,
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 1024,
                "stride": 64,
                "aggregator": "gate",
                "gating_weight": 0.35
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": null,
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 1024,
                "stride": 64,
                "aggregator": "gate",
                "gating_weight": 0.35
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": null,
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 1024,
                "stride": 64,
                "aggregator": "gate",
                "gating_weight": 0.35
              }
            ]
          }
        ],
        "head": {
          "tie_embeddings": true,
          "vocab": 50257
        },
        "norm": "layernorm",
        "recurrences": []
      },
      "train": {
        "lr": 0.0008,
        "warmup": 500,
        "clip": 1.0,
        "bf16": true,
        "grad_checkpoint": true,
        "max_tokens": 520000,
        "weight_decay": 0.02,
        "seed": 4242,
        "router_lb_coeff": 0.01,
        "router_entropy_coeff": 0.005,
        "entropy_threshold": 0.5,
        "entropy_patience": 3,
        "instability_threshold": 500.0,
        "no_improve_patience": 20,
        "improvement_tolerance": 0.001,
        "ppl_stop_threshold": null,
        "init_checkpoint": null,
        "optimizer": {
          "name": "adamw",
          "lr": null,
          "betas": null,
          "eps": null,
          "weight_decay": null
        }
      },
      "data": {
        "tokenizer": "gpt2",
        "hf_revision": "main",
        "seq_len": 512,
        "batch_size": 1,
        "workers": 0,
        "shards": [
          {
            "name": "ag_news",
            "split": "train",
            "weight": 0.25,
            "cache_path": null,
            "revision": null
          },
          {
            "name": "wikitext",
            "split": "wikitext-2-raw-v1",
            "weight": 0.35,
            "cache_path": null,
            "revision": null
          },
          {
            "name": "mbpp",
            "split": "train",
            "weight": 0.4,
            "cache_path": null,
            "revision": null
          }
        ],
        "healing_shards": [],
        "healing_tokens": null
      },
      "evolution": {
        "rung0_thresholds": {
          "gate_entropy_min": 0.0,
          "gate_entropy_max": 4.0
        },
        "rung1_tokens": 300000,
        "rung2_tokens": 900000,
        "population": 24,
        "topk_keep": 0.45,
        "crossover_prob": 0.5,
        "parent_selection": "lexicase",
        "pareto_objectives": [
          "ppl_code",
          "ppl_math",
          "long_recall",
          "ppl_per_long_recall",
          "throughput",
          "ram",
          "novelty",
          "graph_entropy"
        ],
        "objectives": {
          "ppl_code": "min",
          "ppl_math": "min",
          "long_recall": "max",
          "ppl_per_long_recall": "min",
          "throughput": "max",
          "ram": "min",
          "novelty": "max",
          "graph_entropy": "max",
          "instability": "min"
        },
        "composite_metrics": [
          {
            "name": "ppl_per_long_recall",
            "op": "ratio",
            "numerator": "ppl_code",
            "denominator": "long_recall",
            "terms": {},
            "epsilon": 0.1
          }
        ],
        "promotion_prob": 0.4,
        "promotion_min_layers": 8,
        "promotion_min_moe_blocks": 2,
        "promotion_steps_multiplier": 1.5,
        "promotion_tokens_multiplier": 1.5,
        "promotion_min_router_entropy": 0.0,
        "promotion_min_recurrence_gain": 0.0,
        "promotion_max_instability": null
      },
      "priors": {
        "tokens_per_param": 4.0,
        "window_scale": 6.0,
        "rope_theta_default": 10000.0,
        "prior_weight": 0.0,
        "compute_penalty_weight": 0.0
      }
    }
  },
  {
    "id": "tune_kv-16-6a7b",
    "parent": "xover-10-ebf8",
    "metrics": {
      "layers": 22.0,
      "moe_blocks": 9.0,
      "graph_entropy": 2.7614908461268786,
      "selector_blocks": 0.0,
      "selector_topk_avg": 0.0,
      "memory_blocks": 13.0,
      "recurrences": 0.0,
      "novelty": 0.022727272727272728,
      "params": 568511397.0,
      "kv_bytes_per_token": 22016,
      "throughput_proxy": 7.8816059207128095,
      "ppl_code": 1.0,
      "ppl_math": 1.09,
      "throughput": 225.76987472165897,
      "ram": 1.0589349959045649,
      "long_recall": 1.0272727272727273,
      "router_entropy": 0.689816845787896,
      "router_lb": 0.025484946452909045,
      "router_load_max": 0.4970703125,
      "router_load_min": 0.0,
      "router_load_cv": 2.6901392936706543,
      "capacity_overflow": 0.0,
      "max_grad_norm": 0.0,
      "instability": 0.0,
      "stop_reason_code": 3.0,
      "nan_seen": 0.0,
      "loss_spike": 0.0,
      "prior_distance": 0.042040127964311544,
      "ppl_per_long_recall": 0.9734513274336283,
      "ppl_per_param": 1.7589796884933866e-09,
      "ppl_per_throughput": 0.004429288899738519
    },
    "spec": {
      "model": {
        "name": "phi-tiny-evo-creative",
        "emb": {
          "dim": 512,
          "vocab": 50257,
          "rope": null,
          "dropout": 0.0
        },
        "blocks": [
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": "yarn",
              "rope_theta": null,
              "sw": 128,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "local_global",
              "block_size": null,
              "block_stride": null,
              "global_stride": 64,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": null,
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 256,
                "stride": 32,
                "aggregator": "gate",
                "gating_weight": 0.25
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "moe",
              "hidden": 2048,
              "n_experts": 16,
              "k": 2,
              "capacity_factor": 1.2,
              "balance": 0.05,
              "shared": 1,
              "router_temperature": null,
              "router_type": "softmax",
              "router_bias_detached": false,
              "shared_expert": false,
              "router_aux_weight": null,
              "router_lb_weight": null,
              "drop_policy": "none",
              "experts": []
            },
            "ssm": null,
            "extras": [
              {
                "type": "custom",
                "name": "exp-gater",
                "params": {
                  "dim": 256
                }
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "moe",
              "hidden": 2048,
              "n_experts": 16,
              "k": 2,
              "capacity_factor": 1.2,
              "balance": 0.05,
              "shared": 1,
              "router_temperature": null,
              "router_type": "softmax",
              "router_bias_detached": false,
              "shared_expert": false,
              "router_aux_weight": null,
              "router_lb_weight": null,
              "drop_policy": "none",
              "experts": []
            },
            "ssm": null,
            "extras": [
              {
                "type": "custom",
                "name": "exp-gater",
                "params": {
                  "dim": 256
                }
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": {
              "kind": "mamba2",
              "d_state": 16,
              "d_conv": 4,
              "dt_rank": 8,
              "chunk": 128,
              "gate": 0.15
            },
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 512,
                "stride": 128,
                "aggregator": "attention",
                "gating_weight": 0.1191520977835257
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "moe",
              "hidden": 2048,
              "n_experts": 16,
              "k": 2,
              "capacity_factor": 1.2,
              "balance": 0.05,
              "shared": 1,
              "router_temperature": null,
              "router_type": "softmax",
              "router_bias_detached": false,
              "shared_expert": false,
              "router_aux_weight": null,
              "router_lb_weight": null,
              "drop_policy": "none",
              "experts": []
            },
            "ssm": null,
            "extras": [
              {
                "type": "custom",
                "name": "exp-gater",
                "params": {
                  "dim": 256
                }
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": {
              "kind": "mamba2",
              "d_state": 16,
              "d_conv": 4,
              "dt_rank": 8,
              "chunk": 128,
              "gate": 0.15
            },
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 512,
                "stride": 128,
                "aggregator": "attention",
                "gating_weight": 0.1191520977835257
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": "yarn",
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "moe",
              "hidden": 2048,
              "n_experts": 16,
              "k": 2,
              "capacity_factor": 1.2,
              "balance": 0.05,
              "shared": 1,
              "router_temperature": null,
              "router_type": "softmax",
              "router_bias_detached": false,
              "shared_expert": false,
              "router_aux_weight": null,
              "router_lb_weight": null,
              "drop_policy": "none",
              "experts": []
            },
            "ssm": null,
            "extras": [
              {
                "type": "gated",
                "targets": [
                  "attn",
                  "ffn",
                  "ssm"
                ],
                "init_weight": 0.2,
                "learnable": true
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": null,
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 1024,
                "stride": 64,
                "aggregator": "gate",
                "gating_weight": 0.35
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 4,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": {
              "kind": "mamba2",
              "d_state": 16,
              "d_conv": 4,
              "dt_rank": 8,
              "chunk": 128,
              "gate": 0.15
            },
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 512,
                "stride": 128,
                "aggregator": "attention",
                "gating_weight": 0.1191520977835257
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": "yarn",
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "moe",
              "hidden": 2048,
              "n_experts": 16,
              "k": 2,
              "capacity_factor": 1.2,
              "balance": 0.05,
              "shared": 1,
              "router_temperature": null,
              "router_type": "softmax",
              "router_bias_detached": false,
              "shared_expert": false,
              "router_aux_weight": null,
              "router_lb_weight": null,
              "drop_policy": "none",
              "experts": []
            },
            "ssm": null,
            "extras": [
              {
                "type": "gated",
                "targets": [
                  "attn",
                  "ffn",
                  "ssm"
                ],
                "init_weight": 0.2,
                "learnable": true
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": "yarn",
              "rope_theta": null,
              "sw": 128,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "local_global",
              "block_size": null,
              "block_stride": null,
              "global_stride": 64,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": null,
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 256,
                "stride": 32,
                "aggregator": "gate",
                "gating_weight": 0.25
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "moe",
              "hidden": 2048,
              "n_experts": 16,
              "k": 2,
              "capacity_factor": 1.2,
              "balance": 0.05,
              "shared": 1,
              "router_temperature": null,
              "router_type": "softmax",
              "router_bias_detached": false,
              "shared_expert": false,
              "router_aux_weight": null,
              "router_lb_weight": null,
              "drop_policy": "none",
              "experts": []
            },
            "ssm": null,
            "extras": [
              {
                "type": "custom",
                "name": "exp-gater",
                "params": {
                  "dim": 256
                }
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": {
              "kind": "mamba2",
              "d_state": 16,
              "d_conv": 4,
              "dt_rank": 8,
              "chunk": 128,
              "gate": 0.15
            },
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 512,
                "stride": 128,
                "aggregator": "attention",
                "gating_weight": 0.1191520977835257
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "moe",
              "hidden": 2048,
              "n_experts": 16,
              "k": 2,
              "capacity_factor": 1.2,
              "balance": 0.05,
              "shared": 1,
              "router_temperature": null,
              "router_type": "softmax",
              "router_bias_detached": false,
              "shared_expert": false,
              "router_aux_weight": null,
              "router_lb_weight": null,
              "drop_policy": "none",
              "experts": []
            },
            "ssm": null,
            "extras": [
              {
                "type": "custom",
                "name": "exp-gater",
                "params": {
                  "dim": 256
                }
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": {
              "kind": "mamba2",
              "d_state": 16,
              "d_conv": 4,
              "dt_rank": 8,
              "chunk": 128,
              "gate": 0.15
            },
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 512,
                "stride": 128,
                "aggregator": "attention",
                "gating_weight": 0.1191520977835257
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": "yarn",
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "moe",
              "hidden": 2048,
              "n_experts": 16,
              "k": 2,
              "capacity_factor": 1.2,
              "balance": 0.05,
              "shared": 1,
              "router_temperature": null,
              "router_type": "softmax",
              "router_bias_detached": false,
              "shared_expert": false,
              "router_aux_weight": null,
              "router_lb_weight": null,
              "drop_policy": "none",
              "experts": []
            },
            "ssm": null,
            "extras": [
              {
                "type": "gated",
                "targets": [
                  "attn",
                  "ffn",
                  "ssm"
                ],
                "init_weight": 0.2,
                "learnable": true
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": null,
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 1024,
                "stride": 64,
                "aggregator": "gate",
                "gating_weight": 0.35
              },
              {
                "type": "custom",
                "name": "exp-4338",
                "params": {
                  "dim": 1024,
                  "activation": "relu",
                  "notes": "auto-generated"
                }
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": {
              "kind": "mamba2",
              "d_state": 16,
              "d_conv": 4,
              "dt_rank": 8,
              "chunk": 128,
              "gate": 0.15
            },
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 512,
                "stride": 128,
                "aggregator": "attention",
                "gating_weight": 0.1191520977835257
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": "yarn",
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "moe",
              "hidden": 2048,
              "n_experts": 16,
              "k": 2,
              "capacity_factor": 1.2,
              "balance": 0.05,
              "shared": 1,
              "router_temperature": null,
              "router_type": "softmax",
              "router_bias_detached": false,
              "shared_expert": false,
              "router_aux_weight": null,
              "router_lb_weight": null,
              "drop_policy": "none",
              "experts": []
            },
            "ssm": null,
            "extras": [
              {
                "type": "gated",
                "targets": [
                  "attn",
                  "ffn",
                  "ssm"
                ],
                "init_weight": 0.2,
                "learnable": true
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": null,
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 1024,
                "stride": 64,
                "aggregator": "gate",
                "gating_weight": 0.35
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": null,
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 1024,
                "stride": 64,
                "aggregator": "gate",
                "gating_weight": 0.35
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": null,
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 1024,
                "stride": 64,
                "aggregator": "gate",
                "gating_weight": 0.35
              }
            ]
          }
        ],
        "head": {
          "tie_embeddings": true,
          "vocab": 50257
        },
        "norm": "layernorm",
        "recurrences": []
      },
      "train": {
        "lr": 0.0008,
        "warmup": 500,
        "clip": 1.0,
        "bf16": true,
        "grad_checkpoint": true,
        "max_tokens": 520000,
        "weight_decay": 0.02,
        "seed": 4242,
        "router_lb_coeff": 0.01,
        "router_entropy_coeff": 0.005,
        "entropy_threshold": 0.5,
        "entropy_patience": 3,
        "instability_threshold": 500.0,
        "no_improve_patience": 20,
        "improvement_tolerance": 0.001,
        "ppl_stop_threshold": null,
        "init_checkpoint": null,
        "optimizer": {
          "name": "adamw",
          "lr": null,
          "betas": null,
          "eps": null,
          "weight_decay": null
        }
      },
      "data": {
        "tokenizer": "gpt2",
        "hf_revision": "main",
        "seq_len": 512,
        "batch_size": 1,
        "workers": 0,
        "shards": [
          {
            "name": "ag_news",
            "split": "train",
            "weight": 0.25,
            "cache_path": null,
            "revision": null
          },
          {
            "name": "wikitext",
            "split": "wikitext-2-raw-v1",
            "weight": 0.35,
            "cache_path": null,
            "revision": null
          },
          {
            "name": "mbpp",
            "split": "train",
            "weight": 0.4,
            "cache_path": null,
            "revision": null
          }
        ],
        "healing_shards": [],
        "healing_tokens": null
      },
      "evolution": {
        "rung0_thresholds": {
          "gate_entropy_min": 0.0,
          "gate_entropy_max": 4.0
        },
        "rung1_tokens": 300000,
        "rung2_tokens": 900000,
        "population": 24,
        "topk_keep": 0.45,
        "crossover_prob": 0.5,
        "parent_selection": "lexicase",
        "pareto_objectives": [
          "ppl_code",
          "ppl_math",
          "long_recall",
          "ppl_per_long_recall",
          "throughput",
          "ram",
          "novelty",
          "graph_entropy"
        ],
        "objectives": {
          "ppl_code": "min",
          "ppl_math": "min",
          "long_recall": "max",
          "ppl_per_long_recall": "min",
          "throughput": "max",
          "ram": "min",
          "novelty": "max",
          "graph_entropy": "max",
          "instability": "min"
        },
        "composite_metrics": [
          {
            "name": "ppl_per_long_recall",
            "op": "ratio",
            "numerator": "ppl_code",
            "denominator": "long_recall",
            "terms": {},
            "epsilon": 0.1
          }
        ],
        "promotion_prob": 0.4,
        "promotion_min_layers": 8,
        "promotion_min_moe_blocks": 2,
        "promotion_steps_multiplier": 1.5,
        "promotion_tokens_multiplier": 1.5,
        "promotion_min_router_entropy": 0.0,
        "promotion_min_recurrence_gain": 0.0,
        "promotion_max_instability": null
      },
      "priors": {
        "tokens_per_param": 4.0,
        "window_scale": 6.0,
        "rope_theta_default": 10000.0,
        "prior_weight": 0.0,
        "compute_penalty_weight": 0.0
      }
    }
  },
  {
    "id": "add_extra_combo-17-7ee7",
    "parent": "make_gqa-14-498f",
    "metrics": {
      "layers": 13.0,
      "moe_blocks": 5.0,
      "graph_entropy": 2.7110214420242857,
      "selector_blocks": 0.0,
      "selector_topk_avg": 0.0,
      "memory_blocks": 8.0,
      "recurrences": 0.0,
      "novelty": 0.038461538461538464,
      "params": 330954756.0,
      "kv_bytes_per_token": 13312,
      "throughput_proxy": 22.572173169378697,
      "ppl_code": 1.0,
      "ppl_math": 1.05,
      "throughput": 328.68035818567927,
      "ram": 0.616451270878315,
      "long_recall": 1.0307692307692307,
      "router_entropy": 0.6850104570388794,
      "router_lb": 0.024529720097780226,
      "router_load_max": 0.5,
      "router_load_min": 0.0,
      "router_load_cv": 2.7294747829437256,
      "capacity_overflow": 0.0,
      "max_grad_norm": 0.0,
      "instability": 0.0,
      "stop_reason_code": 3.0,
      "nan_seen": 0.0,
      "loss_spike": 1.983344554901123e-05,
      "prior_distance": 0.02312867796508752,
      "ppl_per_long_recall": 0.9701492537313434,
      "ppl_per_param": 3.021561049873536e-09,
      "ppl_per_throughput": 0.0030424696063981907
    },
    "spec": {
      "model": {
        "name": "phi-tiny-evo-creative",
        "emb": {
          "dim": 512,
          "vocab": 50257,
          "rope": null,
          "dropout": 0.0
        },
        "blocks": [
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "moe",
              "hidden": 2048,
              "n_experts": 16,
              "k": 2,
              "capacity_factor": 1.2,
              "balance": 0.05,
              "shared": 1,
              "router_temperature": null,
              "router_type": "softmax",
              "router_bias_detached": false,
              "shared_expert": false,
              "router_aux_weight": null,
              "router_lb_weight": null,
              "drop_policy": "none",
              "experts": []
            },
            "ssm": null,
            "extras": [
              {
                "type": "custom",
                "name": "exp-gater",
                "params": {
                  "dim": 256
                }
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": "yarn",
              "rope_theta": null,
              "sw": 128,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "local_global",
              "block_size": null,
              "block_stride": null,
              "global_stride": 64,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": null,
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 256,
                "stride": 32,
                "aggregator": "gate",
                "gating_weight": 0.25
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "moe",
              "hidden": 2048,
              "n_experts": 16,
              "k": 2,
              "capacity_factor": 1.2,
              "balance": 0.05,
              "shared": 1,
              "router_temperature": null,
              "router_type": "softmax",
              "router_bias_detached": false,
              "shared_expert": false,
              "router_aux_weight": null,
              "router_lb_weight": null,
              "drop_policy": "none",
              "experts": []
            },
            "ssm": null,
            "extras": [
              {
                "type": "custom",
                "name": "exp-gater",
                "params": {
                  "dim": 256
                }
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": {
              "kind": "mamba2",
              "d_state": 16,
              "d_conv": 4,
              "dt_rank": 8,
              "chunk": 128,
              "gate": 0.15
            },
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 512,
                "stride": 128,
                "aggregator": "attention",
                "gating_weight": 0.1191520977835257
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "moe",
              "hidden": 2048,
              "n_experts": 16,
              "k": 2,
              "capacity_factor": 1.2,
              "balance": 0.05,
              "shared": 1,
              "router_temperature": null,
              "router_type": "softmax",
              "router_bias_detached": false,
              "shared_expert": false,
              "router_aux_weight": null,
              "router_lb_weight": null,
              "drop_policy": "none",
              "experts": []
            },
            "ssm": null,
            "extras": [
              {
                "type": "custom",
                "name": "exp-gater",
                "params": {
                  "dim": 256
                }
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": {
              "kind": "mamba2",
              "d_state": 16,
              "d_conv": 4,
              "dt_rank": 8,
              "chunk": 128,
              "gate": 0.15
            },
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 512,
                "stride": 128,
                "aggregator": "attention",
                "gating_weight": 0.1191520977835257
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": "yarn",
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "moe",
              "hidden": 2048,
              "n_experts": 16,
              "k": 2,
              "capacity_factor": 1.2,
              "balance": 0.05,
              "shared": 1,
              "router_temperature": null,
              "router_type": "softmax",
              "router_bias_detached": false,
              "shared_expert": false,
              "router_aux_weight": null,
              "router_lb_weight": null,
              "drop_policy": "none",
              "experts": []
            },
            "ssm": null,
            "extras": [
              {
                "type": "gated",
                "targets": [
                  "attn",
                  "ffn",
                  "ssm"
                ],
                "init_weight": 0.2,
                "learnable": true
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": null,
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 1024,
                "stride": 64,
                "aggregator": "gate",
                "gating_weight": 0.35
              },
              {
                "type": "custom",
                "name": "exp-4338",
                "params": {
                  "dim": 1024,
                  "activation": "relu",
                  "notes": "auto-generated"
                }
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": {
              "kind": "mamba2",
              "d_state": 16,
              "d_conv": 4,
              "dt_rank": 8,
              "chunk": 128,
              "gate": 0.15
            },
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 512,
                "stride": 128,
                "aggregator": "attention",
                "gating_weight": 0.1191520977835257
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": "yarn",
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "moe",
              "hidden": 2048,
              "n_experts": 16,
              "k": 2,
              "capacity_factor": 1.2,
              "balance": 0.05,
              "shared": 1,
              "router_temperature": null,
              "router_type": "softmax",
              "router_bias_detached": false,
              "shared_expert": false,
              "router_aux_weight": null,
              "router_lb_weight": null,
              "drop_policy": "none",
              "experts": []
            },
            "ssm": null,
            "extras": [
              {
                "type": "gated",
                "targets": [
                  "attn",
                  "ffn",
                  "ssm"
                ],
                "init_weight": 0.2,
                "learnable": true
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": null,
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 1024,
                "stride": 64,
                "aggregator": "gate",
                "gating_weight": 0.35
              },
              {
                "type": "gated",
                "targets": [
                  "attn",
                  "ffn"
                ],
                "init_weight": 0.17686717452555856,
                "learnable": true
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": null,
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 1024,
                "stride": 64,
                "aggregator": "gate",
                "gating_weight": 0.35
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": null,
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 1024,
                "stride": 64,
                "aggregator": "gate",
                "gating_weight": 0.35
              }
            ]
          }
        ],
        "head": {
          "tie_embeddings": true,
          "vocab": 50257
        },
        "norm": "layernorm",
        "recurrences": []
      },
      "train": {
        "lr": 0.0008,
        "warmup": 500,
        "clip": 1.0,
        "bf16": true,
        "grad_checkpoint": true,
        "max_tokens": 520000,
        "weight_decay": 0.02,
        "seed": 4242,
        "router_lb_coeff": 0.01,
        "router_entropy_coeff": 0.005,
        "entropy_threshold": 0.5,
        "entropy_patience": 3,
        "instability_threshold": 500.0,
        "no_improve_patience": 20,
        "improvement_tolerance": 0.001,
        "ppl_stop_threshold": null,
        "init_checkpoint": null,
        "optimizer": {
          "name": "adamw",
          "lr": null,
          "betas": null,
          "eps": null,
          "weight_decay": null
        }
      },
      "data": {
        "tokenizer": "gpt2",
        "hf_revision": "main",
        "seq_len": 512,
        "batch_size": 1,
        "workers": 0,
        "shards": [
          {
            "name": "ag_news",
            "split": "train",
            "weight": 0.25,
            "cache_path": null,
            "revision": null
          },
          {
            "name": "wikitext",
            "split": "wikitext-2-raw-v1",
            "weight": 0.35,
            "cache_path": null,
            "revision": null
          },
          {
            "name": "mbpp",
            "split": "train",
            "weight": 0.4,
            "cache_path": null,
            "revision": null
          }
        ],
        "healing_shards": [],
        "healing_tokens": null
      },
      "evolution": {
        "rung0_thresholds": {
          "gate_entropy_min": 0.0,
          "gate_entropy_max": 4.0
        },
        "rung1_tokens": 300000,
        "rung2_tokens": 900000,
        "population": 24,
        "topk_keep": 0.45,
        "crossover_prob": 0.5,
        "parent_selection": "lexicase",
        "pareto_objectives": [
          "ppl_code",
          "ppl_math",
          "long_recall",
          "ppl_per_long_recall",
          "throughput",
          "ram",
          "novelty",
          "graph_entropy"
        ],
        "objectives": {
          "ppl_code": "min",
          "ppl_math": "min",
          "long_recall": "max",
          "ppl_per_long_recall": "min",
          "throughput": "max",
          "ram": "min",
          "novelty": "max",
          "graph_entropy": "max",
          "instability": "min"
        },
        "composite_metrics": [
          {
            "name": "ppl_per_long_recall",
            "op": "ratio",
            "numerator": "ppl_code",
            "denominator": "long_recall",
            "terms": {},
            "epsilon": 0.1
          }
        ],
        "promotion_prob": 0.4,
        "promotion_min_layers": 8,
        "promotion_min_moe_blocks": 2,
        "promotion_steps_multiplier": 1.5,
        "promotion_tokens_multiplier": 1.5,
        "promotion_min_router_entropy": 0.0,
        "promotion_min_recurrence_gain": 0.0,
        "promotion_max_instability": null
      },
      "priors": {
        "tokens_per_param": 4.0,
        "window_scale": 6.0,
        "rope_theta_default": 10000.0,
        "prior_weight": 0.0,
        "compute_penalty_weight": 0.0
      }
    }
  },
  {
    "id": "xover-18-2450",
    "parent": null,
    "metrics": {
      "layers": 14.0,
      "moe_blocks": 7.0,
      "graph_entropy": 2.712917603006569,
      "selector_blocks": 0.0,
      "selector_topk_avg": 0.0,
      "memory_blocks": 7.0,
      "recurrences": 0.0,
      "novelty": 0.8461538461538461,
      "params": 435214915.0,
      "kv_bytes_per_token": 14336,
      "throughput_proxy": 19.46274115114796,
      "ppl_code": 1.0,
      "ppl_math": 1.07,
      "throughput": 276.62251948101925,
      "ram": 0.8106509502977133,
      "long_recall": 0.942857142857143,
      "router_entropy": 0.6877559082848685,
      "router_lb": 0.025746022750224386,
      "router_load_max": 0.4990234375,
      "router_load_min": 0.0,
      "router_load_cv": 2.705186605453491,
      "capacity_overflow": 0.0,
      "max_grad_norm": 0.0,
      "instability": 0.0,
      "stop_reason_code": 3.0,
      "nan_seen": 0.0,
      "loss_spike": 9.39592719078064e-05,
      "prior_distance": 0.02312867796508752,
      "ppl_per_long_recall": 1.0606060606060606,
      "ppl_per_param": 2.2977153712666303e-09,
      "ppl_per_throughput": 0.003615034675687769
    },
    "spec": {
      "model": {
        "name": "phi-tiny-evo-creative",
        "emb": {
          "dim": 512,
          "vocab": 50257,
          "rope": null,
          "dropout": 0.0
        },
        "blocks": [
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": "yarn",
              "rope_theta": null,
              "sw": 128,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "local_global",
              "block_size": null,
              "block_stride": null,
              "global_stride": 64,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": null,
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 256,
                "stride": 32,
                "aggregator": "gate",
                "gating_weight": 0.25
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "moe",
              "hidden": 2048,
              "n_experts": 16,
              "k": 2,
              "capacity_factor": 1.2,
              "balance": 0.05,
              "shared": 1,
              "router_temperature": null,
              "router_type": "softmax",
              "router_bias_detached": false,
              "shared_expert": false,
              "router_aux_weight": null,
              "router_lb_weight": null,
              "drop_policy": "none",
              "experts": []
            },
            "ssm": null,
            "extras": [
              {
                "type": "custom",
                "name": "exp-gater",
                "params": {
                  "dim": 256
                }
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "moe",
              "hidden": 2048,
              "n_experts": 16,
              "k": 2,
              "capacity_factor": 1.2,
              "balance": 0.05,
              "shared": 1,
              "router_temperature": null,
              "router_type": "softmax",
              "router_bias_detached": false,
              "shared_expert": false,
              "router_aux_weight": null,
              "router_lb_weight": null,
              "drop_policy": "none",
              "experts": []
            },
            "ssm": null,
            "extras": [
              {
                "type": "custom",
                "name": "exp-gater",
                "params": {
                  "dim": 256
                }
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": {
              "kind": "mamba2",
              "d_state": 16,
              "d_conv": 4,
              "dt_rank": 8,
              "chunk": 128,
              "gate": 0.15
            },
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 512,
                "stride": 128,
                "aggregator": "attention",
                "gating_weight": 0.1191520977835257
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "moe",
              "hidden": 2048,
              "n_experts": 16,
              "k": 2,
              "capacity_factor": 1.2,
              "balance": 0.05,
              "shared": 1,
              "router_temperature": null,
              "router_type": "softmax",
              "router_bias_detached": false,
              "shared_expert": false,
              "router_aux_weight": null,
              "router_lb_weight": null,
              "drop_policy": "none",
              "experts": []
            },
            "ssm": null,
            "extras": [
              {
                "type": "custom",
                "name": "exp-gater",
                "params": {
                  "dim": 256
                }
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": {
              "kind": "mamba2",
              "d_state": 16,
              "d_conv": 4,
              "dt_rank": 8,
              "chunk": 128,
              "gate": 0.15
            },
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 512,
                "stride": 128,
                "aggregator": "attention",
                "gating_weight": 0.1191520977835257
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "moe",
              "hidden": 2048,
              "n_experts": 16,
              "k": 2,
              "capacity_factor": 1.2,
              "balance": 0.05,
              "shared": 1,
              "router_temperature": null,
              "router_type": "softmax",
              "router_bias_detached": false,
              "shared_expert": false,
              "router_aux_weight": null,
              "router_lb_weight": null,
              "drop_policy": "none",
              "experts": []
            },
            "ssm": null,
            "extras": [
              {
                "type": "custom",
                "name": "exp-gater",
                "params": {
                  "dim": 256
                }
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": {
              "kind": "mamba2",
              "d_state": 16,
              "d_conv": 4,
              "dt_rank": 8,
              "chunk": 128,
              "gate": 0.15
            },
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 512,
                "stride": 128,
                "aggregator": "attention",
                "gating_weight": 0.1191520977835257
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "moe",
              "hidden": 2048,
              "n_experts": 16,
              "k": 2,
              "capacity_factor": 1.2,
              "balance": 0.05,
              "shared": 1,
              "router_temperature": null,
              "router_type": "softmax",
              "router_bias_detached": false,
              "shared_expert": false,
              "router_aux_weight": null,
              "router_lb_weight": null,
              "drop_policy": "none",
              "experts": []
            },
            "ssm": null,
            "extras": [
              {
                "type": "custom",
                "name": "exp-gater",
                "params": {
                  "dim": 256
                }
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": {
              "kind": "mamba2",
              "d_state": 16,
              "d_conv": 4,
              "dt_rank": 8,
              "chunk": 128,
              "gate": 0.15
            },
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 512,
                "stride": 128,
                "aggregator": "attention",
                "gating_weight": 0.1191520977835257
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": "yarn",
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "moe",
              "hidden": 2048,
              "n_experts": 16,
              "k": 2,
              "capacity_factor": 1.2,
              "balance": 0.05,
              "shared": 1,
              "router_temperature": null,
              "router_type": "softmax",
              "router_bias_detached": false,
              "shared_expert": false,
              "router_aux_weight": null,
              "router_lb_weight": null,
              "drop_policy": "none",
              "experts": []
            },
            "ssm": null,
            "extras": [
              {
                "type": "gated",
                "targets": [
                  "attn",
                  "ffn",
                  "ssm"
                ],
                "init_weight": 0.2,
                "learnable": true
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": "yarn",
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "moe",
              "hidden": 2048,
              "n_experts": 16,
              "k": 2,
              "capacity_factor": 1.2,
              "balance": 0.05,
              "shared": 1,
              "router_temperature": null,
              "router_type": "softmax",
              "router_bias_detached": false,
              "shared_expert": false,
              "router_aux_weight": null,
              "router_lb_weight": null,
              "drop_policy": "none",
              "experts": []
            },
            "ssm": null,
            "extras": [
              {
                "type": "gated",
                "targets": [
                  "attn",
                  "ffn",
                  "ssm"
                ],
                "init_weight": 0.2,
                "learnable": true
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": null,
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 1024,
                "stride": 64,
                "aggregator": "gate",
                "gating_weight": 0.35
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": null,
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 1024,
                "stride": 64,
                "aggregator": "gate",
                "gating_weight": 0.35
              }
            ]
          }
        ],
        "head": {
          "tie_embeddings": true,
          "vocab": 50257
        },
        "norm": "layernorm",
        "recurrences": []
      },
      "train": {
        "lr": 0.0008,
        "warmup": 500,
        "clip": 1.0,
        "bf16": true,
        "grad_checkpoint": true,
        "max_tokens": 520000,
        "weight_decay": 0.02,
        "seed": 4242,
        "router_lb_coeff": 0.01,
        "router_entropy_coeff": 0.005,
        "entropy_threshold": 0.5,
        "entropy_patience": 3,
        "instability_threshold": 500.0,
        "no_improve_patience": 20,
        "improvement_tolerance": 0.001,
        "ppl_stop_threshold": null,
        "init_checkpoint": null,
        "optimizer": {
          "name": "adamw",
          "lr": null,
          "betas": null,
          "eps": null,
          "weight_decay": null
        }
      },
      "data": {
        "tokenizer": "gpt2",
        "hf_revision": "main",
        "seq_len": 512,
        "batch_size": 1,
        "workers": 0,
        "shards": [
          {
            "name": "ag_news",
            "split": "train",
            "weight": 0.25,
            "cache_path": null,
            "revision": null
          },
          {
            "name": "wikitext",
            "split": "wikitext-2-raw-v1",
            "weight": 0.35,
            "cache_path": null,
            "revision": null
          },
          {
            "name": "mbpp",
            "split": "train",
            "weight": 0.4,
            "cache_path": null,
            "revision": null
          }
        ],
        "healing_shards": [],
        "healing_tokens": null
      },
      "evolution": {
        "rung0_thresholds": {
          "gate_entropy_min": 0.0,
          "gate_entropy_max": 4.0
        },
        "rung1_tokens": 300000,
        "rung2_tokens": 900000,
        "population": 24,
        "topk_keep": 0.45,
        "crossover_prob": 0.5,
        "parent_selection": "lexicase",
        "pareto_objectives": [
          "ppl_code",
          "ppl_math",
          "long_recall",
          "ppl_per_long_recall",
          "throughput",
          "ram",
          "novelty",
          "graph_entropy"
        ],
        "objectives": {
          "ppl_code": "min",
          "ppl_math": "min",
          "long_recall": "max",
          "ppl_per_long_recall": "min",
          "throughput": "max",
          "ram": "min",
          "novelty": "max",
          "graph_entropy": "max",
          "instability": "min"
        },
        "composite_metrics": [
          {
            "name": "ppl_per_long_recall",
            "op": "ratio",
            "numerator": "ppl_code",
            "denominator": "long_recall",
            "terms": {},
            "epsilon": 0.1
          }
        ],
        "promotion_prob": 0.4,
        "promotion_min_layers": 8,
        "promotion_min_moe_blocks": 2,
        "promotion_steps_multiplier": 1.5,
        "promotion_tokens_multiplier": 1.5,
        "promotion_min_router_entropy": 0.0,
        "promotion_min_recurrence_gain": 0.0,
        "promotion_max_instability": null
      },
      "priors": {
        "tokens_per_param": 4.0,
        "window_scale": 6.0,
        "rope_theta_default": 10000.0,
        "prior_weight": 0.0,
        "compute_penalty_weight": 0.0
      }
    }
  },
  {
    "id": "tune_router_coeffs-19-1edc",
    "parent": "add_extra_combo-17-7ee7",
    "metrics": {
      "layers": 13.0,
      "moe_blocks": 5.0,
      "graph_entropy": 2.7110214420242857,
      "selector_blocks": 0.0,
      "selector_topk_avg": 0.0,
      "memory_blocks": 8.0,
      "recurrences": 0.0,
      "novelty": 0.0,
      "params": 330954756.0,
      "kv_bytes_per_token": 13312,
      "throughput_proxy": 22.572173169378697,
      "ppl_code": 1.0,
      "ppl_math": 1.05,
      "throughput": 337.81709793236473,
      "ram": 0.616451270878315,
      "long_recall": 1.0307692307692307,
      "router_entropy": 0.6850104570388794,
      "router_lb": 0.024529720097780226,
      "router_load_max": 0.5,
      "router_load_min": 0.0,
      "router_load_cv": 2.7294747829437256,
      "capacity_overflow": 0.0,
      "max_grad_norm": 0.0,
      "instability": 0.0,
      "stop_reason_code": 3.0,
      "nan_seen": 0.0,
      "loss_spike": 0.0,
      "prior_distance": 0.02312867796508752,
      "ppl_per_long_recall": 0.9701492537313434,
      "ppl_per_param": 3.021561049873536e-09,
      "ppl_per_throughput": 0.0029601817259119687
    },
    "spec": {
      "model": {
        "name": "phi-tiny-evo-creative",
        "emb": {
          "dim": 512,
          "vocab": 50257,
          "rope": null,
          "dropout": 0.0
        },
        "blocks": [
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "moe",
              "hidden": 2048,
              "n_experts": 16,
              "k": 2,
              "capacity_factor": 1.2,
              "balance": 0.05,
              "shared": 1,
              "router_temperature": null,
              "router_type": "softmax",
              "router_bias_detached": false,
              "shared_expert": false,
              "router_aux_weight": null,
              "router_lb_weight": null,
              "drop_policy": "none",
              "experts": []
            },
            "ssm": null,
            "extras": [
              {
                "type": "custom",
                "name": "exp-gater",
                "params": {
                  "dim": 256
                }
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": "yarn",
              "rope_theta": null,
              "sw": 128,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "local_global",
              "block_size": null,
              "block_stride": null,
              "global_stride": 64,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": null,
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 256,
                "stride": 32,
                "aggregator": "gate",
                "gating_weight": 0.25
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "moe",
              "hidden": 2048,
              "n_experts": 16,
              "k": 2,
              "capacity_factor": 1.2,
              "balance": 0.05,
              "shared": 1,
              "router_temperature": null,
              "router_type": "softmax",
              "router_bias_detached": false,
              "shared_expert": false,
              "router_aux_weight": null,
              "router_lb_weight": null,
              "drop_policy": "none",
              "experts": []
            },
            "ssm": null,
            "extras": [
              {
                "type": "custom",
                "name": "exp-gater",
                "params": {
                  "dim": 256
                }
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": {
              "kind": "mamba2",
              "d_state": 16,
              "d_conv": 4,
              "dt_rank": 8,
              "chunk": 128,
              "gate": 0.15
            },
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 512,
                "stride": 128,
                "aggregator": "attention",
                "gating_weight": 0.1191520977835257
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "moe",
              "hidden": 2048,
              "n_experts": 16,
              "k": 2,
              "capacity_factor": 1.2,
              "balance": 0.05,
              "shared": 1,
              "router_temperature": null,
              "router_type": "softmax",
              "router_bias_detached": false,
              "shared_expert": false,
              "router_aux_weight": null,
              "router_lb_weight": null,
              "drop_policy": "none",
              "experts": []
            },
            "ssm": null,
            "extras": [
              {
                "type": "custom",
                "name": "exp-gater",
                "params": {
                  "dim": 256
                }
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": {
              "kind": "mamba2",
              "d_state": 16,
              "d_conv": 4,
              "dt_rank": 8,
              "chunk": 128,
              "gate": 0.15
            },
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 512,
                "stride": 128,
                "aggregator": "attention",
                "gating_weight": 0.1191520977835257
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": "yarn",
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "moe",
              "hidden": 2048,
              "n_experts": 16,
              "k": 2,
              "capacity_factor": 1.2,
              "balance": 0.05,
              "shared": 1,
              "router_temperature": null,
              "router_type": "softmax",
              "router_bias_detached": false,
              "shared_expert": false,
              "router_aux_weight": null,
              "router_lb_weight": null,
              "drop_policy": "none",
              "experts": []
            },
            "ssm": null,
            "extras": [
              {
                "type": "gated",
                "targets": [
                  "attn",
                  "ffn",
                  "ssm"
                ],
                "init_weight": 0.2,
                "learnable": true
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": null,
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 1024,
                "stride": 64,
                "aggregator": "gate",
                "gating_weight": 0.35
              },
              {
                "type": "custom",
                "name": "exp-4338",
                "params": {
                  "dim": 1024,
                  "activation": "relu",
                  "notes": "auto-generated"
                }
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": {
              "kind": "mamba2",
              "d_state": 16,
              "d_conv": 4,
              "dt_rank": 8,
              "chunk": 128,
              "gate": 0.15
            },
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 512,
                "stride": 128,
                "aggregator": "attention",
                "gating_weight": 0.1191520977835257
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": "yarn",
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "moe",
              "hidden": 2048,
              "n_experts": 16,
              "k": 2,
              "capacity_factor": 1.2,
              "balance": 0.05,
              "shared": 1,
              "router_temperature": null,
              "router_type": "softmax",
              "router_bias_detached": false,
              "shared_expert": false,
              "router_aux_weight": null,
              "router_lb_weight": null,
              "drop_policy": "none",
              "experts": []
            },
            "ssm": null,
            "extras": [
              {
                "type": "gated",
                "targets": [
                  "attn",
                  "ffn",
                  "ssm"
                ],
                "init_weight": 0.2,
                "learnable": true
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": null,
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 1024,
                "stride": 64,
                "aggregator": "gate",
                "gating_weight": 0.35
              },
              {
                "type": "gated",
                "targets": [
                  "attn",
                  "ffn"
                ],
                "init_weight": 0.17686717452555856,
                "learnable": true
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": null,
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 1024,
                "stride": 64,
                "aggregator": "gate",
                "gating_weight": 0.35
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": null,
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 1024,
                "stride": 64,
                "aggregator": "gate",
                "gating_weight": 0.35
              }
            ]
          }
        ],
        "head": {
          "tie_embeddings": true,
          "vocab": 50257
        },
        "norm": "layernorm",
        "recurrences": []
      },
      "train": {
        "lr": 0.0008,
        "warmup": 500,
        "clip": 1.0,
        "bf16": true,
        "grad_checkpoint": true,
        "max_tokens": 520000,
        "weight_decay": 0.02,
        "seed": 4242,
        "router_lb_coeff": 0.01,
        "router_entropy_coeff": 0.005,
        "entropy_threshold": 0.5,
        "entropy_patience": 3,
        "instability_threshold": 500.0,
        "no_improve_patience": 20,
        "improvement_tolerance": 0.001,
        "ppl_stop_threshold": null,
        "init_checkpoint": null,
        "optimizer": {
          "name": "adamw",
          "lr": null,
          "betas": null,
          "eps": null,
          "weight_decay": null
        }
      },
      "data": {
        "tokenizer": "gpt2",
        "hf_revision": "main",
        "seq_len": 512,
        "batch_size": 1,
        "workers": 0,
        "shards": [
          {
            "name": "ag_news",
            "split": "train",
            "weight": 0.25,
            "cache_path": null,
            "revision": null
          },
          {
            "name": "wikitext",
            "split": "wikitext-2-raw-v1",
            "weight": 0.35,
            "cache_path": null,
            "revision": null
          },
          {
            "name": "mbpp",
            "split": "train",
            "weight": 0.4,
            "cache_path": null,
            "revision": null
          }
        ],
        "healing_shards": [],
        "healing_tokens": null
      },
      "evolution": {
        "rung0_thresholds": {
          "gate_entropy_min": 0.0,
          "gate_entropy_max": 4.0
        },
        "rung1_tokens": 300000,
        "rung2_tokens": 900000,
        "population": 24,
        "topk_keep": 0.45,
        "crossover_prob": 0.5,
        "parent_selection": "lexicase",
        "pareto_objectives": [
          "ppl_code",
          "ppl_math",
          "long_recall",
          "ppl_per_long_recall",
          "throughput",
          "ram",
          "novelty",
          "graph_entropy"
        ],
        "objectives": {
          "ppl_code": "min",
          "ppl_math": "min",
          "long_recall": "max",
          "ppl_per_long_recall": "min",
          "throughput": "max",
          "ram": "min",
          "novelty": "max",
          "graph_entropy": "max",
          "instability": "min"
        },
        "composite_metrics": [
          {
            "name": "ppl_per_long_recall",
            "op": "ratio",
            "numerator": "ppl_code",
            "denominator": "long_recall",
            "terms": {},
            "epsilon": 0.1
          }
        ],
        "promotion_prob": 0.4,
        "promotion_min_layers": 8,
        "promotion_min_moe_blocks": 2,
        "promotion_steps_multiplier": 1.5,
        "promotion_tokens_multiplier": 1.5,
        "promotion_min_router_entropy": 0.0,
        "promotion_min_recurrence_gain": 0.0,
        "promotion_max_instability": null
      },
      "priors": {
        "tokens_per_param": 4.0,
        "window_scale": 6.0,
        "rope_theta_default": 10000.0,
        "prior_weight": 0.0,
        "compute_penalty_weight": 0.0
      }
    }
  },
  {
    "id": "xover-20-d384",
    "parent": null,
    "metrics": {
      "layers": 2.0,
      "moe_blocks": 1.0,
      "graph_entropy": 2.3660159754066603,
      "selector_blocks": 0.0,
      "selector_topk_avg": 0.0,
      "memory_blocks": 1.0,
      "recurrences": 0.0,
      "novelty": 1.4285714285714286,
      "params": 84338017.0,
      "kv_bytes_per_token": 2048,
      "throughput_proxy": 953.67431640625,
      "ppl_code": 1.0,
      "ppl_math": 1.01,
      "throughput": 724.214731695039,
      "ram": 0.157091798260808,
      "long_recall": 0.7,
      "router_entropy": 0.6928175687789917,
      "router_lb": 0.025722503662109375,
      "router_load_max": 0.4873046875,
      "router_load_min": 0.0,
      "router_load_cv": 2.650275230407715,
      "capacity_overflow": 0.0,
      "max_grad_norm": 0.0,
      "instability": 0.0,
      "stop_reason_code": 3.0,
      "nan_seen": 0.0,
      "loss_spike": 1.3923505321145058e-05,
      "prior_distance": 0.16190069949827213,
      "ppl_per_long_recall": 1.4285714285714286,
      "ppl_per_param": 1.185704899843685e-08,
      "ppl_per_throughput": 0.00138080593536047
    },
    "spec": {
      "model": {
        "name": "phi-tiny-evo-creative",
        "emb": {
          "dim": 512,
          "vocab": 50257,
          "rope": null,
          "dropout": 0.0
        },
        "blocks": [
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": "yarn",
              "rope_theta": null,
              "sw": 128,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "local_global",
              "block_size": null,
              "block_stride": null,
              "global_stride": 64,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": null,
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 256,
                "stride": 32,
                "aggregator": "gate",
                "gating_weight": 0.25
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "moe",
              "hidden": 2048,
              "n_experts": 16,
              "k": 2,
              "capacity_factor": 1.2,
              "balance": 0.05,
              "shared": 1,
              "router_temperature": null,
              "router_type": "softmax",
              "router_bias_detached": false,
              "shared_expert": false,
              "router_aux_weight": null,
              "router_lb_weight": null,
              "drop_policy": "none",
              "experts": []
            },
            "ssm": null,
            "extras": [
              {
                "type": "custom",
                "name": "exp-gater",
                "params": {
                  "dim": 256
                }
              }
            ]
          }
        ],
        "head": {
          "tie_embeddings": true,
          "vocab": 50257
        },
        "norm": "layernorm",
        "recurrences": []
      },
      "train": {
        "lr": 0.0008,
        "warmup": 500,
        "clip": 1.0,
        "bf16": true,
        "grad_checkpoint": true,
        "max_tokens": 520000,
        "weight_decay": 0.02,
        "seed": 4242,
        "router_lb_coeff": 0.01,
        "router_entropy_coeff": 0.005,
        "entropy_threshold": 0.5,
        "entropy_patience": 3,
        "instability_threshold": 500.0,
        "no_improve_patience": 20,
        "improvement_tolerance": 0.001,
        "ppl_stop_threshold": null,
        "init_checkpoint": null,
        "optimizer": {
          "name": "adamw",
          "lr": null,
          "betas": null,
          "eps": null,
          "weight_decay": null
        }
      },
      "data": {
        "tokenizer": "gpt2",
        "hf_revision": "main",
        "seq_len": 512,
        "batch_size": 1,
        "workers": 0,
        "shards": [
          {
            "name": "ag_news",
            "split": "train",
            "weight": 0.25,
            "cache_path": null,
            "revision": null
          },
          {
            "name": "wikitext",
            "split": "wikitext-2-raw-v1",
            "weight": 0.35,
            "cache_path": null,
            "revision": null
          },
          {
            "name": "mbpp",
            "split": "train",
            "weight": 0.4,
            "cache_path": null,
            "revision": null
          }
        ],
        "healing_shards": [],
        "healing_tokens": null
      },
      "evolution": {
        "rung0_thresholds": {
          "gate_entropy_min": 0.0,
          "gate_entropy_max": 4.0
        },
        "rung1_tokens": 300000,
        "rung2_tokens": 900000,
        "population": 24,
        "topk_keep": 0.45,
        "crossover_prob": 0.5,
        "parent_selection": "lexicase",
        "pareto_objectives": [
          "ppl_code",
          "ppl_math",
          "long_recall",
          "ppl_per_long_recall",
          "throughput",
          "ram",
          "novelty",
          "graph_entropy"
        ],
        "objectives": {
          "ppl_code": "min",
          "ppl_math": "min",
          "long_recall": "max",
          "ppl_per_long_recall": "min",
          "throughput": "max",
          "ram": "min",
          "novelty": "max",
          "graph_entropy": "max",
          "instability": "min"
        },
        "composite_metrics": [
          {
            "name": "ppl_per_long_recall",
            "op": "ratio",
            "numerator": "ppl_code",
            "denominator": "long_recall",
            "terms": {},
            "epsilon": 0.1
          }
        ],
        "promotion_prob": 0.4,
        "promotion_min_layers": 8,
        "promotion_min_moe_blocks": 2,
        "promotion_steps_multiplier": 1.5,
        "promotion_tokens_multiplier": 1.5,
        "promotion_min_router_entropy": 0.0,
        "promotion_min_recurrence_gain": 0.0,
        "promotion_max_instability": null
      },
      "priors": {
        "tokens_per_param": 4.0,
        "window_scale": 6.0,
        "rope_theta_default": 10000.0,
        "prior_weight": 0.0,
        "compute_penalty_weight": 0.0
      }
    }
  },
  {
    "id": "xover-24-7280",
    "parent": null,
    "metrics": {
      "layers": 21.0,
      "moe_blocks": 9.0,
      "graph_entropy": 2.7390990427381112,
      "selector_blocks": 0.0,
      "selector_topk_avg": 0.0,
      "memory_blocks": 12.0,
      "recurrences": 0.0,
      "novelty": 1.7575757575757576,
      "params": 564703397.0,
      "kv_bytes_per_token": 21504,
      "throughput_proxy": 8.650107178287982,
      "ppl_code": 1.0,
      "ppl_math": 1.09,
      "throughput": 236.2590681524579,
      "ram": 1.0518420431762934,
      "long_recall": 1.0142857142857142,
      "router_entropy": 0.6877096825175815,
      "router_lb": 0.022939921046296757,
      "router_load_max": 0.48046875,
      "router_load_min": 0.0,
      "router_load_cv": 2.5608036518096924,
      "capacity_overflow": 0.0,
      "max_grad_norm": 0.0,
      "instability": 0.0,
      "stop_reason_code": 3.0,
      "nan_seen": 0.0,
      "loss_spike": 0.0013075601309537888,
      "prior_distance": 0.014718249869008063,
      "ppl_per_long_recall": 0.9859154929577465,
      "ppl_per_param": 1.7708411270633812e-09,
      "ppl_per_throughput": 0.004232641768292679
    },
    "spec": {
      "model": {
        "name": "phi-tiny-evo-creative",
        "emb": {
          "dim": 512,
          "vocab": 50257,
          "rope": null,
          "dropout": 0.0
        },
        "blocks": [
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "moe",
              "hidden": 2048,
              "n_experts": 16,
              "k": 2,
              "capacity_factor": 1.2,
              "balance": 0.05,
              "shared": 1,
              "router_temperature": null,
              "router_type": "softmax",
              "router_bias_detached": false,
              "shared_expert": false,
              "router_aux_weight": null,
              "router_lb_weight": null,
              "drop_policy": "none",
              "experts": []
            },
            "ssm": null,
            "extras": [
              {
                "type": "custom",
                "name": "exp-gater",
                "params": {
                  "dim": 256
                }
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "moe",
              "hidden": 2048,
              "n_experts": 16,
              "k": 2,
              "capacity_factor": 1.2,
              "balance": 0.05,
              "shared": 1,
              "router_temperature": null,
              "router_type": "softmax",
              "router_bias_detached": false,
              "shared_expert": false,
              "router_aux_weight": null,
              "router_lb_weight": null,
              "drop_policy": "none",
              "experts": []
            },
            "ssm": null,
            "extras": [
              {
                "type": "custom",
                "name": "exp-gater",
                "params": {
                  "dim": 256
                }
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": {
              "kind": "mamba2",
              "d_state": 16,
              "d_conv": 4,
              "dt_rank": 8,
              "chunk": 128,
              "gate": 0.15
            },
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 512,
                "stride": 128,
                "aggregator": "attention",
                "gating_weight": 0.1191520977835257
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "moe",
              "hidden": 2048,
              "n_experts": 16,
              "k": 2,
              "capacity_factor": 1.2,
              "balance": 0.05,
              "shared": 1,
              "router_temperature": null,
              "router_type": "softmax",
              "router_bias_detached": false,
              "shared_expert": false,
              "router_aux_weight": null,
              "router_lb_weight": null,
              "drop_policy": "none",
              "experts": []
            },
            "ssm": null,
            "extras": [
              {
                "type": "custom",
                "name": "exp-gater",
                "params": {
                  "dim": 256
                }
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": {
              "kind": "mamba2",
              "d_state": 16,
              "d_conv": 4,
              "dt_rank": 8,
              "chunk": 128,
              "gate": 0.15
            },
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 512,
                "stride": 128,
                "aggregator": "attention",
                "gating_weight": 0.1191520977835257
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": "yarn",
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "moe",
              "hidden": 2048,
              "n_experts": 16,
              "k": 2,
              "capacity_factor": 1.2,
              "balance": 0.05,
              "shared": 1,
              "router_temperature": null,
              "router_type": "softmax",
              "router_bias_detached": false,
              "shared_expert": false,
              "router_aux_weight": null,
              "router_lb_weight": null,
              "drop_policy": "none",
              "experts": []
            },
            "ssm": null,
            "extras": [
              {
                "type": "gated",
                "targets": [
                  "attn",
                  "ffn",
                  "ssm"
                ],
                "init_weight": 0.2,
                "learnable": true
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": null,
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 1024,
                "stride": 64,
                "aggregator": "gate",
                "gating_weight": 0.35
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": {
              "kind": "mamba2",
              "d_state": 16,
              "d_conv": 4,
              "dt_rank": 8,
              "chunk": 128,
              "gate": 0.15
            },
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 512,
                "stride": 128,
                "aggregator": "attention",
                "gating_weight": 0.1191520977835257
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": "yarn",
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "moe",
              "hidden": 2048,
              "n_experts": 16,
              "k": 2,
              "capacity_factor": 1.2,
              "balance": 0.05,
              "shared": 1,
              "router_temperature": null,
              "router_type": "softmax",
              "router_bias_detached": false,
              "shared_expert": false,
              "router_aux_weight": null,
              "router_lb_weight": null,
              "drop_policy": "none",
              "experts": []
            },
            "ssm": null,
            "extras": [
              {
                "type": "gated",
                "targets": [
                  "attn",
                  "ffn",
                  "ssm"
                ],
                "init_weight": 0.2,
                "learnable": true
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": "yarn",
              "rope_theta": null,
              "sw": 128,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "local_global",
              "block_size": null,
              "block_stride": null,
              "global_stride": 64,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": null,
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 256,
                "stride": 32,
                "aggregator": "gate",
                "gating_weight": 0.25
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "moe",
              "hidden": 2048,
              "n_experts": 16,
              "k": 2,
              "capacity_factor": 1.2,
              "balance": 0.05,
              "shared": 1,
              "router_temperature": null,
              "router_type": "softmax",
              "router_bias_detached": false,
              "shared_expert": false,
              "router_aux_weight": null,
              "router_lb_weight": null,
              "drop_policy": "none",
              "experts": []
            },
            "ssm": null,
            "extras": [
              {
                "type": "custom",
                "name": "exp-gater",
                "params": {
                  "dim": 256
                }
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": {
              "kind": "mamba2",
              "d_state": 16,
              "d_conv": 4,
              "dt_rank": 8,
              "chunk": 128,
              "gate": 0.15
            },
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 512,
                "stride": 128,
                "aggregator": "attention",
                "gating_weight": 0.1191520977835257
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "moe",
              "hidden": 2048,
              "n_experts": 16,
              "k": 2,
              "capacity_factor": 1.2,
              "balance": 0.05,
              "shared": 1,
              "router_temperature": null,
              "router_type": "softmax",
              "router_bias_detached": false,
              "shared_expert": false,
              "router_aux_weight": null,
              "router_lb_weight": null,
              "drop_policy": "none",
              "experts": []
            },
            "ssm": null,
            "extras": [
              {
                "type": "custom",
                "name": "exp-gater",
                "params": {
                  "dim": 256
                }
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": {
              "kind": "mamba2",
              "d_state": 16,
              "d_conv": 4,
              "dt_rank": 8,
              "chunk": 128,
              "gate": 0.15
            },
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 512,
                "stride": 128,
                "aggregator": "attention",
                "gating_weight": 0.1191520977835257
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": "yarn",
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "moe",
              "hidden": 2048,
              "n_experts": 16,
              "k": 2,
              "capacity_factor": 1.2,
              "balance": 0.05,
              "shared": 1,
              "router_temperature": null,
              "router_type": "softmax",
              "router_bias_detached": false,
              "shared_expert": false,
              "router_aux_weight": null,
              "router_lb_weight": null,
              "drop_policy": "none",
              "experts": []
            },
            "ssm": null,
            "extras": [
              {
                "type": "gated",
                "targets": [
                  "attn",
                  "ffn",
                  "ssm"
                ],
                "init_weight": 0.2,
                "learnable": true
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": null,
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 1024,
                "stride": 64,
                "aggregator": "gate",
                "gating_weight": 0.35
              },
              {
                "type": "custom",
                "name": "exp-4338",
                "params": {
                  "dim": 1024,
                  "activation": "relu",
                  "notes": "auto-generated"
                }
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": {
              "kind": "mamba2",
              "d_state": 16,
              "d_conv": 4,
              "dt_rank": 8,
              "chunk": 128,
              "gate": 0.15
            },
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 512,
                "stride": 128,
                "aggregator": "attention",
                "gating_weight": 0.1191520977835257
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": "yarn",
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "moe",
              "hidden": 2048,
              "n_experts": 16,
              "k": 2,
              "capacity_factor": 1.2,
              "balance": 0.05,
              "shared": 1,
              "router_temperature": null,
              "router_type": "softmax",
              "router_bias_detached": false,
              "shared_expert": false,
              "router_aux_weight": null,
              "router_lb_weight": null,
              "drop_policy": "none",
              "experts": []
            },
            "ssm": null,
            "extras": [
              {
                "type": "gated",
                "targets": [
                  "attn",
                  "ffn",
                  "ssm"
                ],
                "init_weight": 0.2,
                "learnable": true
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": null,
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 1024,
                "stride": 64,
                "aggregator": "gate",
                "gating_weight": 0.35
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": null,
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 1024,
                "stride": 64,
                "aggregator": "gate",
                "gating_weight": 0.35
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": null,
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 1024,
                "stride": 64,
                "aggregator": "gate",
                "gating_weight": 0.35
              }
            ]
          }
        ],
        "head": {
          "tie_embeddings": true,
          "vocab": 50257
        },
        "norm": "layernorm",
        "recurrences": []
      },
      "train": {
        "lr": 0.0008,
        "warmup": 500,
        "clip": 1.0,
        "bf16": true,
        "grad_checkpoint": true,
        "max_tokens": 520000,
        "weight_decay": 0.02,
        "seed": 4242,
        "router_lb_coeff": 0.01,
        "router_entropy_coeff": 0.005,
        "entropy_threshold": 0.5,
        "entropy_patience": 3,
        "instability_threshold": 500.0,
        "no_improve_patience": 20,
        "improvement_tolerance": 0.001,
        "ppl_stop_threshold": null,
        "init_checkpoint": null,
        "optimizer": {
          "name": "adamw",
          "lr": null,
          "betas": null,
          "eps": null,
          "weight_decay": null
        }
      },
      "data": {
        "tokenizer": "gpt2",
        "hf_revision": "main",
        "seq_len": 512,
        "batch_size": 1,
        "workers": 0,
        "shards": [
          {
            "name": "ag_news",
            "split": "train",
            "weight": 0.25,
            "cache_path": null,
            "revision": null
          },
          {
            "name": "wikitext",
            "split": "wikitext-2-raw-v1",
            "weight": 0.35,
            "cache_path": null,
            "revision": null
          },
          {
            "name": "mbpp",
            "split": "train",
            "weight": 0.4,
            "cache_path": null,
            "revision": null
          }
        ],
        "healing_shards": [],
        "healing_tokens": null
      },
      "evolution": {
        "rung0_thresholds": {
          "gate_entropy_min": 0.0,
          "gate_entropy_max": 4.0
        },
        "rung1_tokens": 300000,
        "rung2_tokens": 900000,
        "population": 24,
        "topk_keep": 0.45,
        "crossover_prob": 0.5,
        "parent_selection": "lexicase",
        "pareto_objectives": [
          "ppl_code",
          "ppl_math",
          "long_recall",
          "ppl_per_long_recall",
          "throughput",
          "ram",
          "novelty",
          "graph_entropy"
        ],
        "objectives": {
          "ppl_code": "min",
          "ppl_math": "min",
          "long_recall": "max",
          "ppl_per_long_recall": "min",
          "throughput": "max",
          "ram": "min",
          "novelty": "max",
          "graph_entropy": "max",
          "instability": "min"
        },
        "composite_metrics": [
          {
            "name": "ppl_per_long_recall",
            "op": "ratio",
            "numerator": "ppl_code",
            "denominator": "long_recall",
            "terms": {},
            "epsilon": 0.1
          }
        ],
        "promotion_prob": 0.4,
        "promotion_min_layers": 8,
        "promotion_min_moe_blocks": 2,
        "promotion_steps_multiplier": 1.5,
        "promotion_tokens_multiplier": 1.5,
        "promotion_min_router_entropy": 0.0,
        "promotion_min_recurrence_gain": 0.0,
        "promotion_max_instability": null
      },
      "priors": {
        "tokens_per_param": 4.0,
        "window_scale": 6.0,
        "rope_theta_default": 10000.0,
        "prior_weight": 0.0,
        "compute_penalty_weight": 0.0
      }
    }
  },
  {
    "id": "xover-25-549e",
    "parent": null,
    "metrics": {
      "layers": 23.0,
      "moe_blocks": 10.0,
      "graph_entropy": 2.7659264991583576,
      "selector_blocks": 0.0,
      "selector_topk_avg": 0.0,
      "memory_blocks": 13.0,
      "recurrences": 0.0,
      "novelty": 1.1428571428571428,
      "params": 623539412.0,
      "kv_bytes_per_token": 23552,
      "throughput_proxy": 7.211147950141777,
      "ppl_code": 1.0,
      "ppl_math": 1.1,
      "throughput": 196.85461916811644,
      "ram": 1.1614326611161232,
      "long_recall": 1.017391304347826,
      "router_entropy": 0.6859803557395935,
      "router_lb": 0.027179397642612457,
      "router_load_max": 0.5,
      "router_load_min": 0.0,
      "router_load_cv": 2.7294747829437256,
      "capacity_overflow": 0.0,
      "max_grad_norm": 0.0,
      "instability": 0.0,
      "stop_reason_code": 3.0,
      "nan_seen": 0.0,
      "loss_spike": 0.0,
      "prior_distance": 0.026983458161321493,
      "ppl_per_long_recall": 0.982905982905983,
      "ppl_per_param": 1.6037478638158641e-09,
      "ppl_per_throughput": 0.005079890958240542
    },
    "spec": {
      "model": {
        "name": "phi-tiny-evo-creative",
        "emb": {
          "dim": 512,
          "vocab": 50257,
          "rope": null,
          "dropout": 0.0
        },
        "blocks": [
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": "yarn",
              "rope_theta": null,
              "sw": 128,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "local_global",
              "block_size": null,
              "block_stride": null,
              "global_stride": 64,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": null,
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 256,
                "stride": 32,
                "aggregator": "gate",
                "gating_weight": 0.25
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "moe",
              "hidden": 2048,
              "n_experts": 16,
              "k": 2,
              "capacity_factor": 1.2,
              "balance": 0.05,
              "shared": 1,
              "router_temperature": null,
              "router_type": "softmax",
              "router_bias_detached": false,
              "shared_expert": false,
              "router_aux_weight": null,
              "router_lb_weight": null,
              "drop_policy": "none",
              "experts": []
            },
            "ssm": null,
            "extras": [
              {
                "type": "custom",
                "name": "exp-gater",
                "params": {
                  "dim": 256
                }
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "moe",
              "hidden": 2048,
              "n_experts": 16,
              "k": 2,
              "capacity_factor": 1.2,
              "balance": 0.05,
              "shared": 1,
              "router_temperature": null,
              "router_type": "softmax",
              "router_bias_detached": false,
              "shared_expert": false,
              "router_aux_weight": null,
              "router_lb_weight": null,
              "drop_policy": "none",
              "experts": []
            },
            "ssm": null,
            "extras": [
              {
                "type": "custom",
                "name": "exp-gater",
                "params": {
                  "dim": 256
                }
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": {
              "kind": "mamba2",
              "d_state": 16,
              "d_conv": 4,
              "dt_rank": 8,
              "chunk": 128,
              "gate": 0.15
            },
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 512,
                "stride": 128,
                "aggregator": "attention",
                "gating_weight": 0.1191520977835257
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "moe",
              "hidden": 2048,
              "n_experts": 16,
              "k": 2,
              "capacity_factor": 1.2,
              "balance": 0.05,
              "shared": 1,
              "router_temperature": null,
              "router_type": "softmax",
              "router_bias_detached": false,
              "shared_expert": false,
              "router_aux_weight": null,
              "router_lb_weight": null,
              "drop_policy": "none",
              "experts": []
            },
            "ssm": null,
            "extras": [
              {
                "type": "custom",
                "name": "exp-gater",
                "params": {
                  "dim": 256
                }
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": {
              "kind": "mamba2",
              "d_state": 16,
              "d_conv": 4,
              "dt_rank": 8,
              "chunk": 128,
              "gate": 0.15
            },
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 512,
                "stride": 128,
                "aggregator": "attention",
                "gating_weight": 0.1191520977835257
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "moe",
              "hidden": 2048,
              "n_experts": 16,
              "k": 2,
              "capacity_factor": 1.2,
              "balance": 0.05,
              "shared": 1,
              "router_temperature": null,
              "router_type": "softmax",
              "router_bias_detached": false,
              "shared_expert": false,
              "router_aux_weight": null,
              "router_lb_weight": null,
              "drop_policy": "none",
              "experts": []
            },
            "ssm": null,
            "extras": [
              {
                "type": "custom",
                "name": "exp-gater",
                "params": {
                  "dim": 256
                }
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": {
              "kind": "mamba2",
              "d_state": 16,
              "d_conv": 4,
              "dt_rank": 8,
              "chunk": 128,
              "gate": 0.15
            },
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 512,
                "stride": 128,
                "aggregator": "attention",
                "gating_weight": 0.1191520977835257
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "moe",
              "hidden": 2048,
              "n_experts": 16,
              "k": 2,
              "capacity_factor": 1.2,
              "balance": 0.05,
              "shared": 1,
              "router_temperature": null,
              "router_type": "softmax",
              "router_bias_detached": false,
              "shared_expert": false,
              "router_aux_weight": null,
              "router_lb_weight": null,
              "drop_policy": "none",
              "experts": []
            },
            "ssm": null,
            "extras": [
              {
                "type": "custom",
                "name": "exp-gater",
                "params": {
                  "dim": 256
                }
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": {
              "kind": "mamba2",
              "d_state": 16,
              "d_conv": 4,
              "dt_rank": 8,
              "chunk": 128,
              "gate": 0.15
            },
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 512,
                "stride": 128,
                "aggregator": "attention",
                "gating_weight": 0.1191520977835257
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": "yarn",
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "moe",
              "hidden": 2048,
              "n_experts": 16,
              "k": 2,
              "capacity_factor": 1.2,
              "balance": 0.05,
              "shared": 1,
              "router_temperature": null,
              "router_type": "softmax",
              "router_bias_detached": false,
              "shared_expert": false,
              "router_aux_weight": null,
              "router_lb_weight": null,
              "drop_policy": "none",
              "experts": []
            },
            "ssm": null,
            "extras": [
              {
                "type": "gated",
                "targets": [
                  "attn",
                  "ffn",
                  "ssm"
                ],
                "init_weight": 0.2,
                "learnable": true
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": "yarn",
              "rope_theta": null,
              "sw": 128,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "local_global",
              "block_size": null,
              "block_stride": null,
              "global_stride": 64,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": null,
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 256,
                "stride": 32,
                "aggregator": "gate",
                "gating_weight": 0.25
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "moe",
              "hidden": 2048,
              "n_experts": 16,
              "k": 2,
              "capacity_factor": 1.2,
              "balance": 0.05,
              "shared": 1,
              "router_temperature": null,
              "router_type": "softmax",
              "router_bias_detached": false,
              "shared_expert": false,
              "router_aux_weight": null,
              "router_lb_weight": null,
              "drop_policy": "none",
              "experts": []
            },
            "ssm": null,
            "extras": [
              {
                "type": "custom",
                "name": "exp-gater",
                "params": {
                  "dim": 256
                }
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": {
              "kind": "mamba2",
              "d_state": 16,
              "d_conv": 4,
              "dt_rank": 8,
              "chunk": 128,
              "gate": 0.15
            },
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 512,
                "stride": 128,
                "aggregator": "attention",
                "gating_weight": 0.1191520977835257
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "moe",
              "hidden": 2048,
              "n_experts": 16,
              "k": 2,
              "capacity_factor": 1.2,
              "balance": 0.05,
              "shared": 1,
              "router_temperature": null,
              "router_type": "softmax",
              "router_bias_detached": false,
              "shared_expert": false,
              "router_aux_weight": null,
              "router_lb_weight": null,
              "drop_policy": "none",
              "experts": []
            },
            "ssm": null,
            "extras": [
              {
                "type": "custom",
                "name": "exp-gater",
                "params": {
                  "dim": 256
                }
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": {
              "kind": "mamba2",
              "d_state": 16,
              "d_conv": 4,
              "dt_rank": 8,
              "chunk": 128,
              "gate": 0.15
            },
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 512,
                "stride": 128,
                "aggregator": "attention",
                "gating_weight": 0.1191520977835257
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": "yarn",
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "moe",
              "hidden": 2048,
              "n_experts": 16,
              "k": 2,
              "capacity_factor": 1.2,
              "balance": 0.05,
              "shared": 1,
              "router_temperature": null,
              "router_type": "softmax",
              "router_bias_detached": false,
              "shared_expert": false,
              "router_aux_weight": null,
              "router_lb_weight": null,
              "drop_policy": "none",
              "experts": []
            },
            "ssm": null,
            "extras": [
              {
                "type": "gated",
                "targets": [
                  "attn",
                  "ffn",
                  "ssm"
                ],
                "init_weight": 0.2,
                "learnable": true
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": null,
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 1024,
                "stride": 64,
                "aggregator": "gate",
                "gating_weight": 0.35
              },
              {
                "type": "custom",
                "name": "exp-4338",
                "params": {
                  "dim": 1024,
                  "activation": "relu",
                  "notes": "auto-generated"
                }
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": {
              "kind": "mamba2",
              "d_state": 16,
              "d_conv": 4,
              "dt_rank": 8,
              "chunk": 128,
              "gate": 0.15
            },
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 512,
                "stride": 128,
                "aggregator": "attention",
                "gating_weight": 0.1191520977835257
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": "yarn",
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "moe",
              "hidden": 2048,
              "n_experts": 16,
              "k": 2,
              "capacity_factor": 1.2,
              "balance": 0.05,
              "shared": 1,
              "router_temperature": null,
              "router_type": "softmax",
              "router_bias_detached": false,
              "shared_expert": false,
              "router_aux_weight": null,
              "router_lb_weight": null,
              "drop_policy": "none",
              "experts": []
            },
            "ssm": null,
            "extras": [
              {
                "type": "gated",
                "targets": [
                  "attn",
                  "ffn",
                  "ssm"
                ],
                "init_weight": 0.2,
                "learnable": true
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": null,
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 1024,
                "stride": 64,
                "aggregator": "gate",
                "gating_weight": 0.35
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": null,
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 1024,
                "stride": 64,
                "aggregator": "gate",
                "gating_weight": 0.35
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": null,
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 1024,
                "stride": 64,
                "aggregator": "gate",
                "gating_weight": 0.35
              }
            ]
          }
        ],
        "head": {
          "tie_embeddings": true,
          "vocab": 50257
        },
        "norm": "layernorm",
        "recurrences": []
      },
      "train": {
        "lr": 0.0008,
        "warmup": 500,
        "clip": 1.0,
        "bf16": true,
        "grad_checkpoint": true,
        "max_tokens": 520000,
        "weight_decay": 0.02,
        "seed": 4242,
        "router_lb_coeff": 0.01,
        "router_entropy_coeff": 0.005,
        "entropy_threshold": 0.5,
        "entropy_patience": 3,
        "instability_threshold": 500.0,
        "no_improve_patience": 20,
        "improvement_tolerance": 0.001,
        "ppl_stop_threshold": null,
        "init_checkpoint": null,
        "optimizer": {
          "name": "adamw",
          "lr": null,
          "betas": null,
          "eps": null,
          "weight_decay": null
        }
      },
      "data": {
        "tokenizer": "gpt2",
        "hf_revision": "main",
        "seq_len": 512,
        "batch_size": 1,
        "workers": 0,
        "shards": [
          {
            "name": "ag_news",
            "split": "train",
            "weight": 0.25,
            "cache_path": null,
            "revision": null
          },
          {
            "name": "wikitext",
            "split": "wikitext-2-raw-v1",
            "weight": 0.35,
            "cache_path": null,
            "revision": null
          },
          {
            "name": "mbpp",
            "split": "train",
            "weight": 0.4,
            "cache_path": null,
            "revision": null
          }
        ],
        "healing_shards": [],
        "healing_tokens": null
      },
      "evolution": {
        "rung0_thresholds": {
          "gate_entropy_min": 0.0,
          "gate_entropy_max": 4.0
        },
        "rung1_tokens": 300000,
        "rung2_tokens": 900000,
        "population": 24,
        "topk_keep": 0.45,
        "crossover_prob": 0.5,
        "parent_selection": "lexicase",
        "pareto_objectives": [
          "ppl_code",
          "ppl_math",
          "long_recall",
          "ppl_per_long_recall",
          "throughput",
          "ram",
          "novelty",
          "graph_entropy"
        ],
        "objectives": {
          "ppl_code": "min",
          "ppl_math": "min",
          "long_recall": "max",
          "ppl_per_long_recall": "min",
          "throughput": "max",
          "ram": "min",
          "novelty": "max",
          "graph_entropy": "max",
          "instability": "min"
        },
        "composite_metrics": [
          {
            "name": "ppl_per_long_recall",
            "op": "ratio",
            "numerator": "ppl_code",
            "denominator": "long_recall",
            "terms": {},
            "epsilon": 0.1
          }
        ],
        "promotion_prob": 0.4,
        "promotion_min_layers": 8,
        "promotion_min_moe_blocks": 2,
        "promotion_steps_multiplier": 1.5,
        "promotion_tokens_multiplier": 1.5,
        "promotion_min_router_entropy": 0.0,
        "promotion_min_recurrence_gain": 0.0,
        "promotion_max_instability": null
      },
      "priors": {
        "tokens_per_param": 4.0,
        "window_scale": 6.0,
        "rope_theta_default": 10000.0,
        "prior_weight": 0.0,
        "compute_penalty_weight": 0.0
      }
    }
  },
  {
    "id": "xover-26-ed13",
    "parent": null,
    "metrics": {
      "layers": 4.0,
      "moe_blocks": 2.0,
      "graph_entropy": 2.1938117426432733,
      "selector_blocks": 0.0,
      "selector_topk_avg": 0.0,
      "memory_blocks": 2.0,
      "recurrences": 0.0,
      "novelty": 1.5625,
      "params": 142893169.0,
      "kv_bytes_per_token": 4096,
      "throughput_proxy": 238.4185791015625,
      "ppl_code": 1.0,
      "ppl_math": 1.02,
      "throughput": 583.2614554096513,
      "ram": 0.26615926809608936,
      "long_recall": 0.7,
      "router_entropy": 0.6824023723602295,
      "router_lb": 0.022197843529284,
      "router_load_max": 0.462890625,
      "router_load_min": 0.0,
      "router_load_cv": 2.4738214015960693,
      "capacity_overflow": 0.0,
      "max_grad_norm": 0.0,
      "instability": 0.0,
      "stop_reason_code": 3.0,
      "nan_seen": 0.0,
      "loss_spike": 0.0,
      "prior_distance": 0.0,
      "ppl_per_long_recall": 1.4285714285714286,
      "ppl_per_param": 6.998235164061622e-09,
      "ppl_per_throughput": 0.001714496973398755
    },
    "spec": {
      "model": {
        "name": "phi-tiny-evo-creative",
        "emb": {
          "dim": 512,
          "vocab": 50257,
          "rope": null,
          "dropout": 0.0
        },
        "blocks": [
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "moe",
              "hidden": 2048,
              "n_experts": 16,
              "k": 2,
              "capacity_factor": 1.2,
              "balance": 0.05,
              "shared": 1,
              "router_temperature": null,
              "router_type": "softmax",
              "router_bias_detached": false,
              "shared_expert": false,
              "router_aux_weight": null,
              "router_lb_weight": null,
              "drop_policy": "none",
              "experts": []
            },
            "ssm": null,
            "extras": [
              {
                "type": "custom",
                "name": "exp-gater",
                "params": {
                  "dim": 256
                }
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "moe",
              "hidden": 2048,
              "n_experts": 16,
              "k": 2,
              "capacity_factor": 1.2,
              "balance": 0.05,
              "shared": 1,
              "router_temperature": null,
              "router_type": "softmax",
              "router_bias_detached": false,
              "shared_expert": false,
              "router_aux_weight": null,
              "router_lb_weight": null,
              "drop_policy": "none",
              "experts": []
            },
            "ssm": null,
            "extras": [
              {
                "type": "custom",
                "name": "exp-gater",
                "params": {
                  "dim": 256
                }
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": null,
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 1024,
                "stride": 64,
                "aggregator": "gate",
                "gating_weight": 0.35
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": null,
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 1024,
                "stride": 64,
                "aggregator": "gate",
                "gating_weight": 0.35
              }
            ]
          }
        ],
        "head": {
          "tie_embeddings": true,
          "vocab": 50257
        },
        "norm": "layernorm",
        "recurrences": []
      },
      "train": {
        "lr": 0.0008,
        "warmup": 500,
        "clip": 1.0,
        "bf16": true,
        "grad_checkpoint": true,
        "max_tokens": 520000,
        "weight_decay": 0.02,
        "seed": 4242,
        "router_lb_coeff": 0.01,
        "router_entropy_coeff": 0.005,
        "entropy_threshold": 0.5,
        "entropy_patience": 3,
        "instability_threshold": 500.0,
        "no_improve_patience": 20,
        "improvement_tolerance": 0.001,
        "ppl_stop_threshold": null,
        "init_checkpoint": null,
        "optimizer": {
          "name": "adamw",
          "lr": null,
          "betas": null,
          "eps": null,
          "weight_decay": null
        }
      },
      "data": {
        "tokenizer": "gpt2",
        "hf_revision": "main",
        "seq_len": 512,
        "batch_size": 1,
        "workers": 0,
        "shards": [
          {
            "name": "ag_news",
            "split": "train",
            "weight": 0.25,
            "cache_path": null,
            "revision": null
          },
          {
            "name": "wikitext",
            "split": "wikitext-2-raw-v1",
            "weight": 0.35,
            "cache_path": null,
            "revision": null
          },
          {
            "name": "mbpp",
            "split": "train",
            "weight": 0.4,
            "cache_path": null,
            "revision": null
          }
        ],
        "healing_shards": [],
        "healing_tokens": null
      },
      "evolution": {
        "rung0_thresholds": {
          "gate_entropy_min": 0.0,
          "gate_entropy_max": 4.0
        },
        "rung1_tokens": 300000,
        "rung2_tokens": 900000,
        "population": 24,
        "topk_keep": 0.45,
        "crossover_prob": 0.5,
        "parent_selection": "lexicase",
        "pareto_objectives": [
          "ppl_code",
          "ppl_math",
          "long_recall",
          "ppl_per_long_recall",
          "throughput",
          "ram",
          "novelty",
          "graph_entropy"
        ],
        "objectives": {
          "ppl_code": "min",
          "ppl_math": "min",
          "long_recall": "max",
          "ppl_per_long_recall": "min",
          "throughput": "max",
          "ram": "min",
          "novelty": "max",
          "graph_entropy": "max",
          "instability": "min"
        },
        "composite_metrics": [
          {
            "name": "ppl_per_long_recall",
            "op": "ratio",
            "numerator": "ppl_code",
            "denominator": "long_recall",
            "terms": {},
            "epsilon": 0.1
          }
        ],
        "promotion_prob": 0.4,
        "promotion_min_layers": 8,
        "promotion_min_moe_blocks": 2,
        "promotion_steps_multiplier": 1.5,
        "promotion_tokens_multiplier": 1.5,
        "promotion_min_router_entropy": 0.0,
        "promotion_min_recurrence_gain": 0.0,
        "promotion_max_instability": null
      },
      "priors": {
        "tokens_per_param": 4.0,
        "window_scale": 6.0,
        "rope_theta_default": 10000.0,
        "prior_weight": 0.0,
        "compute_penalty_weight": 0.0
      }
    }
  },
  {
    "id": "xover-27-aecb",
    "parent": null,
    "metrics": {
      "layers": 6.0,
      "moe_blocks": 3.0,
      "graph_entropy": 2.5342230861114863,
      "selector_blocks": 0.0,
      "selector_topk_avg": 0.0,
      "memory_blocks": 3.0,
      "recurrences": 0.0,
      "novelty": 1.3333333333333333,
      "params": 201466273.0,
      "kv_bytes_per_token": 6144,
      "throughput_proxy": 105.96381293402777,
      "ppl_code": 1.0,
      "ppl_math": 1.03,
      "throughput": 451.57590571517125,
      "ram": 0.37526017613708973,
      "long_recall": 0.7833333333333334,
      "router_entropy": 0.6812071998914083,
      "router_lb": 0.024373610814412434,
      "router_load_max": 0.494140625,
      "router_load_min": 0.0,
      "router_load_cv": 2.692951202392578,
      "capacity_overflow": 0.0,
      "max_grad_norm": 0.0,
      "instability": 0.0,
      "stop_reason_code": 3.0,
      "nan_seen": 0.0,
      "loss_spike": 3.836117684841156e-06,
      "prior_distance": 0.05396691182540045,
      "ppl_per_long_recall": 1.276595744680851,
      "ppl_per_param": 4.9636099636389266e-09,
      "ppl_per_throughput": 0.0022144671302076597
    },
    "spec": {
      "model": {
        "name": "phi-tiny-evo-creative",
        "emb": {
          "dim": 512,
          "vocab": 50257,
          "rope": null,
          "dropout": 0.0
        },
        "blocks": [
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "moe",
              "hidden": 2048,
              "n_experts": 16,
              "k": 2,
              "capacity_factor": 1.2,
              "balance": 0.05,
              "shared": 1,
              "router_temperature": null,
              "router_type": "softmax",
              "router_bias_detached": false,
              "shared_expert": false,
              "router_aux_weight": null,
              "router_lb_weight": null,
              "drop_policy": "none",
              "experts": []
            },
            "ssm": null,
            "extras": [
              {
                "type": "custom",
                "name": "exp-gater",
                "params": {
                  "dim": 256
                }
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": "yarn",
              "rope_theta": null,
              "sw": 128,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "local_global",
              "block_size": null,
              "block_stride": null,
              "global_stride": 64,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": null,
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 256,
                "stride": 32,
                "aggregator": "gate",
                "gating_weight": 0.25
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "moe",
              "hidden": 2048,
              "n_experts": 16,
              "k": 2,
              "capacity_factor": 1.2,
              "balance": 0.05,
              "shared": 1,
              "router_temperature": null,
              "router_type": "softmax",
              "router_bias_detached": false,
              "shared_expert": false,
              "router_aux_weight": null,
              "router_lb_weight": null,
              "drop_policy": "none",
              "experts": []
            },
            "ssm": null,
            "extras": [
              {
                "type": "custom",
                "name": "exp-gater",
                "params": {
                  "dim": 256
                }
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": {
              "kind": "mamba2",
              "d_state": 16,
              "d_conv": 4,
              "dt_rank": 8,
              "chunk": 128,
              "gate": 0.15
            },
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 512,
                "stride": 128,
                "aggregator": "attention",
                "gating_weight": 0.1191520977835257
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "moe",
              "hidden": 2048,
              "n_experts": 16,
              "k": 2,
              "capacity_factor": 1.2,
              "balance": 0.05,
              "shared": 1,
              "router_temperature": null,
              "router_type": "softmax",
              "router_bias_detached": false,
              "shared_expert": false,
              "router_aux_weight": null,
              "router_lb_weight": null,
              "drop_policy": "none",
              "experts": []
            },
            "ssm": null,
            "extras": [
              {
                "type": "custom",
                "name": "exp-gater",
                "params": {
                  "dim": 256
                }
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": null,
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 1024,
                "stride": 64,
                "aggregator": "gate",
                "gating_weight": 0.35
              }
            ]
          }
        ],
        "head": {
          "tie_embeddings": true,
          "vocab": 50257
        },
        "norm": "layernorm",
        "recurrences": []
      },
      "train": {
        "lr": 0.0008,
        "warmup": 500,
        "clip": 1.0,
        "bf16": true,
        "grad_checkpoint": true,
        "max_tokens": 520000,
        "weight_decay": 0.02,
        "seed": 4242,
        "router_lb_coeff": 0.01,
        "router_entropy_coeff": 0.005,
        "entropy_threshold": 0.5,
        "entropy_patience": 3,
        "instability_threshold": 500.0,
        "no_improve_patience": 20,
        "improvement_tolerance": 0.001,
        "ppl_stop_threshold": null,
        "init_checkpoint": null,
        "optimizer": {
          "name": "adamw",
          "lr": null,
          "betas": null,
          "eps": null,
          "weight_decay": null
        }
      },
      "data": {
        "tokenizer": "gpt2",
        "hf_revision": "main",
        "seq_len": 512,
        "batch_size": 1,
        "workers": 0,
        "shards": [
          {
            "name": "ag_news",
            "split": "train",
            "weight": 0.25,
            "cache_path": null,
            "revision": null
          },
          {
            "name": "wikitext",
            "split": "wikitext-2-raw-v1",
            "weight": 0.35,
            "cache_path": null,
            "revision": null
          },
          {
            "name": "mbpp",
            "split": "train",
            "weight": 0.4,
            "cache_path": null,
            "revision": null
          }
        ],
        "healing_shards": [],
        "healing_tokens": null
      },
      "evolution": {
        "rung0_thresholds": {
          "gate_entropy_min": 0.0,
          "gate_entropy_max": 4.0
        },
        "rung1_tokens": 300000,
        "rung2_tokens": 900000,
        "population": 24,
        "topk_keep": 0.45,
        "crossover_prob": 0.5,
        "parent_selection": "lexicase",
        "pareto_objectives": [
          "ppl_code",
          "ppl_math",
          "long_recall",
          "ppl_per_long_recall",
          "throughput",
          "ram",
          "novelty",
          "graph_entropy"
        ],
        "objectives": {
          "ppl_code": "min",
          "ppl_math": "min",
          "long_recall": "max",
          "ppl_per_long_recall": "min",
          "throughput": "max",
          "ram": "min",
          "novelty": "max",
          "graph_entropy": "max",
          "instability": "min"
        },
        "composite_metrics": [
          {
            "name": "ppl_per_long_recall",
            "op": "ratio",
            "numerator": "ppl_code",
            "denominator": "long_recall",
            "terms": {},
            "epsilon": 0.1
          }
        ],
        "promotion_prob": 0.4,
        "promotion_min_layers": 8,
        "promotion_min_moe_blocks": 2,
        "promotion_steps_multiplier": 1.5,
        "promotion_tokens_multiplier": 1.5,
        "promotion_min_router_entropy": 0.0,
        "promotion_min_recurrence_gain": 0.0,
        "promotion_max_instability": null
      },
      "priors": {
        "tokens_per_param": 4.0,
        "window_scale": 6.0,
        "rope_theta_default": 10000.0,
        "prior_weight": 0.0,
        "compute_penalty_weight": 0.0
      }
    }
  },
  {
    "id": "xover-28-02c2",
    "parent": null,
    "metrics": {
      "layers": 18.0,
      "moe_blocks": 8.0,
      "graph_entropy": 2.7449512897050066,
      "selector_blocks": 0.0,
      "selector_topk_avg": 0.0,
      "memory_blocks": 10.0,
      "recurrences": 0.0,
      "novelty": 0.5666666666666667,
      "params": 501122901.0,
      "kv_bytes_per_token": 18432,
      "throughput_proxy": 11.773756992669753,
      "ppl_code": 1.0,
      "ppl_math": 1.08,
      "throughput": 234.74623344881317,
      "ram": 0.9334141407161951,
      "long_recall": 0.9666666666666667,
      "router_entropy": 0.6895433440804482,
      "router_lb": 0.025332079036161304,
      "router_load_max": 0.49609375,
      "router_load_min": 0.0,
      "router_load_cv": 2.6838881969451904,
      "capacity_overflow": 0.0,
      "max_grad_norm": 0.0,
      "instability": 0.0,
      "stop_reason_code": 3.0,
      "nan_seen": 0.0,
      "loss_spike": 2.92360782623291e-05,
      "prior_distance": 0.03469301736064337,
      "ppl_per_long_recall": 1.0344827586206897,
      "ppl_per_param": 1.9955184606500352e-09,
      "ppl_per_throughput": 0.004259919255394791
    },
    "spec": {
      "model": {
        "name": "phi-tiny-evo-creative",
        "emb": {
          "dim": 512,
          "vocab": 50257,
          "rope": null,
          "dropout": 0.0
        },
        "blocks": [
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": "yarn",
              "rope_theta": null,
              "sw": 128,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "local_global",
              "block_size": null,
              "block_stride": null,
              "global_stride": 64,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": null,
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 256,
                "stride": 32,
                "aggregator": "gate",
                "gating_weight": 0.25
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "moe",
              "hidden": 2048,
              "n_experts": 16,
              "k": 2,
              "capacity_factor": 1.2,
              "balance": 0.05,
              "shared": 1,
              "router_temperature": null,
              "router_type": "softmax",
              "router_bias_detached": false,
              "shared_expert": false,
              "router_aux_weight": null,
              "router_lb_weight": null,
              "drop_policy": "none",
              "experts": []
            },
            "ssm": null,
            "extras": [
              {
                "type": "custom",
                "name": "exp-gater",
                "params": {
                  "dim": 256
                }
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "moe",
              "hidden": 2048,
              "n_experts": 16,
              "k": 2,
              "capacity_factor": 1.2,
              "balance": 0.05,
              "shared": 1,
              "router_temperature": null,
              "router_type": "softmax",
              "router_bias_detached": false,
              "shared_expert": false,
              "router_aux_weight": null,
              "router_lb_weight": null,
              "drop_policy": "none",
              "experts": []
            },
            "ssm": null,
            "extras": [
              {
                "type": "custom",
                "name": "exp-gater",
                "params": {
                  "dim": 256
                }
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": {
              "kind": "mamba2",
              "d_state": 16,
              "d_conv": 4,
              "dt_rank": 8,
              "chunk": 128,
              "gate": 0.15
            },
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 512,
                "stride": 128,
                "aggregator": "attention",
                "gating_weight": 0.1191520977835257
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "moe",
              "hidden": 2048,
              "n_experts": 16,
              "k": 2,
              "capacity_factor": 1.2,
              "balance": 0.05,
              "shared": 1,
              "router_temperature": null,
              "router_type": "softmax",
              "router_bias_detached": false,
              "shared_expert": false,
              "router_aux_weight": null,
              "router_lb_weight": null,
              "drop_policy": "none",
              "experts": []
            },
            "ssm": null,
            "extras": [
              {
                "type": "custom",
                "name": "exp-gater",
                "params": {
                  "dim": 256
                }
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": {
              "kind": "mamba2",
              "d_state": 16,
              "d_conv": 4,
              "dt_rank": 8,
              "chunk": 128,
              "gate": 0.15
            },
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 512,
                "stride": 128,
                "aggregator": "attention",
                "gating_weight": 0.1191520977835257
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": "yarn",
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "moe",
              "hidden": 2048,
              "n_experts": 16,
              "k": 2,
              "capacity_factor": 1.2,
              "balance": 0.05,
              "shared": 1,
              "router_temperature": null,
              "router_type": "softmax",
              "router_bias_detached": false,
              "shared_expert": false,
              "router_aux_weight": null,
              "router_lb_weight": null,
              "drop_policy": "none",
              "experts": []
            },
            "ssm": null,
            "extras": [
              {
                "type": "gated",
                "targets": [
                  "attn",
                  "ffn",
                  "ssm"
                ],
                "init_weight": 0.2,
                "learnable": true
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": null,
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 1024,
                "stride": 64,
                "aggregator": "gate",
                "gating_weight": 0.35
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": {
              "kind": "mamba2",
              "d_state": 16,
              "d_conv": 4,
              "dt_rank": 8,
              "chunk": 128,
              "gate": 0.15
            },
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 512,
                "stride": 128,
                "aggregator": "attention",
                "gating_weight": 0.1191520977835257
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": "yarn",
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "moe",
              "hidden": 2048,
              "n_experts": 16,
              "k": 2,
              "capacity_factor": 1.2,
              "balance": 0.05,
              "shared": 1,
              "router_temperature": null,
              "router_type": "softmax",
              "router_bias_detached": false,
              "shared_expert": false,
              "router_aux_weight": null,
              "router_lb_weight": null,
              "drop_policy": "none",
              "experts": []
            },
            "ssm": null,
            "extras": [
              {
                "type": "gated",
                "targets": [
                  "attn",
                  "ffn",
                  "ssm"
                ],
                "init_weight": 0.2,
                "learnable": true
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": "yarn",
              "rope_theta": null,
              "sw": 128,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "local_global",
              "block_size": null,
              "block_stride": null,
              "global_stride": 64,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": null,
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 256,
                "stride": 32,
                "aggregator": "gate",
                "gating_weight": 0.25
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "moe",
              "hidden": 2048,
              "n_experts": 16,
              "k": 2,
              "capacity_factor": 1.2,
              "balance": 0.05,
              "shared": 1,
              "router_temperature": null,
              "router_type": "softmax",
              "router_bias_detached": false,
              "shared_expert": false,
              "router_aux_weight": null,
              "router_lb_weight": null,
              "drop_policy": "none",
              "experts": []
            },
            "ssm": null,
            "extras": [
              {
                "type": "custom",
                "name": "exp-gater",
                "params": {
                  "dim": 256
                }
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": "yarn",
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "moe",
              "hidden": 2048,
              "n_experts": 16,
              "k": 2,
              "capacity_factor": 1.2,
              "balance": 0.05,
              "shared": 1,
              "router_temperature": null,
              "router_type": "softmax",
              "router_bias_detached": false,
              "shared_expert": false,
              "router_aux_weight": null,
              "router_lb_weight": null,
              "drop_policy": "none",
              "experts": []
            },
            "ssm": null,
            "extras": [
              {
                "type": "gated",
                "targets": [
                  "attn",
                  "ffn",
                  "ssm"
                ],
                "init_weight": 0.2,
                "learnable": true
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": null,
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 1024,
                "stride": 64,
                "aggregator": "gate",
                "gating_weight": 0.35
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": {
              "kind": "mamba2",
              "d_state": 16,
              "d_conv": 4,
              "dt_rank": 8,
              "chunk": 128,
              "gate": 0.15
            },
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 256,
                "stride": 32,
                "aggregator": "attention",
                "gating_weight": 0.2936814817028589
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": "yarn",
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "moe",
              "hidden": 2048,
              "n_experts": 16,
              "k": 2,
              "capacity_factor": 1.2,
              "balance": 0.05,
              "shared": 1,
              "router_temperature": null,
              "router_type": "softmax",
              "router_bias_detached": false,
              "shared_expert": false,
              "router_aux_weight": null,
              "router_lb_weight": null,
              "drop_policy": "none",
              "experts": []
            },
            "ssm": null,
            "extras": [
              {
                "type": "gated",
                "targets": [
                  "attn",
                  "ffn",
                  "ssm"
                ],
                "init_weight": 0.2,
                "learnable": true
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": null,
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 1024,
                "stride": 64,
                "aggregator": "gate",
                "gating_weight": 0.35
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": null,
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 1024,
                "stride": 64,
                "aggregator": "gate",
                "gating_weight": 0.35
              }
            ]
          }
        ],
        "head": {
          "tie_embeddings": true,
          "vocab": 50257
        },
        "norm": "layernorm",
        "recurrences": []
      },
      "train": {
        "lr": 0.0008,
        "warmup": 500,
        "clip": 1.0,
        "bf16": true,
        "grad_checkpoint": true,
        "max_tokens": 520000,
        "weight_decay": 0.02,
        "seed": 4242,
        "router_lb_coeff": 0.01,
        "router_entropy_coeff": 0.005,
        "entropy_threshold": 0.5,
        "entropy_patience": 3,
        "instability_threshold": 500.0,
        "no_improve_patience": 20,
        "improvement_tolerance": 0.001,
        "ppl_stop_threshold": null,
        "init_checkpoint": null,
        "optimizer": {
          "name": "adamw",
          "lr": null,
          "betas": null,
          "eps": null,
          "weight_decay": null
        }
      },
      "data": {
        "tokenizer": "gpt2",
        "hf_revision": "main",
        "seq_len": 512,
        "batch_size": 1,
        "workers": 0,
        "shards": [
          {
            "name": "ag_news",
            "split": "train",
            "weight": 0.25,
            "cache_path": null,
            "revision": null
          },
          {
            "name": "wikitext",
            "split": "wikitext-2-raw-v1",
            "weight": 0.35,
            "cache_path": null,
            "revision": null
          },
          {
            "name": "mbpp",
            "split": "train",
            "weight": 0.4,
            "cache_path": null,
            "revision": null
          }
        ],
        "healing_shards": [],
        "healing_tokens": null
      },
      "evolution": {
        "rung0_thresholds": {
          "gate_entropy_min": 0.0,
          "gate_entropy_max": 4.0
        },
        "rung1_tokens": 300000,
        "rung2_tokens": 900000,
        "population": 24,
        "topk_keep": 0.45,
        "crossover_prob": 0.5,
        "parent_selection": "lexicase",
        "pareto_objectives": [
          "ppl_code",
          "ppl_math",
          "long_recall",
          "ppl_per_long_recall",
          "throughput",
          "ram",
          "novelty",
          "graph_entropy"
        ],
        "objectives": {
          "ppl_code": "min",
          "ppl_math": "min",
          "long_recall": "max",
          "ppl_per_long_recall": "min",
          "throughput": "max",
          "ram": "min",
          "novelty": "max",
          "graph_entropy": "max",
          "instability": "min"
        },
        "composite_metrics": [
          {
            "name": "ppl_per_long_recall",
            "op": "ratio",
            "numerator": "ppl_code",
            "denominator": "long_recall",
            "terms": {},
            "epsilon": 0.1
          }
        ],
        "promotion_prob": 0.4,
        "promotion_min_layers": 8,
        "promotion_min_moe_blocks": 2,
        "promotion_steps_multiplier": 1.5,
        "promotion_tokens_multiplier": 1.5,
        "promotion_min_router_entropy": 0.0,
        "promotion_min_recurrence_gain": 0.0,
        "promotion_max_instability": null
      },
      "priors": {
        "tokens_per_param": 4.0,
        "window_scale": 6.0,
        "rope_theta_default": 10000.0,
        "prior_weight": 0.0,
        "compute_penalty_weight": 0.0
      }
    }
  },
  {
    "id": "xover-33-e218",
    "parent": null,
    "metrics": {
      "layers": 14.0,
      "moe_blocks": 7.0,
      "graph_entropy": 2.6986038507774674,
      "selector_blocks": 0.0,
      "selector_topk_avg": 0.0,
      "memory_blocks": 7.0,
      "recurrences": 0.0,
      "novelty": 1.3076923076923077,
      "params": 435196963.0,
      "kv_bytes_per_token": 14336,
      "throughput_proxy": 19.46274115114796,
      "ppl_code": 1.0,
      "ppl_math": 1.07,
      "throughput": 259.5547657709837,
      "ram": 0.8106175120919943,
      "long_recall": 0.9071428571428571,
      "router_entropy": 0.6825390458106995,
      "router_lb": 0.025663103642208234,
      "router_load_max": 0.4931640625,
      "router_load_min": 0.0,
      "router_load_cv": 2.6655170917510986,
      "capacity_overflow": 0.0,
      "max_grad_norm": 0.0,
      "instability": 0.0,
      "stop_reason_code": 3.0,
      "nan_seen": 0.0,
      "loss_spike": 0.00012498535215854645,
      "prior_distance": 0.02312867796508752,
      "ppl_per_long_recall": 1.1023622047244095,
      "ppl_per_param": 2.2978101526871177e-09,
      "ppl_per_throughput": 0.0038527514493120227
    },
    "spec": {
      "model": {
        "name": "phi-tiny-evo-creative",
        "emb": {
          "dim": 512,
          "vocab": 50257,
          "rope": null,
          "dropout": 0.0
        },
        "blocks": [
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "moe",
              "hidden": 2048,
              "n_experts": 16,
              "k": 2,
              "capacity_factor": 1.2,
              "balance": 0.05,
              "shared": 1,
              "router_temperature": null,
              "router_type": "softmax",
              "router_bias_detached": false,
              "shared_expert": false,
              "router_aux_weight": null,
              "router_lb_weight": null,
              "drop_policy": "none",
              "experts": []
            },
            "ssm": null,
            "extras": [
              {
                "type": "custom",
                "name": "exp-gater",
                "params": {
                  "dim": 256
                }
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": "yarn",
              "rope_theta": null,
              "sw": 128,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "local_global",
              "block_size": null,
              "block_stride": null,
              "global_stride": 64,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": null,
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 256,
                "stride": 32,
                "aggregator": "gate",
                "gating_weight": 0.25
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "moe",
              "hidden": 2048,
              "n_experts": 16,
              "k": 2,
              "capacity_factor": 1.2,
              "balance": 0.05,
              "shared": 1,
              "router_temperature": null,
              "router_type": "softmax",
              "router_bias_detached": false,
              "shared_expert": false,
              "router_aux_weight": null,
              "router_lb_weight": null,
              "drop_policy": "none",
              "experts": []
            },
            "ssm": null,
            "extras": [
              {
                "type": "custom",
                "name": "exp-gater",
                "params": {
                  "dim": 256
                }
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "moe",
              "hidden": 2048,
              "n_experts": 16,
              "k": 2,
              "capacity_factor": 1.2,
              "balance": 0.05,
              "shared": 1,
              "router_temperature": null,
              "router_type": "softmax",
              "router_bias_detached": false,
              "shared_expert": false,
              "router_aux_weight": null,
              "router_lb_weight": null,
              "drop_policy": "none",
              "experts": []
            },
            "ssm": null,
            "extras": [
              {
                "type": "custom",
                "name": "exp-gater",
                "params": {
                  "dim": 256
                }
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "moe",
              "hidden": 2048,
              "n_experts": 16,
              "k": 2,
              "capacity_factor": 1.2,
              "balance": 0.05,
              "shared": 1,
              "router_temperature": null,
              "router_type": "softmax",
              "router_bias_detached": false,
              "shared_expert": false,
              "router_aux_weight": null,
              "router_lb_weight": null,
              "drop_policy": "none",
              "experts": []
            },
            "ssm": null,
            "extras": [
              {
                "type": "custom",
                "name": "exp-gater",
                "params": {
                  "dim": 256
                }
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": {
              "kind": "mamba2",
              "d_state": 16,
              "d_conv": 4,
              "dt_rank": 8,
              "chunk": 128,
              "gate": 0.15
            },
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 512,
                "stride": 128,
                "aggregator": "attention",
                "gating_weight": 0.1191520977835257
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "moe",
              "hidden": 2048,
              "n_experts": 16,
              "k": 2,
              "capacity_factor": 1.2,
              "balance": 0.05,
              "shared": 1,
              "router_temperature": null,
              "router_type": "softmax",
              "router_bias_detached": false,
              "shared_expert": false,
              "router_aux_weight": null,
              "router_lb_weight": null,
              "drop_policy": "none",
              "experts": []
            },
            "ssm": null,
            "extras": [
              {
                "type": "custom",
                "name": "exp-gater",
                "params": {
                  "dim": 256
                }
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": {
              "kind": "mamba2",
              "d_state": 16,
              "d_conv": 4,
              "dt_rank": 8,
              "chunk": 128,
              "gate": 0.15
            },
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 512,
                "stride": 128,
                "aggregator": "attention",
                "gating_weight": 0.1191520977835257
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": "yarn",
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "moe",
              "hidden": 2048,
              "n_experts": 16,
              "k": 2,
              "capacity_factor": 1.2,
              "balance": 0.05,
              "shared": 1,
              "router_temperature": null,
              "router_type": "softmax",
              "router_bias_detached": false,
              "shared_expert": false,
              "router_aux_weight": null,
              "router_lb_weight": null,
              "drop_policy": "none",
              "experts": []
            },
            "ssm": null,
            "extras": [
              {
                "type": "gated",
                "targets": [
                  "attn",
                  "ffn",
                  "ssm"
                ],
                "init_weight": 0.2,
                "learnable": true
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": null,
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 1024,
                "stride": 64,
                "aggregator": "gate",
                "gating_weight": 0.35
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": {
              "kind": "mamba2",
              "d_state": 16,
              "d_conv": 4,
              "dt_rank": 8,
              "chunk": 128,
              "gate": 0.15
            },
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 512,
                "stride": 128,
                "aggregator": "attention",
                "gating_weight": 0.1191520977835257
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": "yarn",
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "moe",
              "hidden": 2048,
              "n_experts": 16,
              "k": 2,
              "capacity_factor": 1.2,
              "balance": 0.05,
              "shared": 1,
              "router_temperature": null,
              "router_type": "softmax",
              "router_bias_detached": false,
              "shared_expert": false,
              "router_aux_weight": null,
              "router_lb_weight": null,
              "drop_policy": "none",
              "experts": []
            },
            "ssm": null,
            "extras": [
              {
                "type": "gated",
                "targets": [
                  "attn",
                  "ffn",
                  "ssm"
                ],
                "init_weight": 0.2,
                "learnable": true
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": null,
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 1024,
                "stride": 64,
                "aggregator": "gate",
                "gating_weight": 0.35
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": null,
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 1024,
                "stride": 64,
                "aggregator": "gate",
                "gating_weight": 0.35
              }
            ]
          }
        ],
        "head": {
          "tie_embeddings": true,
          "vocab": 50257
        },
        "norm": "layernorm",
        "recurrences": []
      },
      "train": {
        "lr": 0.0008,
        "warmup": 500,
        "clip": 1.0,
        "bf16": true,
        "grad_checkpoint": true,
        "max_tokens": 520000,
        "weight_decay": 0.02,
        "seed": 4242,
        "router_lb_coeff": 0.01,
        "router_entropy_coeff": 0.005,
        "entropy_threshold": 0.5,
        "entropy_patience": 3,
        "instability_threshold": 500.0,
        "no_improve_patience": 20,
        "improvement_tolerance": 0.001,
        "ppl_stop_threshold": null,
        "init_checkpoint": null,
        "optimizer": {
          "name": "adamw",
          "lr": null,
          "betas": null,
          "eps": null,
          "weight_decay": null
        }
      },
      "data": {
        "tokenizer": "gpt2",
        "hf_revision": "main",
        "seq_len": 512,
        "batch_size": 1,
        "workers": 0,
        "shards": [
          {
            "name": "ag_news",
            "split": "train",
            "weight": 0.25,
            "cache_path": null,
            "revision": null
          },
          {
            "name": "wikitext",
            "split": "wikitext-2-raw-v1",
            "weight": 0.35,
            "cache_path": null,
            "revision": null
          },
          {
            "name": "mbpp",
            "split": "train",
            "weight": 0.4,
            "cache_path": null,
            "revision": null
          }
        ],
        "healing_shards": [],
        "healing_tokens": null
      },
      "evolution": {
        "rung0_thresholds": {
          "gate_entropy_min": 0.0,
          "gate_entropy_max": 4.0
        },
        "rung1_tokens": 300000,
        "rung2_tokens": 900000,
        "population": 24,
        "topk_keep": 0.45,
        "crossover_prob": 0.5,
        "parent_selection": "lexicase",
        "pareto_objectives": [
          "ppl_code",
          "ppl_math",
          "long_recall",
          "ppl_per_long_recall",
          "throughput",
          "ram",
          "novelty",
          "graph_entropy"
        ],
        "objectives": {
          "ppl_code": "min",
          "ppl_math": "min",
          "long_recall": "max",
          "ppl_per_long_recall": "min",
          "throughput": "max",
          "ram": "min",
          "novelty": "max",
          "graph_entropy": "max",
          "instability": "min"
        },
        "composite_metrics": [
          {
            "name": "ppl_per_long_recall",
            "op": "ratio",
            "numerator": "ppl_code",
            "denominator": "long_recall",
            "terms": {},
            "epsilon": 0.1
          }
        ],
        "promotion_prob": 0.4,
        "promotion_min_layers": 8,
        "promotion_min_moe_blocks": 2,
        "promotion_steps_multiplier": 1.5,
        "promotion_tokens_multiplier": 1.5,
        "promotion_min_router_entropy": 0.0,
        "promotion_min_recurrence_gain": 0.0,
        "promotion_max_instability": null
      },
      "priors": {
        "tokens_per_param": 4.0,
        "window_scale": 6.0,
        "rope_theta_default": 10000.0,
        "prior_weight": 0.0,
        "compute_penalty_weight": 0.0
      }
    }
  },
  {
    "id": "xover-34-6062",
    "parent": null,
    "metrics": {
      "layers": 5.0,
      "moe_blocks": 1.0,
      "graph_entropy": 2.290772125696337,
      "selector_blocks": 0.0,
      "selector_topk_avg": 0.0,
      "memory_blocks": 4.0,
      "recurrences": 0.0,
      "novelty": 1.1764705882352942,
      "params": 96156001.0,
      "kv_bytes_per_token": 5120,
      "throughput_proxy": 152.587890625,
      "ppl_code": 1.0,
      "ppl_math": 1.01,
      "throughput": 681.4287360221014,
      "ram": 0.17910450883209705,
      "long_recall": 1.0,
      "router_entropy": 0.6928525567054749,
      "router_lb": 0.026377439498901367,
      "router_load_max": 0.4931640625,
      "router_load_min": 0.0,
      "router_load_cv": 2.6838033199310303,
      "capacity_overflow": 0.0,
      "max_grad_norm": 0.0,
      "instability": 0.0,
      "stop_reason_code": 3.0,
      "nan_seen": 0.0,
      "loss_spike": 1.3923505321145058e-05,
      "prior_distance": 0.05396691182540045,
      "ppl_per_long_recall": 1.0,
      "ppl_per_param": 1.0399766937063034e-08,
      "ppl_per_throughput": 0.0014675048866262753
    },
    "spec": {
      "model": {
        "name": "phi-tiny-evo-creative",
        "emb": {
          "dim": 512,
          "vocab": 50257,
          "rope": null,
          "dropout": 0.0
        },
        "blocks": [
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": "yarn",
              "rope_theta": null,
              "sw": 128,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "local_global",
              "block_size": null,
              "block_stride": null,
              "global_stride": 64,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": null,
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 256,
                "stride": 32,
                "aggregator": "gate",
                "gating_weight": 0.25
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "moe",
              "hidden": 2048,
              "n_experts": 16,
              "k": 2,
              "capacity_factor": 1.2,
              "balance": 0.05,
              "shared": 1,
              "router_temperature": null,
              "router_type": "softmax",
              "router_bias_detached": false,
              "shared_expert": false,
              "router_aux_weight": null,
              "router_lb_weight": null,
              "drop_policy": "none",
              "experts": []
            },
            "ssm": null,
            "extras": [
              {
                "type": "custom",
                "name": "exp-gater",
                "params": {
                  "dim": 256
                }
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": null,
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 1024,
                "stride": 64,
                "aggregator": "gate",
                "gating_weight": 0.35
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": null,
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 1024,
                "stride": 64,
                "aggregator": "gate",
                "gating_weight": 0.35
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": null,
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 1024,
                "stride": 64,
                "aggregator": "gate",
                "gating_weight": 0.35
              }
            ]
          }
        ],
        "head": {
          "tie_embeddings": true,
          "vocab": 50257
        },
        "norm": "layernorm",
        "recurrences": []
      },
      "train": {
        "lr": 0.0008,
        "warmup": 500,
        "clip": 1.0,
        "bf16": true,
        "grad_checkpoint": true,
        "max_tokens": 520000,
        "weight_decay": 0.02,
        "seed": 4242,
        "router_lb_coeff": 0.01,
        "router_entropy_coeff": 0.005,
        "entropy_threshold": 0.5,
        "entropy_patience": 3,
        "instability_threshold": 500.0,
        "no_improve_patience": 20,
        "improvement_tolerance": 0.001,
        "ppl_stop_threshold": null,
        "init_checkpoint": null,
        "optimizer": {
          "name": "adamw",
          "lr": null,
          "betas": null,
          "eps": null,
          "weight_decay": null
        }
      },
      "data": {
        "tokenizer": "gpt2",
        "hf_revision": "main",
        "seq_len": 512,
        "batch_size": 1,
        "workers": 0,
        "shards": [
          {
            "name": "ag_news",
            "split": "train",
            "weight": 0.25,
            "cache_path": null,
            "revision": null
          },
          {
            "name": "wikitext",
            "split": "wikitext-2-raw-v1",
            "weight": 0.35,
            "cache_path": null,
            "revision": null
          },
          {
            "name": "mbpp",
            "split": "train",
            "weight": 0.4,
            "cache_path": null,
            "revision": null
          }
        ],
        "healing_shards": [],
        "healing_tokens": null
      },
      "evolution": {
        "rung0_thresholds": {
          "gate_entropy_min": 0.0,
          "gate_entropy_max": 4.0
        },
        "rung1_tokens": 300000,
        "rung2_tokens": 900000,
        "population": 24,
        "topk_keep": 0.45,
        "crossover_prob": 0.5,
        "parent_selection": "lexicase",
        "pareto_objectives": [
          "ppl_code",
          "ppl_math",
          "long_recall",
          "ppl_per_long_recall",
          "throughput",
          "ram",
          "novelty",
          "graph_entropy"
        ],
        "objectives": {
          "ppl_code": "min",
          "ppl_math": "min",
          "long_recall": "max",
          "ppl_per_long_recall": "min",
          "throughput": "max",
          "ram": "min",
          "novelty": "max",
          "graph_entropy": "max",
          "instability": "min"
        },
        "composite_metrics": [
          {
            "name": "ppl_per_long_recall",
            "op": "ratio",
            "numerator": "ppl_code",
            "denominator": "long_recall",
            "terms": {},
            "epsilon": 0.1
          }
        ],
        "promotion_prob": 0.4,
        "promotion_min_layers": 8,
        "promotion_min_moe_blocks": 2,
        "promotion_steps_multiplier": 1.5,
        "promotion_tokens_multiplier": 1.5,
        "promotion_min_router_entropy": 0.0,
        "promotion_min_recurrence_gain": 0.0,
        "promotion_max_instability": null
      },
      "priors": {
        "tokens_per_param": 4.0,
        "window_scale": 6.0,
        "rope_theta_default": 10000.0,
        "prior_weight": 0.0,
        "compute_penalty_weight": 0.0
      }
    }
  },
  {
    "id": "xover-35-6f5f",
    "parent": null,
    "metrics": {
      "layers": 11.0,
      "moe_blocks": 4.0,
      "graph_entropy": 2.6841003294555277,
      "selector_blocks": 0.0,
      "selector_topk_avg": 0.0,
      "memory_blocks": 7.0,
      "recurrences": 0.0,
      "novelty": 0.8260869565217391,
      "params": 272644563.0,
      "kv_bytes_per_token": 11264,
      "throughput_proxy": 31.526423682851238,
      "ppl_code": 1.0,
      "ppl_math": 1.04,
      "throughput": 342.23210455731027,
      "ram": 0.5078400727361441,
      "long_recall": 1.0272727272727273,
      "router_entropy": 0.8491839319467545,
      "router_lb": 0.02250704262405634,
      "router_load_max": 0.4990234375,
      "router_load_min": 0.0,
      "router_load_cv": 2.7233798503875732,
      "capacity_overflow": 0.0,
      "max_grad_norm": 0.0,
      "instability": 0.0,
      "stop_reason_code": 3.0,
      "nan_seen": 0.0,
      "loss_spike": 6.1793252825737e-05,
      "prior_distance": 0.026983457411781025,
      "ppl_per_long_recall": 0.9734513274336283,
      "ppl_per_param": 3.667778990333286e-09,
      "ppl_per_throughput": 0.002921993543807167
    },
    "spec": {
      "model": {
        "name": "phi-tiny-evo-creative",
        "emb": {
          "dim": 512,
          "vocab": 50257,
          "rope": null,
          "dropout": 0.0
        },
        "blocks": [
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "moe",
              "hidden": 2048,
              "n_experts": 16,
              "k": 4,
              "capacity_factor": 1.4699690930297657,
              "balance": 0.05,
              "shared": 1,
              "router_temperature": null,
              "router_type": "softmax",
              "router_bias_detached": false,
              "shared_expert": false,
              "router_aux_weight": null,
              "router_lb_weight": null,
              "drop_policy": "none",
              "experts": []
            },
            "ssm": null,
            "extras": [
              {
                "type": "custom",
                "name": "exp-gater",
                "params": {
                  "dim": 256
                }
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": "yarn",
              "rope_theta": null,
              "sw": 128,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "local_global",
              "block_size": null,
              "block_stride": null,
              "global_stride": 64,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": null,
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 256,
                "stride": 32,
                "aggregator": "gate",
                "gating_weight": 0.25
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "moe",
              "hidden": 2048,
              "n_experts": 16,
              "k": 2,
              "capacity_factor": 1.2,
              "balance": 0.05,
              "shared": 1,
              "router_temperature": null,
              "router_type": "softmax",
              "router_bias_detached": false,
              "shared_expert": false,
              "router_aux_weight": null,
              "router_lb_weight": null,
              "drop_policy": "none",
              "experts": []
            },
            "ssm": null,
            "extras": [
              {
                "type": "custom",
                "name": "exp-gater",
                "params": {
                  "dim": 256
                }
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": {
              "kind": "mamba2",
              "d_state": 16,
              "d_conv": 4,
              "dt_rank": 8,
              "chunk": 128,
              "gate": 0.15
            },
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 512,
                "stride": 128,
                "aggregator": "attention",
                "gating_weight": 0.1191520977835257
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "moe",
              "hidden": 2048,
              "n_experts": 16,
              "k": 2,
              "capacity_factor": 1.2,
              "balance": 0.05,
              "shared": 1,
              "router_temperature": null,
              "router_type": "softmax",
              "router_bias_detached": false,
              "shared_expert": false,
              "router_aux_weight": null,
              "router_lb_weight": null,
              "drop_policy": "none",
              "experts": []
            },
            "ssm": null,
            "extras": [
              {
                "type": "custom",
                "name": "exp-gater",
                "params": {
                  "dim": 256
                }
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": {
              "kind": "mamba2",
              "d_state": 16,
              "d_conv": 4,
              "dt_rank": 8,
              "chunk": 128,
              "gate": 0.15
            },
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 512,
                "stride": 128,
                "aggregator": "attention",
                "gating_weight": 0.1191520977835257
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": "yarn",
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "moe",
              "hidden": 2048,
              "n_experts": 16,
              "k": 2,
              "capacity_factor": 1.2,
              "balance": 0.05,
              "shared": 1,
              "router_temperature": null,
              "router_type": "softmax",
              "router_bias_detached": false,
              "shared_expert": false,
              "router_aux_weight": null,
              "router_lb_weight": null,
              "drop_policy": "none",
              "experts": []
            },
            "ssm": null,
            "extras": [
              {
                "type": "gated",
                "targets": [
                  "attn",
                  "ffn",
                  "ssm"
                ],
                "init_weight": 0.2,
                "learnable": true
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": null,
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 1024,
                "stride": 64,
                "aggregator": "gate",
                "gating_weight": 0.35
              },
              {
                "type": "custom",
                "name": "exp-4338",
                "params": {
                  "dim": 1024,
                  "activation": "relu",
                  "notes": "auto-generated"
                }
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": null,
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 1024,
                "stride": 64,
                "aggregator": "gate",
                "gating_weight": 0.35
              },
              {
                "type": "gated",
                "targets": [
                  "attn",
                  "ffn"
                ],
                "init_weight": 0.17686717452555856,
                "learnable": true
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": null,
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 1024,
                "stride": 64,
                "aggregator": "gate",
                "gating_weight": 0.35
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": null,
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 1024,
                "stride": 64,
                "aggregator": "gate",
                "gating_weight": 0.35
              }
            ]
          }
        ],
        "head": {
          "tie_embeddings": true,
          "vocab": 50257
        },
        "norm": "layernorm",
        "recurrences": []
      },
      "train": {
        "lr": 0.0008,
        "warmup": 500,
        "clip": 1.0,
        "bf16": true,
        "grad_checkpoint": true,
        "max_tokens": 520000,
        "weight_decay": 0.02,
        "seed": 4242,
        "router_lb_coeff": 0.01,
        "router_entropy_coeff": 0.005,
        "entropy_threshold": 0.5,
        "entropy_patience": 3,
        "instability_threshold": 500.0,
        "no_improve_patience": 20,
        "improvement_tolerance": 0.001,
        "ppl_stop_threshold": null,
        "init_checkpoint": null,
        "optimizer": {
          "name": "adamw",
          "lr": null,
          "betas": null,
          "eps": null,
          "weight_decay": null
        }
      },
      "data": {
        "tokenizer": "gpt2",
        "hf_revision": "main",
        "seq_len": 512,
        "batch_size": 1,
        "workers": 0,
        "shards": [
          {
            "name": "ag_news",
            "split": "train",
            "weight": 0.25,
            "cache_path": null,
            "revision": null
          },
          {
            "name": "wikitext",
            "split": "wikitext-2-raw-v1",
            "weight": 0.35,
            "cache_path": null,
            "revision": null
          },
          {
            "name": "mbpp",
            "split": "train",
            "weight": 0.4,
            "cache_path": null,
            "revision": null
          }
        ],
        "healing_shards": [],
        "healing_tokens": null
      },
      "evolution": {
        "rung0_thresholds": {
          "gate_entropy_min": 0.0,
          "gate_entropy_max": 4.0
        },
        "rung1_tokens": 300000,
        "rung2_tokens": 900000,
        "population": 24,
        "topk_keep": 0.45,
        "crossover_prob": 0.5,
        "parent_selection": "lexicase",
        "pareto_objectives": [
          "ppl_code",
          "ppl_math",
          "long_recall",
          "ppl_per_long_recall",
          "throughput",
          "ram",
          "novelty",
          "graph_entropy"
        ],
        "objectives": {
          "ppl_code": "min",
          "ppl_math": "min",
          "long_recall": "max",
          "ppl_per_long_recall": "min",
          "throughput": "max",
          "ram": "min",
          "novelty": "max",
          "graph_entropy": "max",
          "instability": "min"
        },
        "composite_metrics": [
          {
            "name": "ppl_per_long_recall",
            "op": "ratio",
            "numerator": "ppl_code",
            "denominator": "long_recall",
            "terms": {},
            "epsilon": 0.1
          }
        ],
        "promotion_prob": 0.4,
        "promotion_min_layers": 8,
        "promotion_min_moe_blocks": 2,
        "promotion_steps_multiplier": 1.5,
        "promotion_tokens_multiplier": 1.5,
        "promotion_min_router_entropy": 0.0,
        "promotion_min_recurrence_gain": 0.0,
        "promotion_max_instability": null
      },
      "priors": {
        "tokens_per_param": 4.0,
        "window_scale": 6.0,
        "rope_theta_default": 10000.0,
        "prior_weight": 0.0,
        "compute_penalty_weight": 0.0
      }
    }
  },
  {
    "id": "xover-36-4415",
    "parent": null,
    "metrics": {
      "layers": 20.0,
      "moe_blocks": 8.0,
      "graph_entropy": 2.752514889194432,
      "selector_blocks": 0.0,
      "selector_topk_avg": 0.0,
      "memory_blocks": 12.0,
      "recurrences": 0.0,
      "novelty": 1.09375,
      "params": 510069621.0,
      "kv_bytes_per_token": 20480,
      "throughput_proxy": 9.5367431640625,
      "ppl_code": 1.0,
      "ppl_math": 1.08,
      "throughput": 239.18052995637015,
      "ram": 0.9500787053257227,
      "long_recall": 1.025,
      "router_entropy": 0.6868812367320061,
      "router_lb": 0.02431207918561995,
      "router_load_max": 0.4921875,
      "router_load_min": 0.0,
      "router_load_cv": 2.627361297607422,
      "capacity_overflow": 0.0,
      "max_grad_norm": 0.0,
      "instability": 0.0,
      "stop_reason_code": 3.0,
      "nan_seen": 0.0,
      "loss_spike": 0.00012238137423992157,
      "prior_distance": 0.030356390326082547,
      "ppl_per_long_recall": 0.9756097560975611,
      "ppl_per_param": 1.96051668013375e-09,
      "ppl_per_throughput": 0.004180942320775081
    },
    "spec": {
      "model": {
        "name": "phi-tiny-evo-creative",
        "emb": {
          "dim": 512,
          "vocab": 50257,
          "rope": null,
          "dropout": 0.0
        },
        "blocks": [
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "moe",
              "hidden": 2048,
              "n_experts": 16,
              "k": 2,
              "capacity_factor": 1.2,
              "balance": 0.05,
              "shared": 1,
              "router_temperature": null,
              "router_type": "softmax",
              "router_bias_detached": false,
              "shared_expert": false,
              "router_aux_weight": null,
              "router_lb_weight": null,
              "drop_policy": "none",
              "experts": []
            },
            "ssm": null,
            "extras": [
              {
                "type": "custom",
                "name": "exp-gater",
                "params": {
                  "dim": 256
                }
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": "yarn",
              "rope_theta": null,
              "sw": 128,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "local_global",
              "block_size": null,
              "block_stride": null,
              "global_stride": 64,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": null,
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 256,
                "stride": 32,
                "aggregator": "gate",
                "gating_weight": 0.25
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "moe",
              "hidden": 2048,
              "n_experts": 16,
              "k": 2,
              "capacity_factor": 1.2,
              "balance": 0.05,
              "shared": 1,
              "router_temperature": null,
              "router_type": "softmax",
              "router_bias_detached": false,
              "shared_expert": false,
              "router_aux_weight": null,
              "router_lb_weight": null,
              "drop_policy": "none",
              "experts": []
            },
            "ssm": null,
            "extras": [
              {
                "type": "custom",
                "name": "exp-gater",
                "params": {
                  "dim": 256
                }
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": {
              "kind": "mamba2",
              "d_state": 16,
              "d_conv": 4,
              "dt_rank": 8,
              "chunk": 128,
              "gate": 0.15
            },
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 512,
                "stride": 128,
                "aggregator": "attention",
                "gating_weight": 0.1191520977835257
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "moe",
              "hidden": 2048,
              "n_experts": 16,
              "k": 2,
              "capacity_factor": 1.2,
              "balance": 0.05,
              "shared": 1,
              "router_temperature": null,
              "router_type": "softmax",
              "router_bias_detached": false,
              "shared_expert": false,
              "router_aux_weight": null,
              "router_lb_weight": null,
              "drop_policy": "none",
              "experts": []
            },
            "ssm": null,
            "extras": [
              {
                "type": "custom",
                "name": "exp-gater",
                "params": {
                  "dim": 256
                }
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": {
              "kind": "mamba2",
              "d_state": 16,
              "d_conv": 4,
              "dt_rank": 8,
              "chunk": 128,
              "gate": 0.15
            },
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 512,
                "stride": 128,
                "aggregator": "attention",
                "gating_weight": 0.1191520977835257
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": "yarn",
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "moe",
              "hidden": 2048,
              "n_experts": 16,
              "k": 2,
              "capacity_factor": 1.2,
              "balance": 0.05,
              "shared": 1,
              "router_temperature": null,
              "router_type": "softmax",
              "router_bias_detached": false,
              "shared_expert": false,
              "router_aux_weight": null,
              "router_lb_weight": null,
              "drop_policy": "none",
              "experts": []
            },
            "ssm": null,
            "extras": [
              {
                "type": "gated",
                "targets": [
                  "attn",
                  "ffn",
                  "ssm"
                ],
                "init_weight": 0.2,
                "learnable": true
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": null,
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 1024,
                "stride": 64,
                "aggregator": "gate",
                "gating_weight": 0.35
              },
              {
                "type": "custom",
                "name": "exp-4338",
                "params": {
                  "dim": 1024,
                  "activation": "relu",
                  "notes": "auto-generated"
                }
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": {
              "kind": "mamba2",
              "d_state": 16,
              "d_conv": 4,
              "dt_rank": 8,
              "chunk": 128,
              "gate": 0.15
            },
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 512,
                "stride": 128,
                "aggregator": "attention",
                "gating_weight": 0.1191520977835257
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": null,
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 1024,
                "stride": 64,
                "aggregator": "gate",
                "gating_weight": 0.35
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": {
              "kind": "mamba2",
              "d_state": 16,
              "d_conv": 4,
              "dt_rank": 8,
              "chunk": 128,
              "gate": 0.15
            },
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 512,
                "stride": 128,
                "aggregator": "attention",
                "gating_weight": 0.1191520977835257
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": "yarn",
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "moe",
              "hidden": 2048,
              "n_experts": 16,
              "k": 2,
              "capacity_factor": 1.2,
              "balance": 0.05,
              "shared": 1,
              "router_temperature": null,
              "router_type": "softmax",
              "router_bias_detached": false,
              "shared_expert": false,
              "router_aux_weight": null,
              "router_lb_weight": null,
              "drop_policy": "none",
              "experts": []
            },
            "ssm": null,
            "extras": [
              {
                "type": "gated",
                "targets": [
                  "attn",
                  "ffn",
                  "ssm"
                ],
                "init_weight": 0.2,
                "learnable": true
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": "yarn",
              "rope_theta": null,
              "sw": 128,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "local_global",
              "block_size": null,
              "block_stride": null,
              "global_stride": 64,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": null,
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 256,
                "stride": 32,
                "aggregator": "gate",
                "gating_weight": 0.25
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "moe",
              "hidden": 2048,
              "n_experts": 16,
              "k": 2,
              "capacity_factor": 1.2,
              "balance": 0.05,
              "shared": 1,
              "router_temperature": null,
              "router_type": "softmax",
              "router_bias_detached": false,
              "shared_expert": false,
              "router_aux_weight": null,
              "router_lb_weight": null,
              "drop_policy": "none",
              "experts": []
            },
            "ssm": null,
            "extras": [
              {
                "type": "custom",
                "name": "exp-gater",
                "params": {
                  "dim": 256
                }
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": "yarn",
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "moe",
              "hidden": 2048,
              "n_experts": 16,
              "k": 2,
              "capacity_factor": 1.2,
              "balance": 0.05,
              "shared": 1,
              "router_temperature": null,
              "router_type": "softmax",
              "router_bias_detached": false,
              "shared_expert": false,
              "router_aux_weight": null,
              "router_lb_weight": null,
              "drop_policy": "none",
              "experts": []
            },
            "ssm": null,
            "extras": [
              {
                "type": "gated",
                "targets": [
                  "attn",
                  "ffn",
                  "ssm"
                ],
                "init_weight": 0.2,
                "learnable": true
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": null,
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 1024,
                "stride": 64,
                "aggregator": "gate",
                "gating_weight": 0.35
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": {
              "kind": "mamba2",
              "d_state": 16,
              "d_conv": 4,
              "dt_rank": 8,
              "chunk": 128,
              "gate": 0.15
            },
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 256,
                "stride": 32,
                "aggregator": "attention",
                "gating_weight": 0.2936814817028589
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": "yarn",
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "moe",
              "hidden": 2048,
              "n_experts": 16,
              "k": 2,
              "capacity_factor": 1.2,
              "balance": 0.05,
              "shared": 1,
              "router_temperature": null,
              "router_type": "softmax",
              "router_bias_detached": false,
              "shared_expert": false,
              "router_aux_weight": null,
              "router_lb_weight": null,
              "drop_policy": "none",
              "experts": []
            },
            "ssm": null,
            "extras": [
              {
                "type": "gated",
                "targets": [
                  "attn",
                  "ffn",
                  "ssm"
                ],
                "init_weight": 0.2,
                "learnable": true
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": null,
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 1024,
                "stride": 64,
                "aggregator": "gate",
                "gating_weight": 0.35
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": null,
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 1024,
                "stride": 64,
                "aggregator": "gate",
                "gating_weight": 0.35
              }
            ]
          }
        ],
        "head": {
          "tie_embeddings": true,
          "vocab": 50257
        },
        "norm": "layernorm",
        "recurrences": []
      },
      "train": {
        "lr": 0.0008,
        "warmup": 500,
        "clip": 1.0,
        "bf16": true,
        "grad_checkpoint": true,
        "max_tokens": 520000,
        "weight_decay": 0.02,
        "seed": 4242,
        "router_lb_coeff": 0.01,
        "router_entropy_coeff": 0.005,
        "entropy_threshold": 0.5,
        "entropy_patience": 3,
        "instability_threshold": 500.0,
        "no_improve_patience": 20,
        "improvement_tolerance": 0.001,
        "ppl_stop_threshold": null,
        "init_checkpoint": null,
        "optimizer": {
          "name": "adamw",
          "lr": null,
          "betas": null,
          "eps": null,
          "weight_decay": null
        }
      },
      "data": {
        "tokenizer": "gpt2",
        "hf_revision": "main",
        "seq_len": 512,
        "batch_size": 1,
        "workers": 0,
        "shards": [
          {
            "name": "ag_news",
            "split": "train",
            "weight": 0.25,
            "cache_path": null,
            "revision": null
          },
          {
            "name": "wikitext",
            "split": "wikitext-2-raw-v1",
            "weight": 0.35,
            "cache_path": null,
            "revision": null
          },
          {
            "name": "mbpp",
            "split": "train",
            "weight": 0.4,
            "cache_path": null,
            "revision": null
          }
        ],
        "healing_shards": [],
        "healing_tokens": null
      },
      "evolution": {
        "rung0_thresholds": {
          "gate_entropy_min": 0.0,
          "gate_entropy_max": 4.0
        },
        "rung1_tokens": 300000,
        "rung2_tokens": 900000,
        "population": 24,
        "topk_keep": 0.45,
        "crossover_prob": 0.5,
        "parent_selection": "lexicase",
        "pareto_objectives": [
          "ppl_code",
          "ppl_math",
          "long_recall",
          "ppl_per_long_recall",
          "throughput",
          "ram",
          "novelty",
          "graph_entropy"
        ],
        "objectives": {
          "ppl_code": "min",
          "ppl_math": "min",
          "long_recall": "max",
          "ppl_per_long_recall": "min",
          "throughput": "max",
          "ram": "min",
          "novelty": "max",
          "graph_entropy": "max",
          "instability": "min"
        },
        "composite_metrics": [
          {
            "name": "ppl_per_long_recall",
            "op": "ratio",
            "numerator": "ppl_code",
            "denominator": "long_recall",
            "terms": {},
            "epsilon": 0.1
          }
        ],
        "promotion_prob": 0.4,
        "promotion_min_layers": 8,
        "promotion_min_moe_blocks": 2,
        "promotion_steps_multiplier": 1.5,
        "promotion_tokens_multiplier": 1.5,
        "promotion_min_router_entropy": 0.0,
        "promotion_min_recurrence_gain": 0.0,
        "promotion_max_instability": null
      },
      "priors": {
        "tokens_per_param": 4.0,
        "window_scale": 6.0,
        "rope_theta_default": 10000.0,
        "prior_weight": 0.0,
        "compute_penalty_weight": 0.0
      }
    }
  },
  {
    "id": "duplicate_block_span-40-d10d",
    "parent": "xover-36-4415",
    "metrics": {
      "layers": 22.0,
      "moe_blocks": 8.0,
      "graph_entropy": 2.737987098144098,
      "selector_blocks": 0.0,
      "selector_topk_avg": 0.0,
      "memory_blocks": 14.0,
      "recurrences": 0.0,
      "novelty": 0.09523809523809523,
      "params": 517948277.0,
      "kv_bytes_per_token": 22528,
      "throughput_proxy": 7.8816059207128095,
      "ppl_code": 1.0,
      "ppl_math": 1.08,
      "throughput": 250.1546557355591,
      "ram": 0.9647538457065821,
      "long_recall": 1.05,
      "router_entropy": 0.6868815496563911,
      "router_lb": 0.02431207918561995,
      "router_load_max": 0.4921875,
      "router_load_min": 0.0,
      "router_load_cv": 2.627361297607422,
      "capacity_overflow": 0.0,
      "max_grad_norm": 0.0,
      "instability": 0.0,
      "stop_reason_code": 3.0,
      "nan_seen": 0.0,
      "loss_spike": 0.001142418012022972,
      "prior_distance": 0.026983458161321493,
      "ppl_per_long_recall": 0.9523809523809523,
      "ppl_per_param": 1.9306947129780683e-09,
      "ppl_per_throughput": 0.003997527038062045
    },
    "spec": {
      "model": {
        "name": "phi-tiny-evo-creative",
        "emb": {
          "dim": 512,
          "vocab": 50257,
          "rope": null,
          "dropout": 0.0
        },
        "blocks": [
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "moe",
              "hidden": 2048,
              "n_experts": 16,
              "k": 2,
              "capacity_factor": 1.2,
              "balance": 0.05,
              "shared": 1,
              "router_temperature": null,
              "router_type": "softmax",
              "router_bias_detached": false,
              "shared_expert": false,
              "router_aux_weight": null,
              "router_lb_weight": null,
              "drop_policy": "none",
              "experts": []
            },
            "ssm": null,
            "extras": [
              {
                "type": "custom",
                "name": "exp-gater",
                "params": {
                  "dim": 256
                }
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": "yarn",
              "rope_theta": null,
              "sw": 128,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "local_global",
              "block_size": null,
              "block_stride": null,
              "global_stride": 64,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": null,
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 256,
                "stride": 32,
                "aggregator": "gate",
                "gating_weight": 0.25
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "moe",
              "hidden": 2048,
              "n_experts": 16,
              "k": 2,
              "capacity_factor": 1.2,
              "balance": 0.05,
              "shared": 1,
              "router_temperature": null,
              "router_type": "softmax",
              "router_bias_detached": false,
              "shared_expert": false,
              "router_aux_weight": null,
              "router_lb_weight": null,
              "drop_policy": "none",
              "experts": []
            },
            "ssm": null,
            "extras": [
              {
                "type": "custom",
                "name": "exp-gater",
                "params": {
                  "dim": 256
                }
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": {
              "kind": "mamba2",
              "d_state": 16,
              "d_conv": 4,
              "dt_rank": 8,
              "chunk": 128,
              "gate": 0.15
            },
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 512,
                "stride": 128,
                "aggregator": "attention",
                "gating_weight": 0.1191520977835257
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "moe",
              "hidden": 2048,
              "n_experts": 16,
              "k": 2,
              "capacity_factor": 1.2,
              "balance": 0.05,
              "shared": 1,
              "router_temperature": null,
              "router_type": "softmax",
              "router_bias_detached": false,
              "shared_expert": false,
              "router_aux_weight": null,
              "router_lb_weight": null,
              "drop_policy": "none",
              "experts": []
            },
            "ssm": null,
            "extras": [
              {
                "type": "custom",
                "name": "exp-gater",
                "params": {
                  "dim": 256
                }
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": {
              "kind": "mamba2",
              "d_state": 16,
              "d_conv": 4,
              "dt_rank": 8,
              "chunk": 128,
              "gate": 0.15
            },
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 512,
                "stride": 128,
                "aggregator": "attention",
                "gating_weight": 0.1191520977835257
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": "yarn",
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "moe",
              "hidden": 2048,
              "n_experts": 16,
              "k": 2,
              "capacity_factor": 1.2,
              "balance": 0.05,
              "shared": 1,
              "router_temperature": null,
              "router_type": "softmax",
              "router_bias_detached": false,
              "shared_expert": false,
              "router_aux_weight": null,
              "router_lb_weight": null,
              "drop_policy": "none",
              "experts": []
            },
            "ssm": null,
            "extras": [
              {
                "type": "gated",
                "targets": [
                  "attn",
                  "ffn",
                  "ssm"
                ],
                "init_weight": 0.2,
                "learnable": true
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": null,
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 1024,
                "stride": 64,
                "aggregator": "gate",
                "gating_weight": 0.35
              },
              {
                "type": "custom",
                "name": "exp-4338",
                "params": {
                  "dim": 1024,
                  "activation": "relu",
                  "notes": "auto-generated"
                }
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": {
              "kind": "mamba2",
              "d_state": 16,
              "d_conv": 4,
              "dt_rank": 8,
              "chunk": 128,
              "gate": 0.15
            },
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 512,
                "stride": 128,
                "aggregator": "attention",
                "gating_weight": 0.1191520977835257
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": null,
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 1024,
                "stride": 64,
                "aggregator": "gate",
                "gating_weight": 0.35
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": {
              "kind": "mamba2",
              "d_state": 16,
              "d_conv": 4,
              "dt_rank": 8,
              "chunk": 128,
              "gate": 0.15
            },
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 512,
                "stride": 128,
                "aggregator": "attention",
                "gating_weight": 0.1191520977835257
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": "yarn",
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "moe",
              "hidden": 2048,
              "n_experts": 16,
              "k": 2,
              "capacity_factor": 1.2,
              "balance": 0.05,
              "shared": 1,
              "router_temperature": null,
              "router_type": "softmax",
              "router_bias_detached": false,
              "shared_expert": false,
              "router_aux_weight": null,
              "router_lb_weight": null,
              "drop_policy": "none",
              "experts": []
            },
            "ssm": null,
            "extras": [
              {
                "type": "gated",
                "targets": [
                  "attn",
                  "ffn",
                  "ssm"
                ],
                "init_weight": 0.2,
                "learnable": true
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": "yarn",
              "rope_theta": null,
              "sw": 128,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "local_global",
              "block_size": null,
              "block_stride": null,
              "global_stride": 64,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": null,
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 256,
                "stride": 32,
                "aggregator": "gate",
                "gating_weight": 0.25
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "moe",
              "hidden": 2048,
              "n_experts": 16,
              "k": 2,
              "capacity_factor": 1.2,
              "balance": 0.05,
              "shared": 1,
              "router_temperature": null,
              "router_type": "softmax",
              "router_bias_detached": false,
              "shared_expert": false,
              "router_aux_weight": null,
              "router_lb_weight": null,
              "drop_policy": "none",
              "experts": []
            },
            "ssm": null,
            "extras": [
              {
                "type": "custom",
                "name": "exp-gater",
                "params": {
                  "dim": 256
                }
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": "yarn",
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "moe",
              "hidden": 2048,
              "n_experts": 16,
              "k": 2,
              "capacity_factor": 1.2,
              "balance": 0.05,
              "shared": 1,
              "router_temperature": null,
              "router_type": "softmax",
              "router_bias_detached": false,
              "shared_expert": false,
              "router_aux_weight": null,
              "router_lb_weight": null,
              "drop_policy": "none",
              "experts": []
            },
            "ssm": null,
            "extras": [
              {
                "type": "gated",
                "targets": [
                  "attn",
                  "ffn",
                  "ssm"
                ],
                "init_weight": 0.2,
                "learnable": true
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": null,
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 1024,
                "stride": 64,
                "aggregator": "gate",
                "gating_weight": 0.35
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": {
              "kind": "mamba2",
              "d_state": 16,
              "d_conv": 4,
              "dt_rank": 8,
              "chunk": 128,
              "gate": 0.15
            },
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 256,
                "stride": 32,
                "aggregator": "attention",
                "gating_weight": 0.2936814817028589
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": "yarn",
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "moe",
              "hidden": 2048,
              "n_experts": 16,
              "k": 2,
              "capacity_factor": 1.2,
              "balance": 0.05,
              "shared": 1,
              "router_temperature": null,
              "router_type": "softmax",
              "router_bias_detached": false,
              "shared_expert": false,
              "router_aux_weight": null,
              "router_lb_weight": null,
              "drop_policy": "none",
              "experts": []
            },
            "ssm": null,
            "extras": [
              {
                "type": "gated",
                "targets": [
                  "attn",
                  "ffn",
                  "ssm"
                ],
                "init_weight": 0.2,
                "learnable": true
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": null,
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 1024,
                "stride": 64,
                "aggregator": "gate",
                "gating_weight": 0.35
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": null,
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 1024,
                "stride": 64,
                "aggregator": "gate",
                "gating_weight": 0.35
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": null,
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 1024,
                "stride": 64,
                "aggregator": "gate",
                "gating_weight": 0.35
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": null,
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 1024,
                "stride": 64,
                "aggregator": "gate",
                "gating_weight": 0.35
              }
            ]
          }
        ],
        "head": {
          "tie_embeddings": true,
          "vocab": 50257
        },
        "norm": "layernorm",
        "recurrences": []
      },
      "train": {
        "lr": 0.0008,
        "warmup": 500,
        "clip": 1.0,
        "bf16": true,
        "grad_checkpoint": true,
        "max_tokens": 520000,
        "weight_decay": 0.02,
        "seed": 4242,
        "router_lb_coeff": 0.01,
        "router_entropy_coeff": 0.005,
        "entropy_threshold": 0.5,
        "entropy_patience": 3,
        "instability_threshold": 500.0,
        "no_improve_patience": 20,
        "improvement_tolerance": 0.001,
        "ppl_stop_threshold": null,
        "init_checkpoint": null,
        "optimizer": {
          "name": "adamw",
          "lr": null,
          "betas": null,
          "eps": null,
          "weight_decay": null
        }
      },
      "data": {
        "tokenizer": "gpt2",
        "hf_revision": "main",
        "seq_len": 512,
        "batch_size": 1,
        "workers": 0,
        "shards": [
          {
            "name": "ag_news",
            "split": "train",
            "weight": 0.25,
            "cache_path": null,
            "revision": null
          },
          {
            "name": "wikitext",
            "split": "wikitext-2-raw-v1",
            "weight": 0.35,
            "cache_path": null,
            "revision": null
          },
          {
            "name": "mbpp",
            "split": "train",
            "weight": 0.4,
            "cache_path": null,
            "revision": null
          }
        ],
        "healing_shards": [],
        "healing_tokens": null
      },
      "evolution": {
        "rung0_thresholds": {
          "gate_entropy_min": 0.0,
          "gate_entropy_max": 4.0
        },
        "rung1_tokens": 300000,
        "rung2_tokens": 900000,
        "population": 24,
        "topk_keep": 0.45,
        "crossover_prob": 0.5,
        "parent_selection": "lexicase",
        "pareto_objectives": [
          "ppl_code",
          "ppl_math",
          "long_recall",
          "ppl_per_long_recall",
          "throughput",
          "ram",
          "novelty",
          "graph_entropy"
        ],
        "objectives": {
          "ppl_code": "min",
          "ppl_math": "min",
          "long_recall": "max",
          "ppl_per_long_recall": "min",
          "throughput": "max",
          "ram": "min",
          "novelty": "max",
          "graph_entropy": "max",
          "instability": "min"
        },
        "composite_metrics": [
          {
            "name": "ppl_per_long_recall",
            "op": "ratio",
            "numerator": "ppl_code",
            "denominator": "long_recall",
            "terms": {},
            "epsilon": 0.1
          }
        ],
        "promotion_prob": 0.4,
        "promotion_min_layers": 8,
        "promotion_min_moe_blocks": 2,
        "promotion_steps_multiplier": 1.5,
        "promotion_tokens_multiplier": 1.5,
        "promotion_min_router_entropy": 0.0,
        "promotion_min_recurrence_gain": 0.0,
        "promotion_max_instability": null
      },
      "priors": {
        "tokens_per_param": 4.0,
        "window_scale": 6.0,
        "rope_theta_default": 10000.0,
        "prior_weight": 0.0,
        "compute_penalty_weight": 0.0
      }
    }
  },
  {
    "id": "xover-42-a170",
    "parent": null,
    "metrics": {
      "layers": 20.0,
      "moe_blocks": 8.0,
      "graph_entropy": 2.732139651787716,
      "selector_blocks": 0.0,
      "selector_topk_avg": 0.0,
      "memory_blocks": 12.0,
      "recurrences": 0.0,
      "novelty": 1.75,
      "params": 510087573.0,
      "kv_bytes_per_token": 20480,
      "throughput_proxy": 9.5367431640625,
      "ppl_code": 1.0,
      "ppl_math": 1.08,
      "throughput": 229.32645406724248,
      "ram": 0.9501121435314417,
      "long_recall": 1.05,
      "router_entropy": 0.6880826726555824,
      "router_lb": 0.025228351820260286,
      "router_load_max": 0.494140625,
      "router_load_min": 0.0,
      "router_load_cv": 2.668726921081543,
      "capacity_overflow": 0.0,
      "max_grad_norm": 0.0,
      "instability": 0.0,
      "stop_reason_code": 3.0,
      "nan_seen": 0.0,
      "loss_spike": 0.0002447422593832016,
      "prior_distance": 0.015178195163041273,
      "ppl_per_long_recall": 0.9523809523809523,
      "ppl_per_param": 1.9604476817944358e-09,
      "ppl_per_throughput": 0.004360595920201961
    },
    "spec": {
      "model": {
        "name": "phi-tiny-evo-creative",
        "emb": {
          "dim": 512,
          "vocab": 50257,
          "rope": null,
          "dropout": 0.0
        },
        "blocks": [
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "moe",
              "hidden": 2048,
              "n_experts": 16,
              "k": 2,
              "capacity_factor": 1.2,
              "balance": 0.05,
              "shared": 1,
              "router_temperature": null,
              "router_type": "softmax",
              "router_bias_detached": false,
              "shared_expert": false,
              "router_aux_weight": null,
              "router_lb_weight": null,
              "drop_policy": "none",
              "experts": []
            },
            "ssm": null,
            "extras": [
              {
                "type": "custom",
                "name": "exp-gater",
                "params": {
                  "dim": 256
                }
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "moe",
              "hidden": 2048,
              "n_experts": 16,
              "k": 2,
              "capacity_factor": 1.2,
              "balance": 0.05,
              "shared": 1,
              "router_temperature": null,
              "router_type": "softmax",
              "router_bias_detached": false,
              "shared_expert": false,
              "router_aux_weight": null,
              "router_lb_weight": null,
              "drop_policy": "none",
              "experts": []
            },
            "ssm": null,
            "extras": [
              {
                "type": "custom",
                "name": "exp-gater",
                "params": {
                  "dim": 256
                }
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": {
              "kind": "mamba2",
              "d_state": 16,
              "d_conv": 4,
              "dt_rank": 8,
              "chunk": 128,
              "gate": 0.15
            },
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 512,
                "stride": 128,
                "aggregator": "attention",
                "gating_weight": 0.1191520977835257
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "moe",
              "hidden": 2048,
              "n_experts": 16,
              "k": 2,
              "capacity_factor": 1.2,
              "balance": 0.05,
              "shared": 1,
              "router_temperature": null,
              "router_type": "softmax",
              "router_bias_detached": false,
              "shared_expert": false,
              "router_aux_weight": null,
              "router_lb_weight": null,
              "drop_policy": "none",
              "experts": []
            },
            "ssm": null,
            "extras": [
              {
                "type": "custom",
                "name": "exp-gater",
                "params": {
                  "dim": 256
                }
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": {
              "kind": "mamba2",
              "d_state": 16,
              "d_conv": 4,
              "dt_rank": 8,
              "chunk": 128,
              "gate": 0.15
            },
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 512,
                "stride": 128,
                "aggregator": "attention",
                "gating_weight": 0.1191520977835257
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": "yarn",
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "moe",
              "hidden": 2048,
              "n_experts": 16,
              "k": 2,
              "capacity_factor": 1.2,
              "balance": 0.05,
              "shared": 1,
              "router_temperature": null,
              "router_type": "softmax",
              "router_bias_detached": false,
              "shared_expert": false,
              "router_aux_weight": null,
              "router_lb_weight": null,
              "drop_policy": "none",
              "experts": []
            },
            "ssm": null,
            "extras": [
              {
                "type": "gated",
                "targets": [
                  "attn",
                  "ffn",
                  "ssm"
                ],
                "init_weight": 0.2,
                "learnable": true
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": null,
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 1024,
                "stride": 64,
                "aggregator": "gate",
                "gating_weight": 0.35
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": {
              "kind": "mamba2",
              "d_state": 16,
              "d_conv": 4,
              "dt_rank": 8,
              "chunk": 128,
              "gate": 0.15
            },
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 512,
                "stride": 128,
                "aggregator": "attention",
                "gating_weight": 0.1191520977835257
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": "yarn",
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "moe",
              "hidden": 2048,
              "n_experts": 16,
              "k": 2,
              "capacity_factor": 1.2,
              "balance": 0.05,
              "shared": 1,
              "router_temperature": null,
              "router_type": "softmax",
              "router_bias_detached": false,
              "shared_expert": false,
              "router_aux_weight": null,
              "router_lb_weight": null,
              "drop_policy": "none",
              "experts": []
            },
            "ssm": null,
            "extras": [
              {
                "type": "gated",
                "targets": [
                  "attn",
                  "ffn",
                  "ssm"
                ],
                "init_weight": 0.2,
                "learnable": true
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": "yarn",
              "rope_theta": null,
              "sw": 128,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "local_global",
              "block_size": null,
              "block_stride": null,
              "global_stride": 64,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": null,
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 256,
                "stride": 32,
                "aggregator": "gate",
                "gating_weight": 0.25
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": {
              "kind": "mamba2",
              "d_state": 16,
              "d_conv": 4,
              "dt_rank": 8,
              "chunk": 128,
              "gate": 0.15
            },
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 512,
                "stride": 128,
                "aggregator": "attention",
                "gating_weight": 0.1191520977835257
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "moe",
              "hidden": 2048,
              "n_experts": 16,
              "k": 2,
              "capacity_factor": 1.2,
              "balance": 0.05,
              "shared": 1,
              "router_temperature": null,
              "router_type": "softmax",
              "router_bias_detached": false,
              "shared_expert": false,
              "router_aux_weight": null,
              "router_lb_weight": null,
              "drop_policy": "none",
              "experts": []
            },
            "ssm": null,
            "extras": [
              {
                "type": "custom",
                "name": "exp-gater",
                "params": {
                  "dim": 256
                }
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": {
              "kind": "mamba2",
              "d_state": 16,
              "d_conv": 4,
              "dt_rank": 8,
              "chunk": 128,
              "gate": 0.15
            },
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 512,
                "stride": 128,
                "aggregator": "attention",
                "gating_weight": 0.1191520977835257
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": "yarn",
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "moe",
              "hidden": 2048,
              "n_experts": 16,
              "k": 2,
              "capacity_factor": 1.2,
              "balance": 0.05,
              "shared": 1,
              "router_temperature": null,
              "router_type": "softmax",
              "router_bias_detached": false,
              "shared_expert": false,
              "router_aux_weight": null,
              "router_lb_weight": null,
              "drop_policy": "none",
              "experts": []
            },
            "ssm": null,
            "extras": [
              {
                "type": "gated",
                "targets": [
                  "attn",
                  "ffn",
                  "ssm"
                ],
                "init_weight": 0.2,
                "learnable": true
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": null,
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 1024,
                "stride": 64,
                "aggregator": "gate",
                "gating_weight": 0.35
              },
              {
                "type": "custom",
                "name": "exp-4338",
                "params": {
                  "dim": 1024,
                  "activation": "relu",
                  "notes": "auto-generated"
                }
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": {
              "kind": "mamba2",
              "d_state": 16,
              "d_conv": 4,
              "dt_rank": 8,
              "chunk": 128,
              "gate": 0.15
            },
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 512,
                "stride": 128,
                "aggregator": "attention",
                "gating_weight": 0.1191520977835257
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": "yarn",
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "moe",
              "hidden": 2048,
              "n_experts": 16,
              "k": 2,
              "capacity_factor": 1.2,
              "balance": 0.05,
              "shared": 1,
              "router_temperature": null,
              "router_type": "softmax",
              "router_bias_detached": false,
              "shared_expert": false,
              "router_aux_weight": null,
              "router_lb_weight": null,
              "drop_policy": "none",
              "experts": []
            },
            "ssm": null,
            "extras": [
              {
                "type": "gated",
                "targets": [
                  "attn",
                  "ffn",
                  "ssm"
                ],
                "init_weight": 0.2,
                "learnable": true
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": null,
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 1024,
                "stride": 64,
                "aggregator": "gate",
                "gating_weight": 0.35
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": null,
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 1024,
                "stride": 64,
                "aggregator": "gate",
                "gating_weight": 0.35
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": null,
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 1024,
                "stride": 64,
                "aggregator": "gate",
                "gating_weight": 0.35
              }
            ]
          }
        ],
        "head": {
          "tie_embeddings": true,
          "vocab": 50257
        },
        "norm": "layernorm",
        "recurrences": []
      },
      "train": {
        "lr": 0.0008,
        "warmup": 500,
        "clip": 1.0,
        "bf16": true,
        "grad_checkpoint": true,
        "max_tokens": 520000,
        "weight_decay": 0.02,
        "seed": 4242,
        "router_lb_coeff": 0.01,
        "router_entropy_coeff": 0.005,
        "entropy_threshold": 0.5,
        "entropy_patience": 3,
        "instability_threshold": 500.0,
        "no_improve_patience": 20,
        "improvement_tolerance": 0.001,
        "ppl_stop_threshold": null,
        "init_checkpoint": null,
        "optimizer": {
          "name": "adamw",
          "lr": null,
          "betas": null,
          "eps": null,
          "weight_decay": null
        }
      },
      "data": {
        "tokenizer": "gpt2",
        "hf_revision": "main",
        "seq_len": 512,
        "batch_size": 1,
        "workers": 0,
        "shards": [
          {
            "name": "ag_news",
            "split": "train",
            "weight": 0.25,
            "cache_path": null,
            "revision": null
          },
          {
            "name": "wikitext",
            "split": "wikitext-2-raw-v1",
            "weight": 0.35,
            "cache_path": null,
            "revision": null
          },
          {
            "name": "mbpp",
            "split": "train",
            "weight": 0.4,
            "cache_path": null,
            "revision": null
          }
        ],
        "healing_shards": [],
        "healing_tokens": null
      },
      "evolution": {
        "rung0_thresholds": {
          "gate_entropy_min": 0.0,
          "gate_entropy_max": 4.0
        },
        "rung1_tokens": 300000,
        "rung2_tokens": 900000,
        "population": 24,
        "topk_keep": 0.45,
        "crossover_prob": 0.5,
        "parent_selection": "lexicase",
        "pareto_objectives": [
          "ppl_code",
          "ppl_math",
          "long_recall",
          "ppl_per_long_recall",
          "throughput",
          "ram",
          "novelty",
          "graph_entropy"
        ],
        "objectives": {
          "ppl_code": "min",
          "ppl_math": "min",
          "long_recall": "max",
          "ppl_per_long_recall": "min",
          "throughput": "max",
          "ram": "min",
          "novelty": "max",
          "graph_entropy": "max",
          "instability": "min"
        },
        "composite_metrics": [
          {
            "name": "ppl_per_long_recall",
            "op": "ratio",
            "numerator": "ppl_code",
            "denominator": "long_recall",
            "terms": {},
            "epsilon": 0.1
          }
        ],
        "promotion_prob": 0.4,
        "promotion_min_layers": 8,
        "promotion_min_moe_blocks": 2,
        "promotion_steps_multiplier": 1.5,
        "promotion_tokens_multiplier": 1.5,
        "promotion_min_router_entropy": 0.0,
        "promotion_min_recurrence_gain": 0.0,
        "promotion_max_instability": null
      },
      "priors": {
        "tokens_per_param": 4.0,
        "window_scale": 6.0,
        "rope_theta_default": 10000.0,
        "prior_weight": 0.0,
        "compute_penalty_weight": 0.0
      }
    }
  },
  {
    "id": "shift_moe-43-0a4d",
    "parent": "xover-36-4415",
    "metrics": {
      "layers": 20.0,
      "moe_blocks": 8.0,
      "graph_entropy": 2.7525148891944324,
      "selector_blocks": 0.0,
      "selector_topk_avg": 0.0,
      "memory_blocks": 12.0,
      "recurrences": 0.0,
      "novelty": 0.25,
      "params": 510069621.0,
      "kv_bytes_per_token": 20480,
      "throughput_proxy": 9.5367431640625,
      "ppl_code": 1.0,
      "ppl_math": 1.08,
      "throughput": 245.51630308768551,
      "ram": 0.9500787053257227,
      "long_recall": 1.025,
      "router_entropy": 0.6896368265151978,
      "router_lb": 0.025083944434300065,
      "router_load_max": 0.49609375,
      "router_load_min": 0.0,
      "router_load_cv": 2.69301176071167,
      "capacity_overflow": 0.0,
      "max_grad_norm": 0.0,
      "instability": 0.0,
      "stop_reason_code": 3.0,
      "nan_seen": 0.0,
      "loss_spike": 0.00010297447443008423,
      "prior_distance": 0.030356390326082547,
      "ppl_per_long_recall": 0.9756097560975611,
      "ppl_per_param": 1.96051668013375e-09,
      "ppl_per_throughput": 0.00407304927381076
    },
    "spec": {
      "model": {
        "name": "phi-tiny-evo-creative",
        "emb": {
          "dim": 512,
          "vocab": 50257,
          "rope": null,
          "dropout": 0.0
        },
        "blocks": [
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": "yarn",
              "rope_theta": null,
              "sw": 128,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "local_global",
              "block_size": null,
              "block_stride": null,
              "global_stride": 64,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": null,
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 256,
                "stride": 32,
                "aggregator": "gate",
                "gating_weight": 0.25
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "moe",
              "hidden": 2048,
              "n_experts": 16,
              "k": 2,
              "capacity_factor": 1.2,
              "balance": 0.05,
              "shared": 1,
              "router_temperature": null,
              "router_type": "softmax",
              "router_bias_detached": false,
              "shared_expert": false,
              "router_aux_weight": null,
              "router_lb_weight": null,
              "drop_policy": "none",
              "experts": []
            },
            "ssm": null,
            "extras": [
              {
                "type": "custom",
                "name": "exp-gater",
                "params": {
                  "dim": 256
                }
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "moe",
              "hidden": 2048,
              "n_experts": 16,
              "k": 2,
              "capacity_factor": 1.2,
              "balance": 0.05,
              "shared": 1,
              "router_temperature": null,
              "router_type": "softmax",
              "router_bias_detached": false,
              "shared_expert": false,
              "router_aux_weight": null,
              "router_lb_weight": null,
              "drop_policy": "none",
              "experts": []
            },
            "ssm": null,
            "extras": [
              {
                "type": "custom",
                "name": "exp-gater",
                "params": {
                  "dim": 256
                }
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": {
              "kind": "mamba2",
              "d_state": 16,
              "d_conv": 4,
              "dt_rank": 8,
              "chunk": 128,
              "gate": 0.15
            },
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 512,
                "stride": 128,
                "aggregator": "attention",
                "gating_weight": 0.1191520977835257
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "moe",
              "hidden": 2048,
              "n_experts": 16,
              "k": 2,
              "capacity_factor": 1.2,
              "balance": 0.05,
              "shared": 1,
              "router_temperature": null,
              "router_type": "softmax",
              "router_bias_detached": false,
              "shared_expert": false,
              "router_aux_weight": null,
              "router_lb_weight": null,
              "drop_policy": "none",
              "experts": []
            },
            "ssm": null,
            "extras": [
              {
                "type": "custom",
                "name": "exp-gater",
                "params": {
                  "dim": 256
                }
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": {
              "kind": "mamba2",
              "d_state": 16,
              "d_conv": 4,
              "dt_rank": 8,
              "chunk": 128,
              "gate": 0.15
            },
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 512,
                "stride": 128,
                "aggregator": "attention",
                "gating_weight": 0.1191520977835257
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": "yarn",
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "moe",
              "hidden": 2048,
              "n_experts": 16,
              "k": 2,
              "capacity_factor": 1.2,
              "balance": 0.05,
              "shared": 1,
              "router_temperature": null,
              "router_type": "softmax",
              "router_bias_detached": false,
              "shared_expert": false,
              "router_aux_weight": null,
              "router_lb_weight": null,
              "drop_policy": "none",
              "experts": []
            },
            "ssm": null,
            "extras": [
              {
                "type": "gated",
                "targets": [
                  "attn",
                  "ffn",
                  "ssm"
                ],
                "init_weight": 0.2,
                "learnable": true
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": null,
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 1024,
                "stride": 64,
                "aggregator": "gate",
                "gating_weight": 0.35
              },
              {
                "type": "custom",
                "name": "exp-4338",
                "params": {
                  "dim": 1024,
                  "activation": "relu",
                  "notes": "auto-generated"
                }
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": {
              "kind": "mamba2",
              "d_state": 16,
              "d_conv": 4,
              "dt_rank": 8,
              "chunk": 128,
              "gate": 0.15
            },
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 512,
                "stride": 128,
                "aggregator": "attention",
                "gating_weight": 0.1191520977835257
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": null,
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 1024,
                "stride": 64,
                "aggregator": "gate",
                "gating_weight": 0.35
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": {
              "kind": "mamba2",
              "d_state": 16,
              "d_conv": 4,
              "dt_rank": 8,
              "chunk": 128,
              "gate": 0.15
            },
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 512,
                "stride": 128,
                "aggregator": "attention",
                "gating_weight": 0.1191520977835257
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": "yarn",
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "moe",
              "hidden": 2048,
              "n_experts": 16,
              "k": 2,
              "capacity_factor": 1.2,
              "balance": 0.05,
              "shared": 1,
              "router_temperature": null,
              "router_type": "softmax",
              "router_bias_detached": false,
              "shared_expert": false,
              "router_aux_weight": null,
              "router_lb_weight": null,
              "drop_policy": "none",
              "experts": []
            },
            "ssm": null,
            "extras": [
              {
                "type": "gated",
                "targets": [
                  "attn",
                  "ffn",
                  "ssm"
                ],
                "init_weight": 0.2,
                "learnable": true
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": "yarn",
              "rope_theta": null,
              "sw": 128,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "local_global",
              "block_size": null,
              "block_stride": null,
              "global_stride": 64,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": null,
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 256,
                "stride": 32,
                "aggregator": "gate",
                "gating_weight": 0.25
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "moe",
              "hidden": 2048,
              "n_experts": 16,
              "k": 2,
              "capacity_factor": 1.2,
              "balance": 0.05,
              "shared": 1,
              "router_temperature": null,
              "router_type": "softmax",
              "router_bias_detached": false,
              "shared_expert": false,
              "router_aux_weight": null,
              "router_lb_weight": null,
              "drop_policy": "none",
              "experts": []
            },
            "ssm": null,
            "extras": [
              {
                "type": "custom",
                "name": "exp-gater",
                "params": {
                  "dim": 256
                }
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": "yarn",
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "moe",
              "hidden": 2048,
              "n_experts": 16,
              "k": 2,
              "capacity_factor": 1.2,
              "balance": 0.05,
              "shared": 1,
              "router_temperature": null,
              "router_type": "softmax",
              "router_bias_detached": false,
              "shared_expert": false,
              "router_aux_weight": null,
              "router_lb_weight": null,
              "drop_policy": "none",
              "experts": []
            },
            "ssm": null,
            "extras": [
              {
                "type": "gated",
                "targets": [
                  "attn",
                  "ffn",
                  "ssm"
                ],
                "init_weight": 0.2,
                "learnable": true
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": null,
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 1024,
                "stride": 64,
                "aggregator": "gate",
                "gating_weight": 0.35
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": {
              "kind": "mamba2",
              "d_state": 16,
              "d_conv": 4,
              "dt_rank": 8,
              "chunk": 128,
              "gate": 0.15
            },
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 256,
                "stride": 32,
                "aggregator": "attention",
                "gating_weight": 0.2936814817028589
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": "yarn",
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "moe",
              "hidden": 2048,
              "n_experts": 16,
              "k": 2,
              "capacity_factor": 1.2,
              "balance": 0.05,
              "shared": 1,
              "router_temperature": null,
              "router_type": "softmax",
              "router_bias_detached": false,
              "shared_expert": false,
              "router_aux_weight": null,
              "router_lb_weight": null,
              "drop_policy": "none",
              "experts": []
            },
            "ssm": null,
            "extras": [
              {
                "type": "gated",
                "targets": [
                  "attn",
                  "ffn",
                  "ssm"
                ],
                "init_weight": 0.2,
                "learnable": true
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": null,
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 1024,
                "stride": 64,
                "aggregator": "gate",
                "gating_weight": 0.35
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": null,
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 1024,
                "stride": 64,
                "aggregator": "gate",
                "gating_weight": 0.35
              }
            ]
          }
        ],
        "head": {
          "tie_embeddings": true,
          "vocab": 50257
        },
        "norm": "layernorm",
        "recurrences": []
      },
      "train": {
        "lr": 0.0008,
        "warmup": 500,
        "clip": 1.0,
        "bf16": true,
        "grad_checkpoint": true,
        "max_tokens": 520000,
        "weight_decay": 0.02,
        "seed": 4242,
        "router_lb_coeff": 0.01,
        "router_entropy_coeff": 0.005,
        "entropy_threshold": 0.5,
        "entropy_patience": 3,
        "instability_threshold": 500.0,
        "no_improve_patience": 20,
        "improvement_tolerance": 0.001,
        "ppl_stop_threshold": null,
        "init_checkpoint": null,
        "optimizer": {
          "name": "adamw",
          "lr": null,
          "betas": null,
          "eps": null,
          "weight_decay": null
        }
      },
      "data": {
        "tokenizer": "gpt2",
        "hf_revision": "main",
        "seq_len": 512,
        "batch_size": 1,
        "workers": 0,
        "shards": [
          {
            "name": "ag_news",
            "split": "train",
            "weight": 0.25,
            "cache_path": null,
            "revision": null
          },
          {
            "name": "wikitext",
            "split": "wikitext-2-raw-v1",
            "weight": 0.35,
            "cache_path": null,
            "revision": null
          },
          {
            "name": "mbpp",
            "split": "train",
            "weight": 0.4,
            "cache_path": null,
            "revision": null
          }
        ],
        "healing_shards": [],
        "healing_tokens": null
      },
      "evolution": {
        "rung0_thresholds": {
          "gate_entropy_min": 0.0,
          "gate_entropy_max": 4.0
        },
        "rung1_tokens": 300000,
        "rung2_tokens": 900000,
        "population": 24,
        "topk_keep": 0.45,
        "crossover_prob": 0.5,
        "parent_selection": "lexicase",
        "pareto_objectives": [
          "ppl_code",
          "ppl_math",
          "long_recall",
          "ppl_per_long_recall",
          "throughput",
          "ram",
          "novelty",
          "graph_entropy"
        ],
        "objectives": {
          "ppl_code": "min",
          "ppl_math": "min",
          "long_recall": "max",
          "ppl_per_long_recall": "min",
          "throughput": "max",
          "ram": "min",
          "novelty": "max",
          "graph_entropy": "max",
          "instability": "min"
        },
        "composite_metrics": [
          {
            "name": "ppl_per_long_recall",
            "op": "ratio",
            "numerator": "ppl_code",
            "denominator": "long_recall",
            "terms": {},
            "epsilon": 0.1
          }
        ],
        "promotion_prob": 0.4,
        "promotion_min_layers": 8,
        "promotion_min_moe_blocks": 2,
        "promotion_steps_multiplier": 1.5,
        "promotion_tokens_multiplier": 1.5,
        "promotion_min_router_entropy": 0.0,
        "promotion_min_recurrence_gain": 0.0,
        "promotion_max_instability": null
      },
      "priors": {
        "tokens_per_param": 4.0,
        "window_scale": 6.0,
        "rope_theta_default": 10000.0,
        "prior_weight": 0.0,
        "compute_penalty_weight": 0.0
      }
    }
  },
  {
    "id": "xover-45-88da",
    "parent": null,
    "metrics": {
      "layers": 2.0,
      "moe_blocks": 1.0,
      "graph_entropy": 2.142729180266674,
      "selector_blocks": 0.0,
      "selector_topk_avg": 0.0,
      "memory_blocks": 1.0,
      "recurrences": 0.0,
      "novelty": 1.9285714285714286,
      "params": 84338017.0,
      "kv_bytes_per_token": 2048,
      "throughput_proxy": 953.67431640625,
      "ppl_code": 1.0,
      "ppl_math": 1.01,
      "throughput": 765.5367465172728,
      "ram": 0.157091798260808,
      "long_recall": 0.7,
      "router_entropy": 0.6826527714729309,
      "router_lb": 0.023753046989440918,
      "router_load_max": 0.4716796875,
      "router_load_min": 0.0009765625,
      "router_load_cv": 2.546795129776001,
      "capacity_overflow": 0.0,
      "max_grad_norm": 0.0,
      "instability": 0.0,
      "stop_reason_code": 3.0,
      "nan_seen": 0.0,
      "loss_spike": 3.194226883351803e-05,
      "prior_distance": 0.0,
      "ppl_per_long_recall": 1.4285714285714286,
      "ppl_per_param": 1.185704899843685e-08,
      "ppl_per_throughput": 0.0013062730228815176
    },
    "spec": {
      "model": {
        "name": "phi-tiny-evo-creative",
        "emb": {
          "dim": 512,
          "vocab": 50257,
          "rope": null,
          "dropout": 0.0
        },
        "blocks": [
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "moe",
              "hidden": 2048,
              "n_experts": 16,
              "k": 2,
              "capacity_factor": 1.2,
              "balance": 0.05,
              "shared": 1,
              "router_temperature": null,
              "router_type": "softmax",
              "router_bias_detached": false,
              "shared_expert": false,
              "router_aux_weight": null,
              "router_lb_weight": null,
              "drop_policy": "none",
              "experts": []
            },
            "ssm": null,
            "extras": [
              {
                "type": "custom",
                "name": "exp-gater",
                "params": {
                  "dim": 256
                }
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": null,
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 1024,
                "stride": 64,
                "aggregator": "gate",
                "gating_weight": 0.35
              }
            ]
          }
        ],
        "head": {
          "tie_embeddings": true,
          "vocab": 50257
        },
        "norm": "layernorm",
        "recurrences": []
      },
      "train": {
        "lr": 0.0008,
        "warmup": 500,
        "clip": 1.0,
        "bf16": true,
        "grad_checkpoint": true,
        "max_tokens": 520000,
        "weight_decay": 0.02,
        "seed": 4242,
        "router_lb_coeff": 0.01,
        "router_entropy_coeff": 0.005,
        "entropy_threshold": 0.5,
        "entropy_patience": 3,
        "instability_threshold": 500.0,
        "no_improve_patience": 20,
        "improvement_tolerance": 0.001,
        "ppl_stop_threshold": null,
        "init_checkpoint": null,
        "optimizer": {
          "name": "adamw",
          "lr": null,
          "betas": null,
          "eps": null,
          "weight_decay": null
        }
      },
      "data": {
        "tokenizer": "gpt2",
        "hf_revision": "main",
        "seq_len": 512,
        "batch_size": 1,
        "workers": 0,
        "shards": [
          {
            "name": "ag_news",
            "split": "train",
            "weight": 0.25,
            "cache_path": null,
            "revision": null
          },
          {
            "name": "wikitext",
            "split": "wikitext-2-raw-v1",
            "weight": 0.35,
            "cache_path": null,
            "revision": null
          },
          {
            "name": "mbpp",
            "split": "train",
            "weight": 0.4,
            "cache_path": null,
            "revision": null
          }
        ],
        "healing_shards": [],
        "healing_tokens": null
      },
      "evolution": {
        "rung0_thresholds": {
          "gate_entropy_min": 0.0,
          "gate_entropy_max": 4.0
        },
        "rung1_tokens": 300000,
        "rung2_tokens": 900000,
        "population": 24,
        "topk_keep": 0.45,
        "crossover_prob": 0.5,
        "parent_selection": "lexicase",
        "pareto_objectives": [
          "ppl_code",
          "ppl_math",
          "long_recall",
          "ppl_per_long_recall",
          "throughput",
          "ram",
          "novelty",
          "graph_entropy"
        ],
        "objectives": {
          "ppl_code": "min",
          "ppl_math": "min",
          "long_recall": "max",
          "ppl_per_long_recall": "min",
          "throughput": "max",
          "ram": "min",
          "novelty": "max",
          "graph_entropy": "max",
          "instability": "min"
        },
        "composite_metrics": [
          {
            "name": "ppl_per_long_recall",
            "op": "ratio",
            "numerator": "ppl_code",
            "denominator": "long_recall",
            "terms": {},
            "epsilon": 0.1
          }
        ],
        "promotion_prob": 0.4,
        "promotion_min_layers": 8,
        "promotion_min_moe_blocks": 2,
        "promotion_steps_multiplier": 1.5,
        "promotion_tokens_multiplier": 1.5,
        "promotion_min_router_entropy": 0.0,
        "promotion_min_recurrence_gain": 0.0,
        "promotion_max_instability": null
      },
      "priors": {
        "tokens_per_param": 4.0,
        "window_scale": 6.0,
        "rope_theta_default": 10000.0,
        "prior_weight": 0.0,
        "compute_penalty_weight": 0.0
      }
    }
  },
  {
    "id": "xover-46-9d4c",
    "parent": null,
    "metrics": {
      "layers": 15.0,
      "moe_blocks": 5.0,
      "graph_entropy": 2.695018032114523,
      "selector_blocks": 0.0,
      "selector_topk_avg": 0.0,
      "memory_blocks": 10.0,
      "recurrences": 0.0,
      "novelty": 0.9629629629629629,
      "params": 339901475.0,
      "kv_bytes_per_token": 15360,
      "throughput_proxy": 16.954210069444443,
      "ppl_code": 1.0,
      "ppl_math": 1.05,
      "throughput": 317.0214299479207,
      "ram": 0.6331158336251974,
      "long_recall": 1.1,
      "router_entropy": 0.6849294543266297,
      "router_lb": 0.02557835578918457,
      "router_load_max": 0.4931640625,
      "router_load_min": 0.0,
      "router_load_cv": 2.6809089183807373,
      "capacity_overflow": 0.0,
      "max_grad_norm": 0.0,
      "instability": 0.0,
      "stop_reason_code": 3.0,
      "nan_seen": 0.0,
      "loss_spike": 3.9206817746162415e-05,
      "prior_distance": 0.01942808963869705,
      "ppl_per_long_recall": 0.9090909090909091,
      "ppl_per_param": 2.942029010024155e-09,
      "ppl_per_throughput": 0.003154360890253624
    },
    "spec": {
      "model": {
        "name": "phi-tiny-evo-creative",
        "emb": {
          "dim": 512,
          "vocab": 50257,
          "rope": null,
          "dropout": 0.0
        },
        "blocks": [
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "moe",
              "hidden": 2048,
              "n_experts": 16,
              "k": 2,
              "capacity_factor": 1.2,
              "balance": 0.05,
              "shared": 1,
              "router_temperature": null,
              "router_type": "softmax",
              "router_bias_detached": false,
              "shared_expert": false,
              "router_aux_weight": null,
              "router_lb_weight": null,
              "drop_policy": "none",
              "experts": []
            },
            "ssm": null,
            "extras": [
              {
                "type": "custom",
                "name": "exp-gater",
                "params": {
                  "dim": 256
                }
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": "yarn",
              "rope_theta": null,
              "sw": 128,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "local_global",
              "block_size": null,
              "block_stride": null,
              "global_stride": 64,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": null,
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 256,
                "stride": 32,
                "aggregator": "gate",
                "gating_weight": 0.25
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "moe",
              "hidden": 2048,
              "n_experts": 16,
              "k": 2,
              "capacity_factor": 1.2,
              "balance": 0.05,
              "shared": 1,
              "router_temperature": null,
              "router_type": "softmax",
              "router_bias_detached": false,
              "shared_expert": false,
              "router_aux_weight": null,
              "router_lb_weight": null,
              "drop_policy": "none",
              "experts": []
            },
            "ssm": null,
            "extras": [
              {
                "type": "custom",
                "name": "exp-gater",
                "params": {
                  "dim": 256
                }
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": {
              "kind": "mamba2",
              "d_state": 16,
              "d_conv": 4,
              "dt_rank": 8,
              "chunk": 128,
              "gate": 0.15
            },
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 512,
                "stride": 128,
                "aggregator": "attention",
                "gating_weight": 0.1191520977835257
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "moe",
              "hidden": 2048,
              "n_experts": 16,
              "k": 2,
              "capacity_factor": 1.2,
              "balance": 0.05,
              "shared": 1,
              "router_temperature": null,
              "router_type": "softmax",
              "router_bias_detached": false,
              "shared_expert": false,
              "router_aux_weight": null,
              "router_lb_weight": null,
              "drop_policy": "none",
              "experts": []
            },
            "ssm": null,
            "extras": [
              {
                "type": "custom",
                "name": "exp-gater",
                "params": {
                  "dim": 256
                }
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": {
              "kind": "mamba2",
              "d_state": 16,
              "d_conv": 4,
              "dt_rank": 8,
              "chunk": 128,
              "gate": 0.15
            },
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 512,
                "stride": 128,
                "aggregator": "attention",
                "gating_weight": 0.1191520977835257
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": "yarn",
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "moe",
              "hidden": 2048,
              "n_experts": 16,
              "k": 2,
              "capacity_factor": 1.2,
              "balance": 0.05,
              "shared": 1,
              "router_temperature": null,
              "router_type": "softmax",
              "router_bias_detached": false,
              "shared_expert": false,
              "router_aux_weight": null,
              "router_lb_weight": null,
              "drop_policy": "none",
              "experts": []
            },
            "ssm": null,
            "extras": [
              {
                "type": "gated",
                "targets": [
                  "attn",
                  "ffn",
                  "ssm"
                ],
                "init_weight": 0.2,
                "learnable": true
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": null,
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 1024,
                "stride": 64,
                "aggregator": "gate",
                "gating_weight": 0.35
              },
              {
                "type": "custom",
                "name": "exp-4338",
                "params": {
                  "dim": 1024,
                  "activation": "relu",
                  "notes": "auto-generated"
                }
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": {
              "kind": "mamba2",
              "d_state": 16,
              "d_conv": 4,
              "dt_rank": 8,
              "chunk": 128,
              "gate": 0.15
            },
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 512,
                "stride": 128,
                "aggregator": "attention",
                "gating_weight": 0.1191520977835257
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": null,
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 1024,
                "stride": 64,
                "aggregator": "gate",
                "gating_weight": 0.35
              },
              {
                "type": "custom",
                "name": "exp-4338",
                "params": {
                  "dim": 1024,
                  "activation": "relu",
                  "notes": "auto-generated"
                }
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": {
              "kind": "mamba2",
              "d_state": 16,
              "d_conv": 4,
              "dt_rank": 8,
              "chunk": 128,
              "gate": 0.15
            },
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 512,
                "stride": 128,
                "aggregator": "attention",
                "gating_weight": 0.1191520977835257
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": "yarn",
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "moe",
              "hidden": 2048,
              "n_experts": 16,
              "k": 2,
              "capacity_factor": 1.2,
              "balance": 0.05,
              "shared": 1,
              "router_temperature": null,
              "router_type": "softmax",
              "router_bias_detached": false,
              "shared_expert": false,
              "router_aux_weight": null,
              "router_lb_weight": null,
              "drop_policy": "none",
              "experts": []
            },
            "ssm": null,
            "extras": [
              {
                "type": "gated",
                "targets": [
                  "attn",
                  "ffn",
                  "ssm"
                ],
                "init_weight": 0.2,
                "learnable": true
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": null,
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 1024,
                "stride": 64,
                "aggregator": "gate",
                "gating_weight": 0.35
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": null,
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 1024,
                "stride": 64,
                "aggregator": "gate",
                "gating_weight": 0.35
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": null,
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 1024,
                "stride": 64,
                "aggregator": "gate",
                "gating_weight": 0.35
              }
            ]
          }
        ],
        "head": {
          "tie_embeddings": true,
          "vocab": 50257
        },
        "norm": "layernorm",
        "recurrences": []
      },
      "train": {
        "lr": 0.0008,
        "warmup": 500,
        "clip": 1.0,
        "bf16": true,
        "grad_checkpoint": true,
        "max_tokens": 520000,
        "weight_decay": 0.02,
        "seed": 4242,
        "router_lb_coeff": 0.01,
        "router_entropy_coeff": 0.005,
        "entropy_threshold": 0.5,
        "entropy_patience": 3,
        "instability_threshold": 500.0,
        "no_improve_patience": 20,
        "improvement_tolerance": 0.001,
        "ppl_stop_threshold": null,
        "init_checkpoint": null,
        "optimizer": {
          "name": "adamw",
          "lr": null,
          "betas": null,
          "eps": null,
          "weight_decay": null
        }
      },
      "data": {
        "tokenizer": "gpt2",
        "hf_revision": "main",
        "seq_len": 512,
        "batch_size": 1,
        "workers": 0,
        "shards": [
          {
            "name": "ag_news",
            "split": "train",
            "weight": 0.25,
            "cache_path": null,
            "revision": null
          },
          {
            "name": "wikitext",
            "split": "wikitext-2-raw-v1",
            "weight": 0.35,
            "cache_path": null,
            "revision": null
          },
          {
            "name": "mbpp",
            "split": "train",
            "weight": 0.4,
            "cache_path": null,
            "revision": null
          }
        ],
        "healing_shards": [],
        "healing_tokens": null
      },
      "evolution": {
        "rung0_thresholds": {
          "gate_entropy_min": 0.0,
          "gate_entropy_max": 4.0
        },
        "rung1_tokens": 300000,
        "rung2_tokens": 900000,
        "population": 24,
        "topk_keep": 0.45,
        "crossover_prob": 0.5,
        "parent_selection": "lexicase",
        "pareto_objectives": [
          "ppl_code",
          "ppl_math",
          "long_recall",
          "ppl_per_long_recall",
          "throughput",
          "ram",
          "novelty",
          "graph_entropy"
        ],
        "objectives": {
          "ppl_code": "min",
          "ppl_math": "min",
          "long_recall": "max",
          "ppl_per_long_recall": "min",
          "throughput": "max",
          "ram": "min",
          "novelty": "max",
          "graph_entropy": "max",
          "instability": "min"
        },
        "composite_metrics": [
          {
            "name": "ppl_per_long_recall",
            "op": "ratio",
            "numerator": "ppl_code",
            "denominator": "long_recall",
            "terms": {},
            "epsilon": 0.1
          }
        ],
        "promotion_prob": 0.4,
        "promotion_min_layers": 8,
        "promotion_min_moe_blocks": 2,
        "promotion_steps_multiplier": 1.5,
        "promotion_tokens_multiplier": 1.5,
        "promotion_min_router_entropy": 0.0,
        "promotion_min_recurrence_gain": 0.0,
        "promotion_max_instability": null
      },
      "priors": {
        "tokens_per_param": 4.0,
        "window_scale": 6.0,
        "rope_theta_default": 10000.0,
        "prior_weight": 0.0,
        "compute_penalty_weight": 0.0
      }
    }
  },
  {
    "id": "graph_jitter-47-3679",
    "parent": "xover-42-a170",
    "metrics": {
      "layers": 22.0,
      "moe_blocks": 9.0,
      "graph_entropy": 2.741244332234336,
      "selector_blocks": 0.0,
      "selector_topk_avg": 0.0,
      "memory_blocks": 13.0,
      "recurrences": 0.0,
      "novelty": 0.09523809523809523,
      "params": 568660677.0,
      "kv_bytes_per_token": 22528,
      "throughput_proxy": 7.8816059207128095,
      "ppl_code": 1.0,
      "ppl_math": 1.09,
      "throughput": 198.8185425676729,
      "ram": 1.059213051572442,
      "long_recall": 1.05,
      "router_entropy": 0.762855139043596,
      "router_lb": 0.020901514631178644,
      "router_load_max": 0.486328125,
      "router_load_min": 0.0,
      "router_load_cv": 2.5990660190582275,
      "capacity_overflow": 0.0,
      "max_grad_norm": 0.0,
      "instability": 0.0,
      "stop_reason_code": 3.0,
      "nan_seen": 0.0,
      "loss_spike": 1.1313706636428833e-05,
      "prior_distance": 0.013877207043380253,
      "ppl_per_long_recall": 0.9523809523809523,
      "ppl_per_param": 1.758517935995775e-09,
      "ppl_per_throughput": 0.00502971195284577
    },
    "spec": {
      "model": {
        "name": "phi-tiny-evo-creative",
        "emb": {
          "dim": 512,
          "vocab": 50257,
          "rope": null,
          "dropout": 0.0
        },
        "blocks": [
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "moe",
              "hidden": 2048,
              "n_experts": 16,
              "k": 4,
              "capacity_factor": 1.070899795428443,
              "balance": 0.05,
              "shared": 1,
              "router_temperature": null,
              "router_type": "softmax",
              "router_bias_detached": false,
              "shared_expert": false,
              "router_aux_weight": null,
              "router_lb_weight": null,
              "drop_policy": "none",
              "experts": []
            },
            "ssm": null,
            "extras": [
              {
                "type": "custom",
                "name": "exp-gater",
                "params": {
                  "dim": 256
                }
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "moe",
              "hidden": 2048,
              "n_experts": 16,
              "k": 2,
              "capacity_factor": 1.2,
              "balance": 0.05,
              "shared": 1,
              "router_temperature": null,
              "router_type": "softmax",
              "router_bias_detached": false,
              "shared_expert": false,
              "router_aux_weight": null,
              "router_lb_weight": null,
              "drop_policy": "none",
              "experts": []
            },
            "ssm": null,
            "extras": [
              {
                "type": "custom",
                "name": "exp-gater",
                "params": {
                  "dim": 256
                }
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": {
              "kind": "mamba2",
              "d_state": 16,
              "d_conv": 4,
              "dt_rank": 8,
              "chunk": 128,
              "gate": 0.15
            },
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 512,
                "stride": 128,
                "aggregator": "attention",
                "gating_weight": 0.1191520977835257
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "moe",
              "hidden": 2048,
              "n_experts": 16,
              "k": 2,
              "capacity_factor": 1.2,
              "balance": 0.05,
              "shared": 1,
              "router_temperature": null,
              "router_type": "softmax",
              "router_bias_detached": false,
              "shared_expert": false,
              "router_aux_weight": null,
              "router_lb_weight": null,
              "drop_policy": "none",
              "experts": []
            },
            "ssm": null,
            "extras": [
              {
                "type": "custom",
                "name": "exp-gater",
                "params": {
                  "dim": 256
                }
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": {
              "kind": "mamba2",
              "d_state": 16,
              "d_conv": 4,
              "dt_rank": 8,
              "chunk": 128,
              "gate": 0.15
            },
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 512,
                "stride": 128,
                "aggregator": "attention",
                "gating_weight": 0.1191520977835257
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": "yarn",
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "moe",
              "hidden": 2048,
              "n_experts": 16,
              "k": 2,
              "capacity_factor": 1.2,
              "balance": 0.05,
              "shared": 1,
              "router_temperature": null,
              "router_type": "softmax",
              "router_bias_detached": false,
              "shared_expert": false,
              "router_aux_weight": null,
              "router_lb_weight": null,
              "drop_policy": "none",
              "experts": []
            },
            "ssm": null,
            "extras": [
              {
                "type": "gated",
                "targets": [
                  "attn",
                  "ffn",
                  "ssm"
                ],
                "init_weight": 0.2,
                "learnable": true
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": null,
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 1024,
                "stride": 64,
                "aggregator": "gate",
                "gating_weight": 0.35
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": {
              "kind": "mamba2",
              "d_state": 16,
              "d_conv": 4,
              "dt_rank": 8,
              "chunk": 128,
              "gate": 0.15
            },
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 512,
                "stride": 128,
                "aggregator": "attention",
                "gating_weight": 0.1191520977835257
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": "yarn",
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "moe",
              "hidden": 2048,
              "n_experts": 16,
              "k": 2,
              "capacity_factor": 1.2,
              "balance": 0.05,
              "shared": 1,
              "router_temperature": null,
              "router_type": "softmax",
              "router_bias_detached": false,
              "shared_expert": false,
              "router_aux_weight": null,
              "router_lb_weight": null,
              "drop_policy": "none",
              "experts": []
            },
            "ssm": null,
            "extras": [
              {
                "type": "gated",
                "targets": [
                  "attn",
                  "ffn",
                  "ssm"
                ],
                "init_weight": 0.2,
                "learnable": true
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": "yarn",
              "rope_theta": null,
              "sw": 128,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "local_global",
              "block_size": null,
              "block_stride": null,
              "global_stride": 64,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": null,
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 256,
                "stride": 32,
                "aggregator": "gate",
                "gating_weight": 0.25
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": {
              "kind": "mamba2",
              "d_state": 16,
              "d_conv": 4,
              "dt_rank": 8,
              "chunk": 128,
              "gate": 0.15
            },
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 512,
                "stride": 128,
                "aggregator": "attention",
                "gating_weight": 0.1191520977835257
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "moe",
              "hidden": 2048,
              "n_experts": 16,
              "k": 2,
              "capacity_factor": 1.2,
              "balance": 0.05,
              "shared": 1,
              "router_temperature": null,
              "router_type": "softmax",
              "router_bias_detached": false,
              "shared_expert": false,
              "router_aux_weight": null,
              "router_lb_weight": null,
              "drop_policy": "none",
              "experts": []
            },
            "ssm": null,
            "extras": [
              {
                "type": "custom",
                "name": "exp-gater",
                "params": {
                  "dim": 256
                }
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": {
              "kind": "mamba2",
              "d_state": 16,
              "d_conv": 4,
              "dt_rank": 8,
              "chunk": 128,
              "gate": 0.15
            },
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 512,
                "stride": 128,
                "aggregator": "attention",
                "gating_weight": 0.1191520977835257
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": "yarn",
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "moe",
              "hidden": 2048,
              "n_experts": 16,
              "k": 2,
              "capacity_factor": 1.2,
              "balance": 0.05,
              "shared": 1,
              "router_temperature": null,
              "router_type": "softmax",
              "router_bias_detached": false,
              "shared_expert": false,
              "router_aux_weight": null,
              "router_lb_weight": null,
              "drop_policy": "none",
              "experts": []
            },
            "ssm": null,
            "extras": [
              {
                "type": "gated",
                "targets": [
                  "attn",
                  "ffn",
                  "ssm"
                ],
                "init_weight": 0.2,
                "learnable": true
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": null,
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 1024,
                "stride": 64,
                "aggregator": "gate",
                "gating_weight": 0.35
              },
              {
                "type": "custom",
                "name": "exp-4338",
                "params": {
                  "dim": 1024,
                  "activation": "relu",
                  "notes": "auto-generated"
                }
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": {
              "kind": "mamba2",
              "d_state": 16,
              "d_conv": 4,
              "dt_rank": 8,
              "chunk": 128,
              "gate": 0.15
            },
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 512,
                "stride": 128,
                "aggregator": "attention",
                "gating_weight": 0.1191520977835257
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": "yarn",
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "moe",
              "hidden": 2048,
              "n_experts": 16,
              "k": 2,
              "capacity_factor": 1.2,
              "balance": 0.05,
              "shared": 1,
              "router_temperature": null,
              "router_type": "softmax",
              "router_bias_detached": false,
              "shared_expert": false,
              "router_aux_weight": null,
              "router_lb_weight": null,
              "drop_policy": "none",
              "experts": []
            },
            "ssm": null,
            "extras": [
              {
                "type": "gated",
                "targets": [
                  "attn",
                  "ffn",
                  "ssm"
                ],
                "init_weight": 0.2,
                "learnable": true
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": null,
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 1024,
                "stride": 64,
                "aggregator": "gate",
                "gating_weight": 0.35
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": null,
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 1024,
                "stride": 64,
                "aggregator": "gate",
                "gating_weight": 0.35
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": null,
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 1024,
                "stride": 64,
                "aggregator": "gate",
                "gating_weight": 0.35
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": {
              "kind": "mamba2",
              "d_state": 16,
              "d_conv": 4,
              "dt_rank": 8,
              "chunk": 128,
              "gate": 0.15
            },
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 512,
                "stride": 128,
                "aggregator": "attention",
                "gating_weight": 0.1191520977835257
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "moe",
              "hidden": 2048,
              "n_experts": 16,
              "k": 2,
              "capacity_factor": 1.2,
              "balance": 0.05,
              "shared": 1,
              "router_temperature": null,
              "router_type": "softmax",
              "router_bias_detached": false,
              "shared_expert": false,
              "router_aux_weight": null,
              "router_lb_weight": null,
              "drop_policy": "none",
              "experts": []
            },
            "ssm": null,
            "extras": [
              {
                "type": "custom",
                "name": "exp-gater",
                "params": {
                  "dim": 256
                }
              }
            ]
          }
        ],
        "head": {
          "tie_embeddings": true,
          "vocab": 50257
        },
        "norm": "layernorm",
        "recurrences": []
      },
      "train": {
        "lr": 0.0008,
        "warmup": 500,
        "clip": 1.0,
        "bf16": true,
        "grad_checkpoint": true,
        "max_tokens": 520000,
        "weight_decay": 0.02,
        "seed": 4242,
        "router_lb_coeff": 0.01,
        "router_entropy_coeff": 0.005,
        "entropy_threshold": 0.5,
        "entropy_patience": 3,
        "instability_threshold": 500.0,
        "no_improve_patience": 20,
        "improvement_tolerance": 0.001,
        "ppl_stop_threshold": null,
        "init_checkpoint": null,
        "optimizer": {
          "name": "adamw",
          "lr": null,
          "betas": null,
          "eps": null,
          "weight_decay": null
        }
      },
      "data": {
        "tokenizer": "gpt2",
        "hf_revision": "main",
        "seq_len": 512,
        "batch_size": 1,
        "workers": 0,
        "shards": [
          {
            "name": "ag_news",
            "split": "train",
            "weight": 0.25,
            "cache_path": null,
            "revision": null
          },
          {
            "name": "wikitext",
            "split": "wikitext-2-raw-v1",
            "weight": 0.35,
            "cache_path": null,
            "revision": null
          },
          {
            "name": "mbpp",
            "split": "train",
            "weight": 0.4,
            "cache_path": null,
            "revision": null
          }
        ],
        "healing_shards": [],
        "healing_tokens": null
      },
      "evolution": {
        "rung0_thresholds": {
          "gate_entropy_min": 0.0,
          "gate_entropy_max": 4.0
        },
        "rung1_tokens": 300000,
        "rung2_tokens": 900000,
        "population": 24,
        "topk_keep": 0.45,
        "crossover_prob": 0.5,
        "parent_selection": "lexicase",
        "pareto_objectives": [
          "ppl_code",
          "ppl_math",
          "long_recall",
          "ppl_per_long_recall",
          "throughput",
          "ram",
          "novelty",
          "graph_entropy"
        ],
        "objectives": {
          "ppl_code": "min",
          "ppl_math": "min",
          "long_recall": "max",
          "ppl_per_long_recall": "min",
          "throughput": "max",
          "ram": "min",
          "novelty": "max",
          "graph_entropy": "max",
          "instability": "min"
        },
        "composite_metrics": [
          {
            "name": "ppl_per_long_recall",
            "op": "ratio",
            "numerator": "ppl_code",
            "denominator": "long_recall",
            "terms": {},
            "epsilon": 0.1
          }
        ],
        "promotion_prob": 0.4,
        "promotion_min_layers": 8,
        "promotion_min_moe_blocks": 2,
        "promotion_steps_multiplier": 1.5,
        "promotion_tokens_multiplier": 1.5,
        "promotion_min_router_entropy": 0.0,
        "promotion_min_recurrence_gain": 0.0,
        "promotion_max_instability": null
      },
      "priors": {
        "tokens_per_param": 4.0,
        "window_scale": 6.0,
        "rope_theta_default": 10000.0,
        "prior_weight": 0.0,
        "compute_penalty_weight": 0.0
      }
    }
  },
  {
    "id": "toggle_qk_norm-48-1e1c",
    "parent": "xover-25-549e",
    "metrics": {
      "layers": 23.0,
      "moe_blocks": 10.0,
      "graph_entropy": 2.7659264991583576,
      "selector_blocks": 0.0,
      "selector_topk_avg": 0.0,
      "memory_blocks": 13.0,
      "recurrences": 0.0,
      "novelty": 0.0,
      "params": 623539412.0,
      "kv_bytes_per_token": 23552,
      "throughput_proxy": 7.211147950141777,
      "ppl_code": 1.0,
      "ppl_math": 1.1,
      "throughput": 214.7201567880129,
      "ram": 1.1614326611161232,
      "long_recall": 1.017391304347826,
      "router_entropy": 0.6799679875373841,
      "router_lb": 0.02598807867616415,
      "router_load_max": 0.5,
      "router_load_min": 0.0,
      "router_load_cv": 2.726425886154175,
      "capacity_overflow": 0.0,
      "max_grad_norm": 0.0,
      "instability": 0.0,
      "stop_reason_code": 3.0,
      "nan_seen": 0.0,
      "loss_spike": 0.00010773539543151855,
      "prior_distance": 0.026983458161321493,
      "ppl_per_long_recall": 0.982905982905983,
      "ppl_per_param": 1.6037478638158641e-09,
      "ppl_per_throughput": 0.00465722461718986
    },
    "spec": {
      "model": {
        "name": "phi-tiny-evo-creative",
        "emb": {
          "dim": 512,
          "vocab": 50257,
          "rope": null,
          "dropout": 0.0
        },
        "blocks": [
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": "yarn",
              "rope_theta": null,
              "sw": 128,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "local_global",
              "block_size": null,
              "block_stride": null,
              "global_stride": 64,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": null,
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 256,
                "stride": 32,
                "aggregator": "gate",
                "gating_weight": 0.25
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "moe",
              "hidden": 2048,
              "n_experts": 16,
              "k": 2,
              "capacity_factor": 1.2,
              "balance": 0.05,
              "shared": 1,
              "router_temperature": null,
              "router_type": "softmax",
              "router_bias_detached": false,
              "shared_expert": false,
              "router_aux_weight": null,
              "router_lb_weight": null,
              "drop_policy": "none",
              "experts": []
            },
            "ssm": null,
            "extras": [
              {
                "type": "custom",
                "name": "exp-gater",
                "params": {
                  "dim": 256
                }
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "moe",
              "hidden": 2048,
              "n_experts": 16,
              "k": 2,
              "capacity_factor": 1.2,
              "balance": 0.05,
              "shared": 1,
              "router_temperature": null,
              "router_type": "softmax",
              "router_bias_detached": false,
              "shared_expert": false,
              "router_aux_weight": null,
              "router_lb_weight": null,
              "drop_policy": "none",
              "experts": []
            },
            "ssm": null,
            "extras": [
              {
                "type": "custom",
                "name": "exp-gater",
                "params": {
                  "dim": 256
                }
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": {
              "kind": "mamba2",
              "d_state": 16,
              "d_conv": 4,
              "dt_rank": 8,
              "chunk": 128,
              "gate": 0.15
            },
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 512,
                "stride": 128,
                "aggregator": "attention",
                "gating_weight": 0.1191520977835257
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": 0.5,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "moe",
              "hidden": 2048,
              "n_experts": 16,
              "k": 2,
              "capacity_factor": 1.2,
              "balance": 0.05,
              "shared": 1,
              "router_temperature": null,
              "router_type": "softmax",
              "router_bias_detached": false,
              "shared_expert": false,
              "router_aux_weight": null,
              "router_lb_weight": null,
              "drop_policy": "none",
              "experts": []
            },
            "ssm": null,
            "extras": [
              {
                "type": "custom",
                "name": "exp-gater",
                "params": {
                  "dim": 256
                }
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": {
              "kind": "mamba2",
              "d_state": 16,
              "d_conv": 4,
              "dt_rank": 8,
              "chunk": 128,
              "gate": 0.15
            },
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 512,
                "stride": 128,
                "aggregator": "attention",
                "gating_weight": 0.1191520977835257
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "moe",
              "hidden": 2048,
              "n_experts": 16,
              "k": 2,
              "capacity_factor": 1.2,
              "balance": 0.05,
              "shared": 1,
              "router_temperature": null,
              "router_type": "softmax",
              "router_bias_detached": false,
              "shared_expert": false,
              "router_aux_weight": null,
              "router_lb_weight": null,
              "drop_policy": "none",
              "experts": []
            },
            "ssm": null,
            "extras": [
              {
                "type": "custom",
                "name": "exp-gater",
                "params": {
                  "dim": 256
                }
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": {
              "kind": "mamba2",
              "d_state": 16,
              "d_conv": 4,
              "dt_rank": 8,
              "chunk": 128,
              "gate": 0.15
            },
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 512,
                "stride": 128,
                "aggregator": "attention",
                "gating_weight": 0.1191520977835257
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "moe",
              "hidden": 2048,
              "n_experts": 16,
              "k": 2,
              "capacity_factor": 1.2,
              "balance": 0.05,
              "shared": 1,
              "router_temperature": null,
              "router_type": "softmax",
              "router_bias_detached": false,
              "shared_expert": false,
              "router_aux_weight": null,
              "router_lb_weight": null,
              "drop_policy": "none",
              "experts": []
            },
            "ssm": null,
            "extras": [
              {
                "type": "custom",
                "name": "exp-gater",
                "params": {
                  "dim": 256
                }
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": {
              "kind": "mamba2",
              "d_state": 16,
              "d_conv": 4,
              "dt_rank": 8,
              "chunk": 128,
              "gate": 0.15
            },
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 512,
                "stride": 128,
                "aggregator": "attention",
                "gating_weight": 0.1191520977835257
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": "yarn",
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "moe",
              "hidden": 2048,
              "n_experts": 16,
              "k": 2,
              "capacity_factor": 1.2,
              "balance": 0.05,
              "shared": 1,
              "router_temperature": null,
              "router_type": "softmax",
              "router_bias_detached": false,
              "shared_expert": false,
              "router_aux_weight": null,
              "router_lb_weight": null,
              "drop_policy": "none",
              "experts": []
            },
            "ssm": null,
            "extras": [
              {
                "type": "gated",
                "targets": [
                  "attn",
                  "ffn",
                  "ssm"
                ],
                "init_weight": 0.2,
                "learnable": true
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": "yarn",
              "rope_theta": null,
              "sw": 128,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "local_global",
              "block_size": null,
              "block_stride": null,
              "global_stride": 64,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": null,
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 256,
                "stride": 32,
                "aggregator": "gate",
                "gating_weight": 0.25
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "moe",
              "hidden": 2048,
              "n_experts": 16,
              "k": 2,
              "capacity_factor": 1.2,
              "balance": 0.05,
              "shared": 1,
              "router_temperature": null,
              "router_type": "softmax",
              "router_bias_detached": false,
              "shared_expert": false,
              "router_aux_weight": null,
              "router_lb_weight": null,
              "drop_policy": "none",
              "experts": []
            },
            "ssm": null,
            "extras": [
              {
                "type": "custom",
                "name": "exp-gater",
                "params": {
                  "dim": 256
                }
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": {
              "kind": "mamba2",
              "d_state": 16,
              "d_conv": 4,
              "dt_rank": 8,
              "chunk": 128,
              "gate": 0.15
            },
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 512,
                "stride": 128,
                "aggregator": "attention",
                "gating_weight": 0.1191520977835257
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "moe",
              "hidden": 2048,
              "n_experts": 16,
              "k": 2,
              "capacity_factor": 1.2,
              "balance": 0.05,
              "shared": 1,
              "router_temperature": null,
              "router_type": "softmax",
              "router_bias_detached": false,
              "shared_expert": false,
              "router_aux_weight": null,
              "router_lb_weight": null,
              "drop_policy": "none",
              "experts": []
            },
            "ssm": null,
            "extras": [
              {
                "type": "custom",
                "name": "exp-gater",
                "params": {
                  "dim": 256
                }
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": {
              "kind": "mamba2",
              "d_state": 16,
              "d_conv": 4,
              "dt_rank": 8,
              "chunk": 128,
              "gate": 0.15
            },
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 512,
                "stride": 128,
                "aggregator": "attention",
                "gating_weight": 0.1191520977835257
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": "yarn",
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "moe",
              "hidden": 2048,
              "n_experts": 16,
              "k": 2,
              "capacity_factor": 1.2,
              "balance": 0.05,
              "shared": 1,
              "router_temperature": null,
              "router_type": "softmax",
              "router_bias_detached": false,
              "shared_expert": false,
              "router_aux_weight": null,
              "router_lb_weight": null,
              "drop_policy": "none",
              "experts": []
            },
            "ssm": null,
            "extras": [
              {
                "type": "gated",
                "targets": [
                  "attn",
                  "ffn",
                  "ssm"
                ],
                "init_weight": 0.2,
                "learnable": true
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": null,
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 1024,
                "stride": 64,
                "aggregator": "gate",
                "gating_weight": 0.35
              },
              {
                "type": "custom",
                "name": "exp-4338",
                "params": {
                  "dim": 1024,
                  "activation": "relu",
                  "notes": "auto-generated"
                }
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": {
              "kind": "mamba2",
              "d_state": 16,
              "d_conv": 4,
              "dt_rank": 8,
              "chunk": 128,
              "gate": 0.15
            },
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 512,
                "stride": 128,
                "aggregator": "attention",
                "gating_weight": 0.1191520977835257
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": "yarn",
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "moe",
              "hidden": 2048,
              "n_experts": 16,
              "k": 2,
              "capacity_factor": 1.2,
              "balance": 0.05,
              "shared": 1,
              "router_temperature": null,
              "router_type": "softmax",
              "router_bias_detached": false,
              "shared_expert": false,
              "router_aux_weight": null,
              "router_lb_weight": null,
              "drop_policy": "none",
              "experts": []
            },
            "ssm": null,
            "extras": [
              {
                "type": "gated",
                "targets": [
                  "attn",
                  "ffn",
                  "ssm"
                ],
                "init_weight": 0.2,
                "learnable": true
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": null,
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 1024,
                "stride": 64,
                "aggregator": "gate",
                "gating_weight": 0.35
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": null,
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 1024,
                "stride": 64,
                "aggregator": "gate",
                "gating_weight": 0.35
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": null,
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 1024,
                "stride": 64,
                "aggregator": "gate",
                "gating_weight": 0.35
              }
            ]
          }
        ],
        "head": {
          "tie_embeddings": true,
          "vocab": 50257
        },
        "norm": "layernorm",
        "recurrences": []
      },
      "train": {
        "lr": 0.0008,
        "warmup": 500,
        "clip": 1.0,
        "bf16": true,
        "grad_checkpoint": true,
        "max_tokens": 520000,
        "weight_decay": 0.02,
        "seed": 4242,
        "router_lb_coeff": 0.01,
        "router_entropy_coeff": 0.005,
        "entropy_threshold": 0.5,
        "entropy_patience": 3,
        "instability_threshold": 500.0,
        "no_improve_patience": 20,
        "improvement_tolerance": 0.001,
        "ppl_stop_threshold": null,
        "init_checkpoint": null,
        "optimizer": {
          "name": "adamw",
          "lr": null,
          "betas": null,
          "eps": null,
          "weight_decay": null
        }
      },
      "data": {
        "tokenizer": "gpt2",
        "hf_revision": "main",
        "seq_len": 512,
        "batch_size": 1,
        "workers": 0,
        "shards": [
          {
            "name": "ag_news",
            "split": "train",
            "weight": 0.25,
            "cache_path": null,
            "revision": null
          },
          {
            "name": "wikitext",
            "split": "wikitext-2-raw-v1",
            "weight": 0.35,
            "cache_path": null,
            "revision": null
          },
          {
            "name": "mbpp",
            "split": "train",
            "weight": 0.4,
            "cache_path": null,
            "revision": null
          }
        ],
        "healing_shards": [],
        "healing_tokens": null
      },
      "evolution": {
        "rung0_thresholds": {
          "gate_entropy_min": 0.0,
          "gate_entropy_max": 4.0
        },
        "rung1_tokens": 300000,
        "rung2_tokens": 900000,
        "population": 24,
        "topk_keep": 0.45,
        "crossover_prob": 0.5,
        "parent_selection": "lexicase",
        "pareto_objectives": [
          "ppl_code",
          "ppl_math",
          "long_recall",
          "ppl_per_long_recall",
          "throughput",
          "ram",
          "novelty",
          "graph_entropy"
        ],
        "objectives": {
          "ppl_code": "min",
          "ppl_math": "min",
          "long_recall": "max",
          "ppl_per_long_recall": "min",
          "throughput": "max",
          "ram": "min",
          "novelty": "max",
          "graph_entropy": "max",
          "instability": "min"
        },
        "composite_metrics": [
          {
            "name": "ppl_per_long_recall",
            "op": "ratio",
            "numerator": "ppl_code",
            "denominator": "long_recall",
            "terms": {},
            "epsilon": 0.1
          }
        ],
        "promotion_prob": 0.4,
        "promotion_min_layers": 8,
        "promotion_min_moe_blocks": 2,
        "promotion_steps_multiplier": 1.5,
        "promotion_tokens_multiplier": 1.5,
        "promotion_min_router_entropy": 0.0,
        "promotion_min_recurrence_gain": 0.0,
        "promotion_max_instability": null
      },
      "priors": {
        "tokens_per_param": 4.0,
        "window_scale": 6.0,
        "rope_theta_default": 10000.0,
        "prior_weight": 0.0,
        "compute_penalty_weight": 0.0
      }
    }
  },
  {
    "id": "xover-49-3af0",
    "parent": null,
    "metrics": {
      "layers": 10.0,
      "moe_blocks": 4.0,
      "graph_entropy": 2.652952135365423,
      "selector_blocks": 0.0,
      "selector_topk_avg": 0.0,
      "memory_blocks": 6.0,
      "recurrences": 0.0,
      "novelty": 0.4090909090909091,
      "params": 267655122.0,
      "kv_bytes_per_token": 10240,
      "throughput_proxy": 38.14697265625,
      "ppl_code": 1.0,
      "ppl_math": 1.04,
      "throughput": 376.18220053260126,
      "ram": 0.49854651466012,
      "long_recall": 1.0,
      "router_entropy": 0.6860901564359665,
      "router_lb": 0.027161152567714453,
      "router_load_max": 0.5,
      "router_load_min": 0.0,
      "router_load_cv": 2.7264318466186523,
      "capacity_overflow": 0.0,
      "max_grad_norm": 0.0,
      "instability": 0.0,
      "stop_reason_code": 3.0,
      "nan_seen": 0.0,
      "loss_spike": 9.313225746154785e-10,
      "prior_distance": 0.030356389377445406,
      "ppl_per_long_recall": 1.0,
      "ppl_per_param": 3.736151180398483e-09,
      "ppl_per_throughput": 0.002658286326636915
    },
    "spec": {
      "model": {
        "name": "phi-tiny-evo-creative",
        "emb": {
          "dim": 512,
          "vocab": 50257,
          "rope": null,
          "dropout": 0.0
        },
        "blocks": [
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": "yarn",
              "rope_theta": null,
              "sw": 128,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "local_global",
              "block_size": null,
              "block_stride": null,
              "global_stride": 64,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": null,
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 256,
                "stride": 32,
                "aggregator": "gate",
                "gating_weight": 0.25
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "moe",
              "hidden": 2048,
              "n_experts": 16,
              "k": 2,
              "capacity_factor": 1.2,
              "balance": 0.05,
              "shared": 1,
              "router_temperature": null,
              "router_type": "softmax",
              "router_bias_detached": false,
              "shared_expert": false,
              "router_aux_weight": null,
              "router_lb_weight": null,
              "drop_policy": "none",
              "experts": []
            },
            "ssm": null,
            "extras": [
              {
                "type": "custom",
                "name": "exp-gater",
                "params": {
                  "dim": 256
                }
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "moe",
              "hidden": 2048,
              "n_experts": 16,
              "k": 2,
              "capacity_factor": 1.2,
              "balance": 0.05,
              "shared": 1,
              "router_temperature": null,
              "router_type": "softmax",
              "router_bias_detached": false,
              "shared_expert": false,
              "router_aux_weight": null,
              "router_lb_weight": null,
              "drop_policy": "none",
              "experts": []
            },
            "ssm": null,
            "extras": [
              {
                "type": "custom",
                "name": "exp-gater",
                "params": {
                  "dim": 256
                }
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": {
              "kind": "mamba2",
              "d_state": 16,
              "d_conv": 4,
              "dt_rank": 8,
              "chunk": 128,
              "gate": 0.15
            },
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 512,
                "stride": 128,
                "aggregator": "attention",
                "gating_weight": 0.1191520977835257
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "moe",
              "hidden": 2048,
              "n_experts": 16,
              "k": 2,
              "capacity_factor": 1.2,
              "balance": 0.05,
              "shared": 1,
              "router_temperature": null,
              "router_type": "softmax",
              "router_bias_detached": false,
              "shared_expert": false,
              "router_aux_weight": null,
              "router_lb_weight": null,
              "drop_policy": "none",
              "experts": []
            },
            "ssm": null,
            "extras": [
              {
                "type": "custom",
                "name": "exp-gater",
                "params": {
                  "dim": 256
                }
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": {
              "kind": "mamba2",
              "d_state": 16,
              "d_conv": 4,
              "dt_rank": 8,
              "chunk": 128,
              "gate": 0.15
            },
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 512,
                "stride": 128,
                "aggregator": "attention",
                "gating_weight": 0.1191520977835257
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": "yarn",
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "moe",
              "hidden": 2048,
              "n_experts": 16,
              "k": 2,
              "capacity_factor": 1.2,
              "balance": 0.05,
              "shared": 1,
              "router_temperature": null,
              "router_type": "softmax",
              "router_bias_detached": false,
              "shared_expert": false,
              "router_aux_weight": null,
              "router_lb_weight": null,
              "drop_policy": "none",
              "experts": []
            },
            "ssm": null,
            "extras": [
              {
                "type": "gated",
                "targets": [
                  "attn",
                  "ffn",
                  "ssm"
                ],
                "init_weight": 0.2,
                "learnable": true
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": null,
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 1024,
                "stride": 64,
                "aggregator": "gate",
                "gating_weight": 0.35
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": null,
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 1024,
                "stride": 64,
                "aggregator": "gate",
                "gating_weight": 0.35
              }
            ]
          },
          {
            "name": null,
            "attn": {
              "kind": "GQA",
              "heads": 8,
              "head_dim": 64,
              "rope": null,
              "rope_theta": null,
              "sw": null,
              "kv_groups": 2,
              "dropout": 0.0,
              "qk_norm_max": null,
              "gating_pos": "none",
              "gating_op": "dense",
              "sparsity": "none",
              "block_size": null,
              "block_stride": null,
              "global_stride": null,
              "dilation": null,
              "selector": "none",
              "selector_topk": null,
              "selector_heads": null,
              "selector_dim": null,
              "selector_rope": "none",
              "selector_detach": false
            },
            "ffn": {
              "type": "dense",
              "hidden": 2048,
              "activation": "swiglu",
              "dropout": 0.0
            },
            "ssm": null,
            "extras": [
              {
                "type": "retro",
                "memory_tokens": 1024,
                "stride": 64,
                "aggregator": "gate",
                "gating_weight": 0.35
              }
            ]
          }
        ],
        "head": {
          "tie_embeddings": true,
          "vocab": 50257
        },
        "norm": "layernorm",
        "recurrences": []
      },
      "train": {
        "lr": 0.0008,
        "warmup": 500,
        "clip": 1.0,
        "bf16": true,
        "grad_checkpoint": true,
        "max_tokens": 520000,
        "weight_decay": 0.02,
        "seed": 4242,
        "router_lb_coeff": 0.01,
        "router_entropy_coeff": 0.005,
        "entropy_threshold": 0.5,
        "entropy_patience": 3,
        "instability_threshold": 500.0,
        "no_improve_patience": 20,
        "improvement_tolerance": 0.001,
        "ppl_stop_threshold": null,
        "init_checkpoint": null,
        "optimizer": {
          "name": "adamw",
          "lr": null,
          "betas": null,
          "eps": null,
          "weight_decay": null
        }
      },
      "data": {
        "tokenizer": "gpt2",
        "hf_revision": "main",
        "seq_len": 512,
        "batch_size": 1,
        "workers": 0,
        "shards": [
          {
            "name": "ag_news",
            "split": "train",
            "weight": 0.25,
            "cache_path": null,
            "revision": null
          },
          {
            "name": "wikitext",
            "split": "wikitext-2-raw-v1",
            "weight": 0.35,
            "cache_path": null,
            "revision": null
          },
          {
            "name": "mbpp",
            "split": "train",
            "weight": 0.4,
            "cache_path": null,
            "revision": null
          }
        ],
        "healing_shards": [],
        "healing_tokens": null
      },
      "evolution": {
        "rung0_thresholds": {
          "gate_entropy_min": 0.0,
          "gate_entropy_max": 4.0
        },
        "rung1_tokens": 300000,
        "rung2_tokens": 900000,
        "population": 24,
        "topk_keep": 0.45,
        "crossover_prob": 0.5,
        "parent_selection": "lexicase",
        "pareto_objectives": [
          "ppl_code",
          "ppl_math",
          "long_recall",
          "ppl_per_long_recall",
          "throughput",
          "ram",
          "novelty",
          "graph_entropy"
        ],
        "objectives": {
          "ppl_code": "min",
          "ppl_math": "min",
          "long_recall": "max",
          "ppl_per_long_recall": "min",
          "throughput": "max",
          "ram": "min",
          "novelty": "max",
          "graph_entropy": "max",
          "instability": "min"
        },
        "composite_metrics": [
          {
            "name": "ppl_per_long_recall",
            "op": "ratio",
            "numerator": "ppl_code",
            "denominator": "long_recall",
            "terms": {},
            "epsilon": 0.1
          }
        ],
        "promotion_prob": 0.4,
        "promotion_min_layers": 8,
        "promotion_min_moe_blocks": 2,
        "promotion_steps_multiplier": 1.5,
        "promotion_tokens_multiplier": 1.5,
        "promotion_min_router_entropy": 0.0,
        "promotion_min_recurrence_gain": 0.0,
        "promotion_max_instability": null
      },
      "priors": {
        "tokens_per_param": 4.0,
        "window_scale": 6.0,
        "rope_theta_default": 10000.0,
        "prior_weight": 0.0,
        "compute_penalty_weight": 0.0
      }
    }
  }
]