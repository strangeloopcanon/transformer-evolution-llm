model:
  name: phi-scalehop-xover-68-8a93
  emb:
    dim: 1536
    vocab: 50257
    rope: null
    dropout: 0.0
  blocks:
    - attn:
        kind: GQA
        heads: 24
        head_dim: 64
        rope: yarn
        rope_theta: 14000.0
        sw: 192
        kv_groups: 2
        dropout: 0.0
        sparsity: local_global
        global_stride: 48
      ffn:
        type: dense
        hidden: 6144
        activation: swiglu
        dropout: 0.0
      extras:
        - type: retro
          memory_tokens: 512
          stride: 32
          aggregator: gate
          gating_weight: 0.25
    - attn:
        kind: GQA
        heads: 24
        head_dim: 64
        rope: yarn
        rope_theta: 15000.0
        sw: 192
        kv_groups: 2
        dropout: 0.0
        sparsity: local_block
        block_size: 96
        block_stride: 192
      ffn:
        type: moe
        hidden: 6144
        n_experts: 32
        k: 2
        capacity_factor: 1.3
        balance: 0.05
        shared: 1
      extras:
        - type: custom
          name: exp-gater
          params:
            dim: 512
        - type: retro
          memory_tokens: 1024
          stride: 64
          aggregator: gate
          gating_weight: 0.35
    - attn:
        kind: GQA
        heads: 24
        head_dim: 64
        rope: null
        sw: null
        kv_groups: 2
        dropout: 0.0
        sparsity: none
      ffn:
        type: dense
        hidden: 6144
        activation: swiglu
        dropout: 0.0
      ssm:
        kind: mamba2
        d_state: 32
        d_conv: 6
        dt_rank: 16
        chunk: 256
        gate: 0.15
    - attn:
        kind: GQA
        heads: 24
        head_dim: 64
        rope: yarn
        rope_theta: 16000.0
        sw: 192
        kv_groups: 2
        dropout: 0.0
        sparsity: dilated
        dilation: 4
      ffn:
        type: dense
        hidden: 6144
        activation: swiglu
        dropout: 0.0
      extras:
        - type: retro
          memory_tokens: 2048
          stride: 64
          aggregator: gate
          gating_weight: 0.3
    - attn:
        kind: GQA
        heads: 24
        head_dim: 64
        rope: yarn
        rope_theta: 14000.0
        sw: 192
        kv_groups: 2
        dropout: 0.0
        sparsity: local_global
        global_stride: 48
      ffn:
        type: moe
        hidden: 6144
        n_experts: 32
        k: 2
        capacity_factor: 1.3
        balance: 0.05
        shared: 1
      extras:
        - type: gated
          targets: ["attn", "ffn", "ssm"]
          init_weight: 0.2
          learnable: true
    - attn:
        kind: GQA
        heads: 24
        head_dim: 64
        rope: yarn
        rope_theta: 15000.0
        sw: 192
        kv_groups: 2
        dropout: 0.0
        sparsity: local_block
        block_size: 96
        block_stride: 192
      ffn:
        type: dense
        hidden: 6144
        activation: swiglu
        dropout: 0.0
      extras:
        - type: retro
          memory_tokens: 1024
          stride: 64
          aggregator: gate
          gating_weight: 0.35
    - attn:
        kind: GQA
        heads: 24
        head_dim: 64
        rope: yarn
        rope_theta: 15000.0
        sw: 192
        kv_groups: 2
        dropout: 0.0
        sparsity: dilated
        dilation: 3
      ffn:
        type: dense
        hidden: 6144
        activation: swiglu
        dropout: 0.0
      extras:
        - type: retro
          memory_tokens: 512
          stride: 32
          aggregator: gate
          gating_weight: 0.25
    - attn:
        kind: GQA
        heads: 24
        head_dim: 64
        rope: yarn
        rope_theta: 16000.0
        sw: 192
        kv_groups: 2
        dropout: 0.0
        sparsity: local_global
        global_stride: 48
      ffn:
        type: dense
        hidden: 6144
        activation: swiglu
        dropout: 0.0
      ssm:
        kind: mamba2
        d_state: 32
        d_conv: 6
        dt_rank: 16
        chunk: 256
        gate: 0.15
    - attn:
        kind: GQA
        heads: 24
        head_dim: 64
        rope: yarn
        rope_theta: 14000.0
        sw: 192
        kv_groups: 2
        dropout: 0.0
        sparsity: local_block
        block_size: 96
        block_stride: 192
      ffn:
        type: moe
        hidden: 6144
        n_experts: 32
        k: 2
        capacity_factor: 1.3
        balance: 0.05
        shared: 1
      extras:
        - type: retro
          memory_tokens: 1536
          stride: 64
          aggregator: gate
          gating_weight: 0.3
    - attn:
        kind: GQA
        heads: 24
        head_dim: 64
        rope: null
        sw: null
        kv_groups: 2
        dropout: 0.0
        sparsity: none
      ffn:
        type: dense
        hidden: 6144
        activation: swiglu
        dropout: 0.0
      extras:
        - type: custom
          name: exp-bridge
          params:
            dim: 512
    - attn:
        kind: GQA
        heads: 24
        head_dim: 64
        rope: yarn
        rope_theta: 15000.0
        sw: 192
        kv_groups: 2
        dropout: 0.0
        sparsity: local_global
        global_stride: 48
      ffn:
        type: dense
        hidden: 6144
        activation: swiglu
        dropout: 0.0
      ssm:
        kind: mamba2
        d_state: 32
        d_conv: 6
        dt_rank: 16
        chunk: 256
        gate: 0.15
    - attn:
        kind: GQA
        heads: 24
        head_dim: 64
        rope: yarn
        rope_theta: 15000.0
        sw: 192
        kv_groups: 2
        dropout: 0.0
        sparsity: local_block
        block_size: 96
        block_stride: 192
      ffn:
        type: dense
        hidden: 6144
        activation: swiglu
        dropout: 0.0
      extras:
        - type: retro
          memory_tokens: 1024
          stride: 64
          aggregator: gate
          gating_weight: 0.35
  head:
    tie_embeddings: true
    vocab: 50257
  norm: rmsnorm
train:
  lr: 0.0003
  warmup: 2000
  clip: 1.0
  bf16: true
  grad_ckpt: true
  max_tokens: 2000000
  weight_decay: 0.02
  seed: 9001
  router_lb_coeff: 0.01
  router_entropy_coeff: 0.005
  optimizer:
    name: adamw
data:
  tokenizer: gpt2
  hf_revision: main
  seq_len: 2048
  batch_size: 1
  workers: 0
  shards:
    - name: ag_news
      split: train
      weight: 0.2
    - name: wikitext
      split: wikitext-2-raw-v1
      weight: 0.3
    - name: codeparrot/github-code-clean
      split: train
      weight: 0.5
evolution:
  rung0_thresholds:
    gate_entropy_min: 0.8
    gate_entropy_max: 3.5
  rung1_tokens: 800000
  rung2_tokens: 2000000
  population: 16
  topk_keep: 0.5
  crossover_prob: 0.4
  parent_selection: lexicase
  pareto_objectives:
    - ppl_code
    - ppl_math
    - long_recall
    - throughput
    - ram
    - layers
    - moe_blocks
    - novelty
priors:
  tokens_per_param: 6.0
  window_scale: 5.0
  rope_theta_default: 15000.0
  prior_weight: 0.0
  compute_penalty_weight: 0.0
