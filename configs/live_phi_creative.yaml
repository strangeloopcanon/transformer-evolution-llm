model:
  name: phi-tiny-evo-creative
  emb:
    dim: 512
    vocab: 50257
  blocks:
    - attn:
        kind: GQA
        heads: 8
        head_dim: 64
        rope: yarn
        sparsity: local_global
        sliding_window: 128
        global_stride: 64
        kv_groups: 2
      ffn:
        type: dense
        hidden: 2048
        activation: swiglu
      extras:
        - type: retro
          memory_tokens: 256
          stride: 32
          aggregator: gate
          gating_weight: 0.25
    - attn:
        kind: GQA
        heads: 8
        head_dim: 64
      ffn:
        type: moe
        hidden: 2048
        n_experts: 16
        k: 2
        capacity_factor: 1.2
        balance: 0.05
        shared: 1
      extras:
        - type: custom
          name: exp-gater
          params:
            dim: 256
    - attn:
        kind: GQA
        heads: 8
        head_dim: 64
      ffn:
        type: dense
        hidden: 2048
        activation: swiglu
      ssm:
        kind: mamba2
        d_state: 16
        d_conv: 4
        dt_rank: 8
        chunk: 128
        gate: 0.15
    - attn:
        kind: GQA
        heads: 8
        head_dim: 64
        rope: yarn
      ffn:
        type: moe
        hidden: 2048
        n_experts: 16
        k: 2
        capacity_factor: 1.2
        balance: 0.05
        shared: 1
      extras:
        - type: gated
          targets: ["attn", "ffn", "ssm"]
          init_weight: 0.2
          learnable: true
    - attn:
        kind: GQA
        heads: 8
        head_dim: 64
      ffn:
        type: dense
        hidden: 2048
        activation: swiglu
      extras:
        - type: retro
          memory_tokens: 1024
          stride: 64
          aggregator: gate
          gating_weight: 0.35
  head:
    tie_embeddings: true
    vocab: 50257
train:
  lr: 0.0008
  warmup: 500
  clip: 1.0
  bf16: true
  grad_ckpt: true
  max_tokens: 520000
  weight_decay: 0.02
  seed: 4242
  router_lb_coeff: 0.01
  router_entropy_coeff: 0.005
  optimizer:
    name: adamw
data:
  tokenizer: gpt2
  hf_revision: main
  seq_len: 512
  batch_size: 1
  workers: 0
  shards:
    - name: ag_news
      split: train
      weight: 0.25
    - name: wikitext
      split: wikitext-2-raw-v1
      weight: 0.35
    - name: codeparrot/github-code-clean
      split: train
      weight: 0.40
evolution:
  rung0_thresholds:
    gate_entropy_min: 0.8
    gate_entropy_max: 3.5
  rung1_tokens: 180000
  rung2_tokens: 600000
  population: 24
  topk_keep: 0.5
  crossover_prob: 0.5
  pareto_objectives:
    - ppl_code
    - ppl_math
    - long_recall
    - ppl_per_long_recall
    - throughput
    - ram
    - novelty
  objectives:
    ppl_code: min
    ppl_math: min
    long_recall: max
    ppl_per_long_recall: min
    throughput: max
    ram: min
    novelty: max
    instability: min
  composite_metrics:
    - name: ppl_per_long_recall
      op: ratio
      numerator: ppl_code
      denominator: long_recall
      epsilon: 0.1
